{"task_id": "L1_1", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single square matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input matrix A of shape (N, N).\n            B (torch.Tensor): Input matrix B of shape (N, N).\n\n        Returns:\n            torch.Tensor: Output matrix C of shape (N, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(N, N)\n    B = torch.rand(N, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single square matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input matrix A of shape (N, N).\n            B (torch.Tensor): Input matrix B of shape (N, N).\n\n        Returns:\n            torch.Tensor: Output matrix C of shape (N, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(N, N)\n    B = torch.rand(N, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 1, "problem_name": "1_Square_matrix_multiplication_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single square matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input matrix A of shape (N, N).\n            B (torch.Tensor): Input matrix B of shape (N, N).\n\n        Returns:\n            torch.Tensor: Output matrix C of shape (N, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(N, N)\n    B = torch.rand(N, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_2", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 2, "problem_name": "2_Standard_matrix_multiplication_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_3", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs batched matrix multiplication (C = A * B) where A, B, and C have the same batch dimension.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs batched matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (batch_size, m, k).\n            B: Input tensor of shape (batch_size, k, n).\n\n        Returns:\n            C: Output tensor of shape (batch_size, m, n).\n        \"\"\"\n        return torch.bmm(A, B)\n\nbatch_size = 128\nm = 128 * 4\nk = 256 * 4\nn = 512 * 4\n\ndef get_inputs():\n    A = torch.rand(batch_size, m, k)\n    B = torch.rand(batch_size, k, n)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs batched matrix multiplication (C = A * B) where A, B, and C have the same batch dimension.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs batched matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (batch_size, m, k).\n            B: Input tensor of shape (batch_size, k, n).\n\n        Returns:\n            C: Output tensor of shape (batch_size, m, n).\n        \"\"\"\n        return torch.bmm(A, B)\n\nbatch_size = 128\nm = 128 * 4\nk = 256 * 4\nn = 512 * 4\n\ndef get_inputs():\n    A = torch.rand(batch_size, m, k)\n    B = torch.rand(batch_size, k, n)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 3, "problem_name": "3_Batched_matrix_multiplication.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs batched matrix multiplication (C = A * B) where A, B, and C have the same batch dimension.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs batched matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (batch_size, m, k).\n            B: Input tensor of shape (batch_size, k, n).\n\n        Returns:\n            C: Output tensor of shape (batch_size, m, n).\n        \"\"\"\n        return torch.bmm(A, B)\n\nbatch_size = 128\nm = 128 * 4\nk = 256 * 4\nn = 512 * 4\n\ndef get_inputs():\n    A = torch.rand(batch_size, m, k)\n    B = torch.rand(batch_size, k, n)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_4", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs matrix-vector multiplication (C = A * B).\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix-vector multiplication.\n\n        Args:\n            A: Input matrix of shape (M, K).\n            B: Input vector of shape (K, 1).\n\n        Returns:\n            Output vector of shape (M, 1).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 256 * 8 # 2048\nK = 131072 * 8 # 1048576\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, 1)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs matrix-vector multiplication (C = A * B).\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix-vector multiplication.\n\n        Args:\n            A: Input matrix of shape (M, K).\n            B: Input vector of shape (K, 1).\n\n        Returns:\n            Output vector of shape (M, 1).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 256 * 8 # 2048\nK = 131072 * 8 # 1048576\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, 1)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 4, "problem_name": "4_Matrix_vector_multiplication_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs matrix-vector multiplication (C = A * B).\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix-vector multiplication.\n\n        Args:\n            A: Input matrix of shape (M, K).\n            B: Input vector of shape (K, 1).\n\n        Returns:\n            Output vector of shape (M, 1).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 256 * 8 # 2048\nK = 131072 * 8 # 1048576\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, 1)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_5", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix-scalar multiplication (C = A * s)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, s: float) -> torch.Tensor:\n        \"\"\"\n        Performs matrix-scalar multiplication.\n\n        Args:\n            A: Input matrix of shape (M, N)\n            s: Scalar value\n\n        Returns:\n            C: Resulting matrix of shape (M, N)\n        \"\"\"\n        return A * s\n\nM = 16384 * 4\nN = 4096 * 4\n\ndef get_inputs():\n    A = torch.rand(M, N)\n    s = 3.14\n    return [A, s]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix-scalar multiplication (C = A * s)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, s: float) -> torch.Tensor:\n        \"\"\"\n        Performs matrix-scalar multiplication.\n\n        Args:\n            A: Input matrix of shape (M, N)\n            s: Scalar value\n\n        Returns:\n            C: Resulting matrix of shape (M, N)\n        \"\"\"\n        return A * s\n\nM = 16384 * 4\nN = 4096 * 4\n\ndef get_inputs():\n    A = torch.rand(M, N)\n    s = 3.14\n    return [A, s]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 5, "problem_name": "5_Matrix_scalar_multiplication.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix-scalar multiplication (C = A * s)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, s: float) -> torch.Tensor:\n        \"\"\"\n        Performs matrix-scalar multiplication.\n\n        Args:\n            A: Input matrix of shape (M, N)\n            s: Scalar value\n\n        Returns:\n            C: Resulting matrix of shape (M, N)\n        \"\"\"\n        return A * s\n\nM = 16384 * 4\nN = 4096 * 4\n\ndef get_inputs():\n    A = torch.rand(M, N)\n    s = 3.14\n    return [A, s]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_6", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a large K dimension\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor of shape (M, K)\n            B: Input tensor of shape (K, N)\n\n        Returns:\n            Output tensor of shape (M, N)\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 256\nN = 256\nK = 131072 * 4\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a large K dimension\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor of shape (M, K)\n            B: Input tensor of shape (K, N)\n\n        Returns:\n            Output tensor of shape (M, N)\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 256\nN = 256\nK = 131072 * 4\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 6, "problem_name": "6_Matmul_with_large_K_dimension_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a large K dimension\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor of shape (M, K)\n            B: Input tensor of shape (K, N)\n\n        Returns:\n            Output tensor of shape (M, N)\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 256\nN = 256\nK = 131072 * 4\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_7", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a small K dimension\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 16384 * 2\nN = 16384 * 2\nK = 32 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a small K dimension\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 16384 * 2\nN = 16384 * 2\nK = 32 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 7, "problem_name": "7_Matmul_with_small_K_dimension_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with a small K dimension\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 16384 * 2\nN = 16384 * 2\nK = 32 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_8", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with irregular shapes\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor with shape (M, K).\n            B: Input tensor with shape (K, N).\n\n        Returns:\n            C: Output tensor with shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 8205\nK = 2949\nN = 5921\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with irregular shapes\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor with shape (M, K).\n            B: Input tensor with shape (K, N).\n\n        Returns:\n            C: Output tensor with shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 8205\nK = 2949\nN = 5921\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 8, "problem_name": "8_Matmul_with_irregular_shapes_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with irregular shapes\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication of A and B.\n\n        Args:\n            A: Input tensor with shape (M, K).\n            B: Input tensor with shape (K, N).\n\n        Returns:\n            C: Output tensor with shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 8205\nK = 2949\nN = 5921\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_9", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) where one of the matrices is tall and skinny (M >> N or N >> M)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input matrix of shape (M, K) or (K, M) where M >> N or N >> M.\n            B (torch.Tensor): Input matrix of shape (K, N) or (N, K) where M >> N or N >> M.\n\n        Returns:\n            torch.Tensor: Output matrix of shape (M, N) or (N, M)\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 16384 * 2\nN = 16 * 2\n\ndef get_inputs():\n    A = torch.rand(M, N)\n    B = torch.rand(N, M)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) where one of the matrices is tall and skinny (M >> N or N >> M)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input matrix of shape (M, K) or (K, M) where M >> N or N >> M.\n            B (torch.Tensor): Input matrix of shape (K, N) or (N, K) where M >> N or N >> M.\n\n        Returns:\n            torch.Tensor: Output matrix of shape (M, N) or (N, M)\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 16384 * 2\nN = 16 * 2\n\ndef get_inputs():\n    A = torch.rand(M, N)\n    B = torch.rand(N, M)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 9, "problem_name": "9_Tall_skinny_matrix_multiplication_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) where one of the matrices is tall and skinny (M >> N or N >> M)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input matrix of shape (M, K) or (K, M) where M >> N or N >> M.\n            B (torch.Tensor): Input matrix of shape (K, N) or (N, K) where M >> N or N >> M.\n\n        Returns:\n            torch.Tensor: Output matrix of shape (M, N) or (N, M)\n        \"\"\"\n        return torch.matmul(A, B)\n\nM = 16384 * 2\nN = 16 * 2\n\ndef get_inputs():\n    A = torch.rand(M, N)\n    B = torch.rand(N, M)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_10", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs 3D tensor-matrix multiplication.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs 3D tensor-matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input 3D tensor of shape (N, M, K).\n            B (torch.Tensor): Input matrix of shape (K, L).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (N, M, L), resulting from the multiplication of A and B along the last dimension of A.\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 16\nM = 1024\nK = 2048\nL = 768\n\ndef get_inputs():\n    A = torch.rand(N, M, K)\n    B = torch.rand(K, L)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs 3D tensor-matrix multiplication.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs 3D tensor-matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input 3D tensor of shape (N, M, K).\n            B (torch.Tensor): Input matrix of shape (K, L).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (N, M, L), resulting from the multiplication of A and B along the last dimension of A.\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 16\nM = 1024\nK = 2048\nL = 768\n\ndef get_inputs():\n    A = torch.rand(N, M, K)\n    B = torch.rand(K, L)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 10, "problem_name": "10_3D_tensor_matrix_multiplication.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs 3D tensor-matrix multiplication.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs 3D tensor-matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input 3D tensor of shape (N, M, K).\n            B (torch.Tensor): Input matrix of shape (K, L).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (N, M, L), resulting from the multiplication of A and B along the last dimension of A.\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 16\nM = 1024\nK = 2048\nL = 768\n\ndef get_inputs():\n    A = torch.rand(N, M, K)\n    B = torch.rand(K, L)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_11", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs 4D tensor-matrix multiplication: \n        C[b, i, j, k] = sum_l A[b, i, j, l] * B[l, k]\n\n    Args:\n        A (torch.Tensor): Input 4D tensor of shape (b, i, j, l)\n        B (torch.Tensor): Input matrix of shape (l, k)\n\n    Returns:\n        torch.Tensor: Output 4D tensor of shape (b, i, j, k)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, A, B):\n        \"\"\"\n        Performs the 4D tensor-matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input 4D tensor of shape (b, i, j, l)\n            B (torch.Tensor): Input matrix of shape (l, k)\n\n        Returns:\n            torch.Tensor: Output 4D tensor of shape (b, i, j, k)\n        \"\"\"\n        return torch.einsum(\"bijl,lk->bijk\", A, B)\n\n# Test code\nb = 8\ni = 256\nj = 512\nl = 256\nk = 768\n\ndef get_inputs():\n    A = torch.rand(b, i, j, l)\n    B = torch.rand(l, k)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs 4D tensor-matrix multiplication: \n        C[b, i, j, k] = sum_l A[b, i, j, l] * B[l, k]\n\n    Args:\n        A (torch.Tensor): Input 4D tensor of shape (b, i, j, l)\n        B (torch.Tensor): Input matrix of shape (l, k)\n\n    Returns:\n        torch.Tensor: Output 4D tensor of shape (b, i, j, k)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, A, B):\n        \"\"\"\n        Performs the 4D tensor-matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input 4D tensor of shape (b, i, j, l)\n            B (torch.Tensor): Input matrix of shape (l, k)\n\n        Returns:\n            torch.Tensor: Output 4D tensor of shape (b, i, j, k)\n        \"\"\"\n        return torch.einsum(\"bijl,lk->bijk\", A, B)\n\n# Test code\nb = 8\ni = 256\nj = 512\nl = 256\nk = 768\n\ndef get_inputs():\n    A = torch.rand(b, i, j, l)\n    B = torch.rand(l, k)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 11, "problem_name": "11_4D_tensor_matrix_multiplication.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs 4D tensor-matrix multiplication: \n        C[b, i, j, k] = sum_l A[b, i, j, l] * B[l, k]\n\n    Args:\n        A (torch.Tensor): Input 4D tensor of shape (b, i, j, l)\n        B (torch.Tensor): Input matrix of shape (l, k)\n\n    Returns:\n        torch.Tensor: Output 4D tensor of shape (b, i, j, k)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, A, B):\n        \"\"\"\n        Performs the 4D tensor-matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input 4D tensor of shape (b, i, j, l)\n            B (torch.Tensor): Input matrix of shape (l, k)\n\n        Returns:\n            torch.Tensor: Output 4D tensor of shape (b, i, j, k)\n        \"\"\"\n        return torch.einsum(\"bijl,lk->bijk\", A, B)\n\n# Test code\nb = 8\ni = 256\nj = 512\nl = 256\nk = 768\n\ndef get_inputs():\n    A = torch.rand(b, i, j, l)\n    B = torch.rand(l, k)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_12", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication of a diagonal matrix with another matrix.\n    C = diag(A) * B\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): A 1D tensor representing the diagonal of the diagonal matrix. Shape: (N,).\n            B (torch.Tensor): A 2D tensor representing the second matrix. Shape: (N, M).\n\n        Returns:\n            torch.Tensor: The result of the matrix multiplication. Shape: (N, M).\n        \"\"\"\n        # Logically equivalent to torch.diag(A) @ B \n        # more efficient as no need to materialize a full N\u00d7N matrix\n        return A.unsqueeze(1) * B\n\nM = 4096\nN = 4096\n\ndef get_inputs():\n    A = torch.rand(N)\n    B = torch.rand(N, M)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication of a diagonal matrix with another matrix.\n    C = diag(A) * B\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): A 1D tensor representing the diagonal of the diagonal matrix. Shape: (N,).\n            B (torch.Tensor): A 2D tensor representing the second matrix. Shape: (N, M).\n\n        Returns:\n            torch.Tensor: The result of the matrix multiplication. Shape: (N, M).\n        \"\"\"\n        # Logically equivalent to torch.diag(A) @ B \n        # more efficient as no need to materialize a full N\u00d7N matrix\n        return A.unsqueeze(1) * B\n\nM = 4096\nN = 4096\n\ndef get_inputs():\n    A = torch.rand(N)\n    B = torch.rand(N, M)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 12, "problem_name": "12_Matmul_with_diagonal_matrices_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication of a diagonal matrix with another matrix.\n    C = diag(A) * B\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs the matrix multiplication.\n\n        Args:\n            A (torch.Tensor): A 1D tensor representing the diagonal of the diagonal matrix. Shape: (N,).\n            B (torch.Tensor): A 2D tensor representing the second matrix. Shape: (N, M).\n\n        Returns:\n            torch.Tensor: The result of the matrix multiplication. Shape: (N, M).\n        \"\"\"\n        # Logically equivalent to torch.diag(A) @ B \n        # more efficient as no need to materialize a full N\u00d7N matrix\n        return A.unsqueeze(1) * B\n\nM = 4096\nN = 4096\n\ndef get_inputs():\n    A = torch.rand(N)\n    B = torch.rand(N, M)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_13", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with A and B being symmetric matrices.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of two symmetric matrices.\n\n        Args:\n            A (torch.Tensor): Input matrix A, shape (N, N), symmetric.\n            B (torch.Tensor): Input matrix B, shape (N, N), symmetric.\n\n        Returns:\n            torch.Tensor: Output matrix C, shape (N, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates a pair of random symmetric matrices for testing.\n\n    Returns:\n        list: List containing two symmetric tensors A and B.\n    \"\"\"\n    A = torch.rand(N, N)\n    A = (A + A.T) / 2  # Ensure symmetry\n    B = torch.rand(N, N)\n    B = (B + B.T) / 2  # Ensure symmetry\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs needed for this model.\n\n    Returns:\n        list: Empty list.\n    \"\"\"\n    return []", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with A and B being symmetric matrices.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of two symmetric matrices.\n\n        Args:\n            A (torch.Tensor): Input matrix A, shape (N, N), symmetric.\n            B (torch.Tensor): Input matrix B, shape (N, N), symmetric.\n\n        Returns:\n            torch.Tensor: Output matrix C, shape (N, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates a pair of random symmetric matrices for testing.\n\n    Returns:\n        list: List containing two symmetric tensors A and B.\n    \"\"\"\n    A = torch.rand(N, N)\n    A = (A + A.T) / 2  # Ensure symmetry\n    B = torch.rand(N, N)\n    B = (B + B.T) / 2  # Ensure symmetry\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs needed for this model.\n\n    Returns:\n        list: Empty list.\n    \"\"\"\n    return []", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 13, "problem_name": "13_Matmul_for_symmetric_matrices.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B) with A and B being symmetric matrices.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of two symmetric matrices.\n\n        Args:\n            A (torch.Tensor): Input matrix A, shape (N, N), symmetric.\n            B (torch.Tensor): Input matrix B, shape (N, N), symmetric.\n\n        Returns:\n            torch.Tensor: Output matrix C, shape (N, N).\n        \"\"\"\n        return torch.matmul(A, B)\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates a pair of random symmetric matrices for testing.\n\n    Returns:\n        list: List containing two symmetric tensors A and B.\n    \"\"\"\n    A = torch.rand(N, N)\n    A = (A + A.T) / 2  # Ensure symmetry\n    B = torch.rand(N, N)\n    B = (B + B.T) / 2  # Ensure symmetry\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs needed for this model.\n\n    Returns:\n        list: Empty list.\n    \"\"\"\n    return []"}}
{"task_id": "L1_14", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs matrix multiplication (C = A * B) for upper triangular matrices.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication for upper triangular matrices.\n\n        Args:\n            A (torch.Tensor): Upper triangular matrix of shape (N, N).\n            B (torch.Tensor): Upper triangular matrix of shape (N, N).\n\n        Returns:\n            torch.Tensor: The product of A and B, also an upper triangular matrix of shape (N, N).\n        \"\"\"\n        return torch.triu(torch.matmul(A, B))\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates upper triangular matrices for testing.\n\n    Returns:\n        list: A list containing two upper triangular matrices of shape (N, N).\n    \"\"\"\n    A = torch.triu(torch.rand(N, N))\n    B = torch.triu(torch.rand(N, N))\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs are needed for this model.\n\n    Returns:\n        list: An empty list.\n    \"\"\"\n    return []", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs matrix multiplication (C = A * B) for upper triangular matrices.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication for upper triangular matrices.\n\n        Args:\n            A (torch.Tensor): Upper triangular matrix of shape (N, N).\n            B (torch.Tensor): Upper triangular matrix of shape (N, N).\n\n        Returns:\n            torch.Tensor: The product of A and B, also an upper triangular matrix of shape (N, N).\n        \"\"\"\n        return torch.triu(torch.matmul(A, B))\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates upper triangular matrices for testing.\n\n    Returns:\n        list: A list containing two upper triangular matrices of shape (N, N).\n    \"\"\"\n    A = torch.triu(torch.rand(N, N))\n    B = torch.triu(torch.rand(N, N))\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs are needed for this model.\n\n    Returns:\n        list: An empty list.\n    \"\"\"\n    return []", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 14, "problem_name": "14_Matmul_for_upper_triangular_matrices.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs matrix multiplication (C = A * B) for upper triangular matrices.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication for upper triangular matrices.\n\n        Args:\n            A (torch.Tensor): Upper triangular matrix of shape (N, N).\n            B (torch.Tensor): Upper triangular matrix of shape (N, N).\n\n        Returns:\n            torch.Tensor: The product of A and B, also an upper triangular matrix of shape (N, N).\n        \"\"\"\n        return torch.triu(torch.matmul(A, B))\n\nN = 4096\n\ndef get_inputs():\n    \"\"\"\n    Generates upper triangular matrices for testing.\n\n    Returns:\n        list: A list containing two upper triangular matrices of shape (N, N).\n    \"\"\"\n    A = torch.triu(torch.rand(N, N))\n    B = torch.triu(torch.rand(N, N))\n    return [A, B]\n\ndef get_init_inputs():\n    \"\"\"\n    No specific initialization inputs are needed for this model.\n\n    Returns:\n        list: An empty list.\n    \"\"\"\n    return []"}}
{"task_id": "L1_15", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication (C = A * B) where A and B are lower triangular matrices. \n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of lower triangular matrices A and B.\n\n        Args:\n            A (torch.Tensor): Lower triangular matrix of shape (N, N).\n            B (torch.Tensor): Lower triangular matrix of shape (N, N).\n\n        Returns:\n            torch.Tensor: The result of matrix multiplication C of shape (N, N).\n        \"\"\"\n        return torch.tril(torch.matmul(A, B))\n\nM = 4096\n\ndef get_inputs():\n    A = torch.rand(M, M)\n    B = torch.rand(M, M)\n    A = torch.tril(A)\n    B = torch.tril(B)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication (C = A * B) where A and B are lower triangular matrices. \n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of lower triangular matrices A and B.\n\n        Args:\n            A (torch.Tensor): Lower triangular matrix of shape (N, N).\n            B (torch.Tensor): Lower triangular matrix of shape (N, N).\n\n        Returns:\n            torch.Tensor: The result of matrix multiplication C of shape (N, N).\n        \"\"\"\n        return torch.tril(torch.matmul(A, B))\n\nM = 4096\n\ndef get_inputs():\n    A = torch.rand(M, M)\n    B = torch.rand(M, M)\n    A = torch.tril(A)\n    B = torch.tril(B)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 15, "problem_name": "15_Matmul_for_lower_triangular_matrices.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication (C = A * B) where A and B are lower triangular matrices. \n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs matrix multiplication of lower triangular matrices A and B.\n\n        Args:\n            A (torch.Tensor): Lower triangular matrix of shape (N, N).\n            B (torch.Tensor): Lower triangular matrix of shape (N, N).\n\n        Returns:\n            torch.Tensor: The result of matrix multiplication C of shape (N, N).\n        \"\"\"\n        return torch.tril(torch.matmul(A, B))\n\nM = 4096\n\ndef get_inputs():\n    A = torch.rand(M, M)\n    B = torch.rand(M, M)\n    A = torch.tril(A)\n    B = torch.tril(B)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_16", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A.T, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(K, M)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A.T, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(K, M)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 16, "problem_name": "16_Matmul_with_transposed_A.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A.T, B)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(K, M)\n    B = torch.rand(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_17", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(N, K)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(N, K)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 17, "problem_name": "17_Matmul_with_transposed_B.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(M, K)\n    B = torch.rand(N, K)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_18", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A.T, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(K, M)\n    B = torch.rand(N, K)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A.T, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(K, M)\n    B = torch.rand(N, K)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 18, "problem_name": "18_Matmul_with_transposed_both.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a single matrix multiplication (C = A * B)\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        return torch.matmul(A.T, B.T)\n\nM = 1024 * 2\nK = 4096 * 2\nN = 2048 * 2\n\ndef get_inputs():\n    A = torch.rand(K, M)\n    B = torch.rand(N, K)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_19", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a ReLU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies ReLU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with ReLU applied, same shape as input.\n        \"\"\"\n        return torch.relu(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a ReLU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies ReLU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with ReLU applied, same shape as input.\n        \"\"\"\n        return torch.relu(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 19, "problem_name": "19_ReLU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a ReLU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies ReLU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with ReLU applied, same shape as input.\n        \"\"\"\n        return torch.relu(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_20", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a LeakyReLU activation.\n    \"\"\"\n    def __init__(self, negative_slope: float = 0.01):\n        \"\"\"\n        Initializes the LeakyReLU module.\n\n        Args:\n            negative_slope (float, optional): The negative slope of the activation function. Defaults to 0.01.\n        \"\"\"\n        super(Model, self).__init__()\n        self.negative_slope = negative_slope\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies LeakyReLU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with LeakyReLU applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.leaky_relu(x, negative_slope=self.negative_slope)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a LeakyReLU activation.\n    \"\"\"\n    def __init__(self, negative_slope: float = 0.01):\n        \"\"\"\n        Initializes the LeakyReLU module.\n\n        Args:\n            negative_slope (float, optional): The negative slope of the activation function. Defaults to 0.01.\n        \"\"\"\n        super(Model, self).__init__()\n        self.negative_slope = negative_slope\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies LeakyReLU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with LeakyReLU applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.leaky_relu(x, negative_slope=self.negative_slope)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 20, "problem_name": "20_LeakyReLU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a LeakyReLU activation.\n    \"\"\"\n    def __init__(self, negative_slope: float = 0.01):\n        \"\"\"\n        Initializes the LeakyReLU module.\n\n        Args:\n            negative_slope (float, optional): The negative slope of the activation function. Defaults to 0.01.\n        \"\"\"\n        super(Model, self).__init__()\n        self.negative_slope = negative_slope\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies LeakyReLU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with LeakyReLU applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.leaky_relu(x, negative_slope=self.negative_slope)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_21", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Sigmoid activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Sigmoid activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Sigmoid applied, same shape as input.\n        \"\"\"\n        return torch.sigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Sigmoid activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Sigmoid activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Sigmoid applied, same shape as input.\n        \"\"\"\n        return torch.sigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 21, "problem_name": "21_Sigmoid.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Sigmoid activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Sigmoid activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Sigmoid applied, same shape as input.\n        \"\"\"\n        return torch.sigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_22", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Tanh activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Tanh activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Tanh applied, same shape as input.\n        \"\"\"\n        return torch.tanh(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Tanh activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Tanh activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Tanh applied, same shape as input.\n        \"\"\"\n        return torch.tanh(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 22, "problem_name": "22_Tanh.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Tanh activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Tanh activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Tanh applied, same shape as input.\n        \"\"\"\n        return torch.tanh(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_23", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softmax activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softmax activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features).\n\n        Returns:\n            torch.Tensor: Output tensor with Softmax applied, same shape as input.\n        \"\"\"\n        return torch.softmax(x, dim=1)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softmax activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softmax activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features).\n\n        Returns:\n            torch.Tensor: Output tensor with Softmax applied, same shape as input.\n        \"\"\"\n        return torch.softmax(x, dim=1)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 23, "problem_name": "23_Softmax.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softmax activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softmax activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features).\n\n        Returns:\n            torch.Tensor: Output tensor with Softmax applied, same shape as input.\n        \"\"\"\n        return torch.softmax(x, dim=1)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_24", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a LogSoftmax activation.\n    \"\"\"\n    def __init__(self, dim: int = 1):\n        super(Model, self).__init__()\n        self.dim = dim\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies LogSoftmax activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, dim).\n\n        Returns:\n            torch.Tensor: Output tensor with LogSoftmax applied, same shape as input.\n        \"\"\"\n        return torch.log_softmax(x, dim=self.dim)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a LogSoftmax activation.\n    \"\"\"\n    def __init__(self, dim: int = 1):\n        super(Model, self).__init__()\n        self.dim = dim\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies LogSoftmax activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, dim).\n\n        Returns:\n            torch.Tensor: Output tensor with LogSoftmax applied, same shape as input.\n        \"\"\"\n        return torch.log_softmax(x, dim=self.dim)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 24, "problem_name": "24_LogSoftmax.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a LogSoftmax activation.\n    \"\"\"\n    def __init__(self, dim: int = 1):\n        super(Model, self).__init__()\n        self.dim = dim\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies LogSoftmax activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, dim).\n\n        Returns:\n            torch.Tensor: Output tensor with LogSoftmax applied, same shape as input.\n        \"\"\"\n        return torch.log_softmax(x, dim=self.dim)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_25", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Swish activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Swish activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Swish applied, same shape as input.\n        \"\"\"\n        return x * torch.sigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Swish activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Swish activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Swish applied, same shape as input.\n        \"\"\"\n        return x * torch.sigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 25, "problem_name": "25_Swish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Swish activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Swish activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Swish applied, same shape as input.\n        \"\"\"\n        return x * torch.sigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_26", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GELU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies GELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with GELU applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.gelu(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GELU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies GELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with GELU applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.gelu(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 26, "problem_name": "26_GELU_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GELU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies GELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with GELU applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.gelu(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_27", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a SELU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies SELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with SELU applied, same shape as input.\n        \"\"\"\n        return torch.selu(x)\n    \nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a SELU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies SELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with SELU applied, same shape as input.\n        \"\"\"\n        return torch.selu(x)\n    \nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 27, "problem_name": "27_SELU_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a SELU activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies SELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with SELU applied, same shape as input.\n        \"\"\"\n        return torch.selu(x)\n    \nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_28", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a HardSigmoid activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies HardSigmoid activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with HardSigmoid applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.hardsigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a HardSigmoid activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies HardSigmoid activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with HardSigmoid applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.hardsigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 28, "problem_name": "28_HardSigmoid.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a HardSigmoid activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies HardSigmoid activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with HardSigmoid applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.hardsigmoid(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_29", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softplus activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softplus activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Softplus applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.softplus(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softplus activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softplus activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Softplus applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.softplus(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 29, "problem_name": "29_Softplus.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softplus activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softplus activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Softplus applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.softplus(x)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_30", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softsign activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softsign activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Softsign applied, same shape as input.\n        \"\"\"\n        return x / (1 + torch.abs(x))\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softsign activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softsign activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Softsign applied, same shape as input.\n        \"\"\"\n        return x / (1 + torch.abs(x))\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 30, "problem_name": "30_Softsign.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Softsign activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Softsign activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Softsign applied, same shape as input.\n        \"\"\"\n        return x / (1 + torch.abs(x))\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_31", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs an ELU activation.\n    \"\"\"\n    def __init__(self, alpha: float = 1.0):\n        \"\"\"\n        Initializes the ELU model.\n\n        Args:\n            alpha (float, optional): The alpha parameter for the ELU function. Defaults to 1.0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.alpha = alpha\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies ELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with ELU applied, same shape as input.\n        \"\"\"\n        return F.elu(x, alpha=self.alpha)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return [1.0]  # Provide alpha value for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs an ELU activation.\n    \"\"\"\n    def __init__(self, alpha: float = 1.0):\n        \"\"\"\n        Initializes the ELU model.\n\n        Args:\n            alpha (float, optional): The alpha parameter for the ELU function. Defaults to 1.0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.alpha = alpha\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies ELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with ELU applied, same shape as input.\n        \"\"\"\n        return F.elu(x, alpha=self.alpha)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return [1.0]  # Provide alpha value for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 31, "problem_name": "31_ELU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs an ELU activation.\n    \"\"\"\n    def __init__(self, alpha: float = 1.0):\n        \"\"\"\n        Initializes the ELU model.\n\n        Args:\n            alpha (float, optional): The alpha parameter for the ELU function. Defaults to 1.0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.alpha = alpha\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies ELU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with ELU applied, same shape as input.\n        \"\"\"\n        return F.elu(x, alpha=self.alpha)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return [1.0]  # Provide alpha value for initialization"}}
{"task_id": "L1_32", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a HardTanh activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies HardTanh activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with HardTanh applied, same shape as input.\n        \"\"\"\n        return F.hardtanh(x, min_val=-1., max_val=1.)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a HardTanh activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies HardTanh activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with HardTanh applied, same shape as input.\n        \"\"\"\n        return F.hardtanh(x, min_val=-1., max_val=1.)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 32, "problem_name": "32_HardTanh.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a HardTanh activation.\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies HardTanh activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with HardTanh applied, same shape as input.\n        \"\"\"\n        return F.hardtanh(x, min_val=-1., max_val=1.)\n\nbatch_size = 4096\ndim = 393216\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed"}}
{"task_id": "L1_33", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Batch Normalization.\n    \"\"\"\n    def __init__(self, num_features: int):\n        \"\"\"\n        Initializes the BatchNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n        \"\"\"\n        super(Model, self).__init__()\n        self.bn = nn.BatchNorm2d(num_features=num_features)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Batch Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with Batch Normalization applied, same shape as input.\n        \"\"\"\n        return self.bn(x)\n\nbatch_size = 64\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Batch Normalization.\n    \"\"\"\n    def __init__(self, num_features: int):\n        \"\"\"\n        Initializes the BatchNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n        \"\"\"\n        super(Model, self).__init__()\n        self.bn = nn.BatchNorm2d(num_features=num_features)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Batch Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with Batch Normalization applied, same shape as input.\n        \"\"\"\n        return self.bn(x)\n\nbatch_size = 64\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 33, "problem_name": "33_BatchNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Batch Normalization.\n    \"\"\"\n    def __init__(self, num_features: int):\n        \"\"\"\n        Initializes the BatchNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n        \"\"\"\n        super(Model, self).__init__()\n        self.bn = nn.BatchNorm2d(num_features=num_features)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Batch Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with Batch Normalization applied, same shape as input.\n        \"\"\"\n        return self.bn(x)\n\nbatch_size = 64\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]"}}
{"task_id": "L1_34", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Instance Normalization.\n    \"\"\"\n    def __init__(self, num_features: int):\n        \"\"\"\n        Initializes the InstanceNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n        \"\"\"\n        super(Model, self).__init__()\n        self.inorm = nn.InstanceNorm2d(num_features=num_features)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Instance Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Instance Normalization applied, same shape as input.\n        \"\"\"\n        return self.inorm(x)\n\nbatch_size = 112  # heavier workload\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Instance Normalization.\n    \"\"\"\n    def __init__(self, num_features: int):\n        \"\"\"\n        Initializes the InstanceNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n        \"\"\"\n        super(Model, self).__init__()\n        self.inorm = nn.InstanceNorm2d(num_features=num_features)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Instance Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Instance Normalization applied, same shape as input.\n        \"\"\"\n        return self.inorm(x)\n\nbatch_size = 112  # heavier workload\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 34, "problem_name": "34_InstanceNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Instance Normalization.\n    \"\"\"\n    def __init__(self, num_features: int):\n        \"\"\"\n        Initializes the InstanceNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n        \"\"\"\n        super(Model, self).__init__()\n        self.inorm = nn.InstanceNorm2d(num_features=num_features)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Instance Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Instance Normalization applied, same shape as input.\n        \"\"\"\n        return self.inorm(x)\n\nbatch_size = 112  # heavier workload\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]"}}
{"task_id": "L1_35", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Group Normalization.\n    \"\"\"\n    def __init__(self, num_features: int, num_groups: int):\n        \"\"\"\n        Initializes the GroupNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n            num_groups (int): Number of groups to divide the channels into.\n        \"\"\"\n        super(Model, self).__init__()\n        self.gn = nn.GroupNorm(num_groups=num_groups, num_channels=num_features)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Group Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with Group Normalization applied, same shape as input.\n        \"\"\"\n        return self.gn(x)\n\nbatch_size = 112  # scaled up\nfeatures = 64\nnum_groups = 8\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features, num_groups] # num_features", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Group Normalization.\n    \"\"\"\n    def __init__(self, num_features: int, num_groups: int):\n        \"\"\"\n        Initializes the GroupNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n            num_groups (int): Number of groups to divide the channels into.\n        \"\"\"\n        super(Model, self).__init__()\n        self.gn = nn.GroupNorm(num_groups=num_groups, num_channels=num_features)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Group Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with Group Normalization applied, same shape as input.\n        \"\"\"\n        return self.gn(x)\n\nbatch_size = 112  # scaled up\nfeatures = 64\nnum_groups = 8\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features, num_groups] # num_features", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 35, "problem_name": "35_GroupNorm_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Group Normalization.\n    \"\"\"\n    def __init__(self, num_features: int, num_groups: int):\n        \"\"\"\n        Initializes the GroupNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n            num_groups (int): Number of groups to divide the channels into.\n        \"\"\"\n        super(Model, self).__init__()\n        self.gn = nn.GroupNorm(num_groups=num_groups, num_channels=num_features)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Group Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with Group Normalization applied, same shape as input.\n        \"\"\"\n        return self.gn(x)\n\nbatch_size = 112  # scaled up\nfeatures = 64\nnum_groups = 8\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features, num_groups] # num_features"}}
{"task_id": "L1_36", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs RMS Normalization.\n    \"\"\"\n    def __init__(self, num_features: int, eps: float = 1e-5):\n        \"\"\"\n        Initializes the RMSNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n            eps (float, optional): A small value added to the denominator to avoid division by zero. Defaults to 1e-5.\n        \"\"\"\n        super(Model, self).__init__()\n        self.num_features = num_features\n        self.eps = eps\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies RMS Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with RMS Normalization applied, same shape as input.\n        \"\"\"\n        # Calculate the RMS along the feature dimension\n        rms = torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.eps)\n\n        # Normalize the input by dividing by the RMS\n        return x / rms\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs RMS Normalization.\n    \"\"\"\n    def __init__(self, num_features: int, eps: float = 1e-5):\n        \"\"\"\n        Initializes the RMSNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n            eps (float, optional): A small value added to the denominator to avoid division by zero. Defaults to 1e-5.\n        \"\"\"\n        super(Model, self).__init__()\n        self.num_features = num_features\n        self.eps = eps\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies RMS Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with RMS Normalization applied, same shape as input.\n        \"\"\"\n        # Calculate the RMS along the feature dimension\n        rms = torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.eps)\n\n        # Normalize the input by dividing by the RMS\n        return x / rms\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 36, "problem_name": "36_RMSNorm_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs RMS Normalization.\n    \"\"\"\n    def __init__(self, num_features: int, eps: float = 1e-5):\n        \"\"\"\n        Initializes the RMSNorm layer.\n\n        Args:\n            num_features (int): Number of features in the input tensor.\n            eps (float, optional): A small value added to the denominator to avoid division by zero. Defaults to 1e-5.\n        \"\"\"\n        super(Model, self).__init__()\n        self.num_features = num_features\n        self.eps = eps\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies RMS Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, *).\n\n        Returns:\n            torch.Tensor: Output tensor with RMS Normalization applied, same shape as input.\n        \"\"\"\n        # Calculate the RMS along the feature dimension\n        rms = torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.eps)\n\n        # Normalize the input by dividing by the RMS\n        return x / rms\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]"}}
{"task_id": "L1_37", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Frobenius norm normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the Frobenius norm normalization layer.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Frobenius norm normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of arbitrary shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Frobenius norm normalization applied, same shape as input.\n        \"\"\"\n        norm = torch.norm(x, p='fro')\n        return x / norm\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return []", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Frobenius norm normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the Frobenius norm normalization layer.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Frobenius norm normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of arbitrary shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Frobenius norm normalization applied, same shape as input.\n        \"\"\"\n        norm = torch.norm(x, p='fro')\n        return x / norm\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return []", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 37, "problem_name": "37_FrobeniusNorm_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Frobenius norm normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the Frobenius norm normalization layer.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Frobenius norm normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of arbitrary shape.\n\n        Returns:\n            torch.Tensor: Output tensor with Frobenius norm normalization applied, same shape as input.\n        \"\"\"\n        norm = torch.norm(x, p='fro')\n        return x / norm\n\nbatch_size = 112\nfeatures = 64\ndim1 = 512\ndim2 = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return []"}}
{"task_id": "L1_38", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies L1 normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            torch.Tensor: Output tensor with L1 normalization applied, same shape as input.\n        \"\"\"\n        return x / torch.mean(torch.abs(x), dim=1, keepdim=True)\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies L1 normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            torch.Tensor: Output tensor with L1 normalization applied, same shape as input.\n        \"\"\"\n        return x / torch.mean(torch.abs(x), dim=1, keepdim=True)\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 38, "problem_name": "38_L1Norm_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies L1 normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            torch.Tensor: Output tensor with L1 normalization applied, same shape as input.\n        \"\"\"\n        return x / torch.mean(torch.abs(x), dim=1, keepdim=True)\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []"}}
{"task_id": "L1_39", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies L2 normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (*, dim, *).\n\n        Returns:\n            torch.Tensor: Output tensor with L2 normalization applied, same shape as input.\n        \"\"\"\n        return x / torch.norm(x, p=2, dim=1, keepdim=True)\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies L2 normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (*, dim, *).\n\n        Returns:\n            torch.Tensor: Output tensor with L2 normalization applied, same shape as input.\n        \"\"\"\n        return x / torch.norm(x, p=2, dim=1, keepdim=True)\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 39, "problem_name": "39_L2Norm_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(Model, self).__init__()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies L2 normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (*, dim, *).\n\n        Returns:\n            torch.Tensor: Output tensor with L2 normalization applied, same shape as input.\n        \"\"\"\n        return x / torch.norm(x, p=2, dim=1, keepdim=True)\n\nbatch_size = 32768\n# choose dim so total <2^31\ndim = 65535\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []"}}
{"task_id": "L1_40", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Layer Normalization.\n    \"\"\"\n    def __init__(self, normalized_shape: tuple):\n        \"\"\"\n        Initializes the LayerNorm layer.\n\n        Args:\n            normalized_shape (tuple): Shape of the input tensor to be normalized.\n        \"\"\"\n        super(Model, self).__init__()\n        self.ln = nn.LayerNorm(normalized_shape=normalized_shape)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Layer Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (*, normalized_shape).\n\n        Returns:\n            torch.Tensor: Output tensor with Layer Normalization applied, same shape as input.\n        \"\"\"\n        return self.ln(x)\n\nbatch_size = 16\nfeatures = 64\ndim1 = 256\ndim2 = 256\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [(features, dim1, dim2)]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Layer Normalization.\n    \"\"\"\n    def __init__(self, normalized_shape: tuple):\n        \"\"\"\n        Initializes the LayerNorm layer.\n\n        Args:\n            normalized_shape (tuple): Shape of the input tensor to be normalized.\n        \"\"\"\n        super(Model, self).__init__()\n        self.ln = nn.LayerNorm(normalized_shape=normalized_shape)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Layer Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (*, normalized_shape).\n\n        Returns:\n            torch.Tensor: Output tensor with Layer Normalization applied, same shape as input.\n        \"\"\"\n        return self.ln(x)\n\nbatch_size = 16\nfeatures = 64\ndim1 = 256\ndim2 = 256\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [(features, dim1, dim2)]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 40, "problem_name": "40_LayerNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Layer Normalization.\n    \"\"\"\n    def __init__(self, normalized_shape: tuple):\n        \"\"\"\n        Initializes the LayerNorm layer.\n\n        Args:\n            normalized_shape (tuple): Shape of the input tensor to be normalized.\n        \"\"\"\n        super(Model, self).__init__()\n        self.ln = nn.LayerNorm(normalized_shape=normalized_shape)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Layer Normalization to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (*, normalized_shape).\n\n        Returns:\n            torch.Tensor: Output tensor with Layer Normalization applied, same shape as input.\n        \"\"\"\n        return self.ln(x)\n\nbatch_size = 16\nfeatures = 64\ndim1 = 256\ndim2 = 256\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [(features, dim1, dim2)]"}}
{"task_id": "L1_41", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 1D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, sequence_length).\n\n        Returns:\n            torch.Tensor: Output tensor with Max Pooling 1D applied, shape (batch_size, num_features, output_sequence_length).\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 64\nfeatures = 192\nsequence_length = 65536\n\nkernel_size = 8\nstride      = 1\npadding     = 4\ndilation    = 3            \n\nreturn_indices = False\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, sequence_length)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation, return_indices]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 1D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, sequence_length).\n\n        Returns:\n            torch.Tensor: Output tensor with Max Pooling 1D applied, shape (batch_size, num_features, output_sequence_length).\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 64\nfeatures = 192\nsequence_length = 65536\n\nkernel_size = 8\nstride      = 1\npadding     = 4\ndilation    = 3            \n\nreturn_indices = False\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, sequence_length)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation, return_indices]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 41, "problem_name": "41_Max_Pooling_1D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 1D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, num_features, sequence_length).\n\n        Returns:\n            torch.Tensor: Output tensor with Max Pooling 1D applied, shape (batch_size, num_features, output_sequence_length).\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 64\nfeatures = 192\nsequence_length = 65536\n\nkernel_size = 8\nstride      = 1\npadding     = 4\ndilation    = 3            \n\nreturn_indices = False\n\ndef get_inputs():\n    x = torch.rand(batch_size, features, sequence_length)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation, return_indices]"}}
{"task_id": "L1_42", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 2D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int, padding: int, dilation: int):\n        \"\"\"\n        Initializes the Max Pooling 2D layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int): Stride of the pooling window.\n            padding (int): Padding to be applied before pooling.\n            dilation (int): Spacing between kernel elements.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 2D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor after Max Pooling 2D, shape (batch_size, channels, pooled_height, pooled_width).\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 32\nchannels = 64\nheight = 512\nwidth = 512\nkernel_size = 4\nstride = 1\npadding = 1\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 2D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int, padding: int, dilation: int):\n        \"\"\"\n        Initializes the Max Pooling 2D layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int): Stride of the pooling window.\n            padding (int): Padding to be applied before pooling.\n            dilation (int): Spacing between kernel elements.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 2D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor after Max Pooling 2D, shape (batch_size, channels, pooled_height, pooled_width).\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 32\nchannels = 64\nheight = 512\nwidth = 512\nkernel_size = 4\nstride = 1\npadding = 1\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 42, "problem_name": "42_Max_Pooling_2D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 2D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int, padding: int, dilation: int):\n        \"\"\"\n        Initializes the Max Pooling 2D layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int): Stride of the pooling window.\n            padding (int): Padding to be applied before pooling.\n            dilation (int): Spacing between kernel elements.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 2D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor after Max Pooling 2D, shape (batch_size, channels, pooled_height, pooled_width).\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 32\nchannels = 64\nheight = 512\nwidth = 512\nkernel_size = 4\nstride = 1\npadding = 1\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]\n"}}
{"task_id": "L1_43", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 3D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False, ceil_mode: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 3D layer.\n\n        Args:\n            kernel_size (int): Size of the kernel for the max pooling operation.\n            stride (int, optional): Stride of the pooling operation. Defaults to None, which means stride is equal to kernel_size.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return indices of the maximum values. Defaults to False.\n            ceil_mode (bool, optional): When True, the output size is ceil(input_size / stride) instead of floor. Defaults to False.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool3d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, return_indices=return_indices, ceil_mode=ceil_mode)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 3D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, dim1, dim2, dim3).\n\n        Returns:\n            torch.Tensor: Output tensor with Max Pooling 3D applied.\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 16\nchannels = 32\ndim1 = 128\ndim2 = 128\ndim3 = 128\nkernel_size = 3\nstride = 2\npadding = 1\ndilation = 3\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, dim1, dim2, dim3)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 3D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False, ceil_mode: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 3D layer.\n\n        Args:\n            kernel_size (int): Size of the kernel for the max pooling operation.\n            stride (int, optional): Stride of the pooling operation. Defaults to None, which means stride is equal to kernel_size.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return indices of the maximum values. Defaults to False.\n            ceil_mode (bool, optional): When True, the output size is ceil(input_size / stride) instead of floor. Defaults to False.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool3d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, return_indices=return_indices, ceil_mode=ceil_mode)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 3D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, dim1, dim2, dim3).\n\n        Returns:\n            torch.Tensor: Output tensor with Max Pooling 3D applied.\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 16\nchannels = 32\ndim1 = 128\ndim2 = 128\ndim3 = 128\nkernel_size = 3\nstride = 2\npadding = 1\ndilation = 3\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, dim1, dim2, dim3)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 43, "problem_name": "43_Max_Pooling_3D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 3D.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False, ceil_mode: bool = False):\n        \"\"\"\n        Initializes the Max Pooling 3D layer.\n\n        Args:\n            kernel_size (int): Size of the kernel for the max pooling operation.\n            stride (int, optional): Stride of the pooling operation. Defaults to None, which means stride is equal to kernel_size.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return indices of the maximum values. Defaults to False.\n            ceil_mode (bool, optional): When True, the output size is ceil(input_size / stride) instead of floor. Defaults to False.\n        \"\"\"\n        super(Model, self).__init__()\n        self.maxpool = nn.MaxPool3d(kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, return_indices=return_indices, ceil_mode=ceil_mode)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max Pooling 3D to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, dim1, dim2, dim3).\n\n        Returns:\n            torch.Tensor: Output tensor with Max Pooling 3D applied.\n        \"\"\"\n        return self.maxpool(x)\n\nbatch_size = 16\nchannels = 32\ndim1 = 128\ndim2 = 128\ndim3 = 128\nkernel_size = 3\nstride = 2\npadding = 1\ndilation = 3\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, dim1, dim2, dim3)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]"}}
{"task_id": "L1_44", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 1D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = 1, padding: int = 0):\n        \"\"\"\n        Initializes the 1D Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to 1.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies 1D Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, input_length).\n\n        Returns:\n            torch.Tensor: Output tensor with 1D Average Pooling applied, shape (batch_size, in_channels, output_length).\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 64\nin_channels = 128\ninput_length = 65536\nkernel_size = 8\nstride = 1\npadding = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, input_length)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 1D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = 1, padding: int = 0):\n        \"\"\"\n        Initializes the 1D Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to 1.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies 1D Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, input_length).\n\n        Returns:\n            torch.Tensor: Output tensor with 1D Average Pooling applied, shape (batch_size, in_channels, output_length).\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 64\nin_channels = 128\ninput_length = 65536\nkernel_size = 8\nstride = 1\npadding = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, input_length)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 44, "problem_name": "44_Average_Pooling_1D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 1D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = 1, padding: int = 0):\n        \"\"\"\n        Initializes the 1D Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to 1.\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies 1D Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, input_length).\n\n        Returns:\n            torch.Tensor: Output tensor with 1D Average Pooling applied, shape (batch_size, in_channels, output_length).\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 64\nin_channels = 128\ninput_length = 65536\nkernel_size = 8\nstride = 1\npadding = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, input_length)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding]"}}
{"task_id": "L1_45", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies 2D Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Average Pooling applied.\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 16\nchannels = 64\nheight = 2048\nwidth = 2048\nkernel_size = 11\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies 2D Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Average Pooling applied.\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 16\nchannels = 64\nheight = 2048\nwidth = 2048\nkernel_size = 11\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 45, "problem_name": "45_Average_Pooling_2D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies 2D Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Average Pooling applied.\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 16\nchannels = 64\nheight = 2048\nwidth = 2048\nkernel_size = 11\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size]"}}
{"task_id": "L1_46", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 3D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the kernel to apply pooling.\n            stride (int, optional): Stride of the pooling operation. Defaults to None, which uses the kernel size.\n            padding (int, optional): Padding to apply before pooling. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool3d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Average Pooling applied, shape depends on kernel_size, stride and padding.\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 16\nchannels = 32\ndepth = 128\nheight = 128\nwidth = 256\nkernel_size = 3\nstride = 2\npadding = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 3D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the kernel to apply pooling.\n            stride (int, optional): Stride of the pooling operation. Defaults to None, which uses the kernel size.\n            padding (int, optional): Padding to apply before pooling. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool3d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Average Pooling applied, shape depends on kernel_size, stride and padding.\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 16\nchannels = 32\ndepth = 128\nheight = 128\nwidth = 256\nkernel_size = 3\nstride = 2\npadding = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 46, "problem_name": "46_Average_Pooling_3D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs 3D Average Pooling.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the kernel to apply pooling.\n            stride (int, optional): Stride of the pooling operation. Defaults to None, which uses the kernel size.\n            padding (int, optional): Padding to apply before pooling. Defaults to 0.\n        \"\"\"\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool3d(kernel_size=kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Average Pooling to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor with Average Pooling applied, shape depends on kernel_size, stride and padding.\n        \"\"\"\n        return self.avg_pool(x)\n\nbatch_size = 16\nchannels = 32\ndepth = 128\nheight = 128\nwidth = 256\nkernel_size = 3\nstride = 2\npadding = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding]"}}
{"task_id": "L1_47", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs sum reduction over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): Dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies sum reduction over the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            torch.Tensor: Output tensor after sum reduction, shape (..., 1, ...).\n        \"\"\"\n        return torch.sum(x, dim=self.dim, keepdim=True)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\nreduce_dim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [reduce_dim]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs sum reduction over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): Dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies sum reduction over the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            torch.Tensor: Output tensor after sum reduction, shape (..., 1, ...).\n        \"\"\"\n        return torch.sum(x, dim=self.dim, keepdim=True)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\nreduce_dim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [reduce_dim]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 47, "problem_name": "47_Sum_reduction_over_a_dimension.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs sum reduction over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): Dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies sum reduction over the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (..., dim, ...).\n\n        Returns:\n            torch.Tensor: Output tensor after sum reduction, shape (..., 1, ...).\n        \"\"\"\n        return torch.sum(x, dim=self.dim, keepdim=True)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\nreduce_dim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [reduce_dim]"}}
{"task_id": "L1_48", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs mean reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Reduces the input tensor along the specified dimension by taking the mean.\n\n        Args:\n            x (torch.Tensor): Input tensor of arbitrary shape.\n\n        Returns:\n            torch.Tensor: Output tensor with reduced dimension. The shape of the output is the same as the input except for the reduced dimension which is removed.\n        \"\"\"\n        return torch.mean(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs mean reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Reduces the input tensor along the specified dimension by taking the mean.\n\n        Args:\n            x (torch.Tensor): Input tensor of arbitrary shape.\n\n        Returns:\n            torch.Tensor: Output tensor with reduced dimension. The shape of the output is the same as the input except for the reduced dimension which is removed.\n        \"\"\"\n        return torch.mean(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 48, "problem_name": "48_Mean_reduction_over_a_dimension.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs mean reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Reduces the input tensor along the specified dimension by taking the mean.\n\n        Args:\n            x (torch.Tensor): Input tensor of arbitrary shape.\n\n        Returns:\n            torch.Tensor: Output tensor with reduced dimension. The shape of the output is the same as the input except for the reduced dimension which is removed.\n        \"\"\"\n        return torch.mean(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]"}}
{"task_id": "L1_49", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor after Max reduction over the specified dimension.\n        \"\"\"\n        return torch.max(x, dim=self.dim)[0]\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1] # Example, change to desired dimension", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor after Max reduction over the specified dimension.\n        \"\"\"\n        return torch.max(x, dim=self.dim)[0]\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1] # Example, change to desired dimension", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 49, "problem_name": "49_Max_reduction_over_a_dimension.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Max reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies Max reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor after Max reduction over the specified dimension.\n        \"\"\"\n        return torch.max(x, dim=self.dim)[0]\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1] # Example, change to desired dimension"}}
{"task_id": "L1_50", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        return x\n\n# Test code\nbatch_size = 256\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        return x\n\n# Test code\nbatch_size = 256\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 50, "problem_name": "50_conv_standard_2D__square_input__square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        return x\n\n# Test code\nbatch_size = 256\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]"}}
{"task_id": "L1_51", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Argmax over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmax.\n\n        Args:\n            dim (int): The dimension to perform argmax over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies argmax over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor with argmax applied, with the specified dimension removed.\n        \"\"\"\n        return torch.argmax(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Argmax over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmax.\n\n        Args:\n            dim (int): The dimension to perform argmax over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies argmax over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor with argmax applied, with the specified dimension removed.\n        \"\"\"\n        return torch.argmax(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 51, "problem_name": "51_Argmax_over_a_dimension.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs Argmax over a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmax.\n\n        Args:\n            dim (int): The dimension to perform argmax over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies argmax over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor with argmax applied, with the specified dimension removed.\n        \"\"\"\n        return torch.argmax(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]"}}
{"task_id": "L1_52", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that finds the index of the minimum value along a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmin on.\n\n        Args:\n            dim (int): Dimension along which to find the minimum value.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Finds the index of the minimum value along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Tensor containing the indices of the minimum values along the specified dimension.\n        \"\"\"\n        return torch.argmin(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\ndim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [dim]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that finds the index of the minimum value along a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmin on.\n\n        Args:\n            dim (int): Dimension along which to find the minimum value.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Finds the index of the minimum value along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Tensor containing the indices of the minimum values along the specified dimension.\n        \"\"\"\n        return torch.argmin(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\ndim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [dim]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 52, "problem_name": "52_Argmin_over_a_dimension.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that finds the index of the minimum value along a specified dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to perform argmin on.\n\n        Args:\n            dim (int): Dimension along which to find the minimum value.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Finds the index of the minimum value along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Tensor containing the indices of the minimum values along the specified dimension.\n        \"\"\"\n        return torch.argmin(x, dim=self.dim)\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\ndim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [dim]"}}
{"task_id": "L1_53", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs min reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies min reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor after min reduction over the specified dimension.\n        \"\"\"\n        return torch.min(x, dim=self.dim)[0]\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1] # Example, change to desired dimension", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs min reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies min reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor after min reduction over the specified dimension.\n        \"\"\"\n        return torch.min(x, dim=self.dim)[0]\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1] # Example, change to desired dimension", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 53, "problem_name": "53_Min_reduction_over_a_dimension.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs min reduction over a specific dimension.\n    \"\"\"\n    def __init__(self, dim: int):\n        \"\"\"\n        Initializes the model with the dimension to reduce over.\n\n        Args:\n            dim (int): The dimension to reduce over.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies min reduction over the specified dimension to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor after min reduction over the specified dimension.\n        \"\"\"\n        return torch.min(x, dim=self.dim)[0]\n\nbatch_size = 128\ndim1 = 4096\ndim2 = 4095\n\ndef get_inputs():\n    x = torch.rand(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1] # Example, change to desired dimension"}}
{"task_id": "L1_54", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, (kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, width, height).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, width_out, height_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\ndepth = 64\nwidth = 64\nheight = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, width, height)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, (kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, width, height).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, width_out, height_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\ndepth = 64\nwidth = 64\nheight = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, width, height)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 54, "problem_name": "54_conv_standard_3D__square_input__square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, (kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, width, height).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, width_out, height_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\ndepth = 64\nwidth = 64\nheight = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, width, height)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_55", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with an asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, (kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\n# smaller spatial dims\nheight = 512\nwidth = 1024\nin_channels = 64  # increased channels\nout_channels = 128\nkernel_size = 3\n# asymmetric input: make width considerably larger than height\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with an asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, (kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\n# smaller spatial dims\nheight = 512\nwidth = 1024\nin_channels = 64  # increased channels\nout_channels = 128\nkernel_size = 3\n# asymmetric input: make width considerably larger than height\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 55, "problem_name": "55_conv_standard_2D__asymmetric_input__square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with an asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, (kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\n# smaller spatial dims\nheight = 512\nwidth = 1024\nin_channels = 64  # increased channels\nout_channels = 128\nkernel_size = 3\n# asymmetric input: make width considerably larger than height\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_56", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with asymmetric input and kernel sizes.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of two integers representing the height and width of the convolution kernel.\n        stride (tuple, optional): Tuple of two integers representing the stride in the height and width dimensions. Defaults to (1, 1).\n        padding (tuple, optional): Tuple of two integers representing the padding in the height and width dimensions. Defaults to (0, 0).\n        dilation (tuple, optional): Tuple of two integers representing the dilation in the height and width dimensions. Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 64\nout_channels = 128\nkernel_size = (5, 7)\nheight = 512\nwidth = 256\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with asymmetric input and kernel sizes.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of two integers representing the height and width of the convolution kernel.\n        stride (tuple, optional): Tuple of two integers representing the stride in the height and width dimensions. Defaults to (1, 1).\n        padding (tuple, optional): Tuple of two integers representing the padding in the height and width dimensions. Defaults to (0, 0).\n        dilation (tuple, optional): Tuple of two integers representing the dilation in the height and width dimensions. Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 64\nout_channels = 128\nkernel_size = (5, 7)\nheight = 512\nwidth = 256\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 56, "problem_name": "56_conv_standard_2D__asymmetric_input__asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with asymmetric input and kernel sizes.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of two integers representing the height and width of the convolution kernel.\n        stride (tuple, optional): Tuple of two integers representing the stride in the height and width dimensions. Defaults to (1, 1).\n        padding (tuple, optional): Tuple of two integers representing the padding in the height and width dimensions. Defaults to (0, 0).\n        dilation (tuple, optional): Tuple of two integers representing the dilation in the height and width dimensions. Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 64\nout_channels = 128\nkernel_size = (5, 7)\nheight = 512\nwidth = 256\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_57", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 64  # double channels for heavier compute\nout_channels = 64\nkernel_size = 3\n# larger square input\nheight = 1024\nwidth = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 64  # double channels for heavier compute\nout_channels = 64\nkernel_size = 3\n# larger square input\nheight = 1024\nwidth = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 57, "problem_name": "57_conv_transposed_2D__square_input__square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 64  # double channels for heavier compute\nout_channels = 64\nkernel_size = 3\n# larger square input\nheight = 1024\nwidth = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_58", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution operation with asymmetric input and kernel sizes.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of 3 integers representing the kernel size in the form (depth, height, width).\n        stride (tuple, optional): Tuple of 3 integers representing the stride in the form (depth, height, width). Defaults to (1, 1, 1).\n        padding (tuple, optional): Tuple of 3 integers representing the padding in the form (depth, height, width). Defaults to (0, 0, 0).\n        output_padding (tuple, optional): Tuple of 3 integers representing the output padding in the form (depth, height, width). Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth_in, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 16\nkernel_size = (3, 5, 7)  # Asymmetric kernel size\ndepth_in = 16\nheight_in = 32\nwidth_in = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth_in, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution operation with asymmetric input and kernel sizes.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of 3 integers representing the kernel size in the form (depth, height, width).\n        stride (tuple, optional): Tuple of 3 integers representing the stride in the form (depth, height, width). Defaults to (1, 1, 1).\n        padding (tuple, optional): Tuple of 3 integers representing the padding in the form (depth, height, width). Defaults to (0, 0, 0).\n        output_padding (tuple, optional): Tuple of 3 integers representing the output padding in the form (depth, height, width). Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth_in, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 16\nkernel_size = (3, 5, 7)  # Asymmetric kernel size\ndepth_in = 16\nheight_in = 32\nwidth_in = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth_in, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 58, "problem_name": "58_conv_transposed_3D__asymmetric_input__asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution operation with asymmetric input and kernel sizes.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of 3 integers representing the kernel size in the form (depth, height, width).\n        stride (tuple, optional): Tuple of 3 integers representing the stride in the form (depth, height, width). Defaults to (1, 1, 1).\n        padding (tuple, optional): Tuple of 3 integers representing the padding in the form (depth, height, width). Defaults to (0, 0, 0).\n        output_padding (tuple, optional): Tuple of 3 integers representing the output padding in the form (depth, height, width). Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth_in, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 16\nkernel_size = (3, 5, 7)  # Asymmetric kernel size\ndepth_in = 16\nheight_in = 32\nwidth_in = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth_in, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_59", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with an asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel (kernel_size x kernel_size).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, (kernel_size, kernel_size, 1), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width, depth).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out, depth_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\nwidth = 256\nheight = 256\ndepth = 10\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width, depth)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with an asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel (kernel_size x kernel_size).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, (kernel_size, kernel_size, 1), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width, depth).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out, depth_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\nwidth = 256\nheight = 256\ndepth = 10\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width, depth)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 59, "problem_name": "59_conv_standard_3D__asymmetric_input__square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with an asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel (kernel_size x kernel_size).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, (kernel_size, kernel_size, 1), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width, depth).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out, depth_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\nwidth = 256\nheight = 256\ndepth = 10\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width, depth)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_60", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (kernel_width, kernel_height, kernel_depth).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        dilation (int or tuple, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, width, height, depth).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, width_out, height_out, depth_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = (3, 5, 7)  # Asymmetric kernel\nwidth = 64\nheight = 64\ndepth = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, width, height, depth)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (kernel_width, kernel_height, kernel_depth).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        dilation (int or tuple, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, width, height, depth).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, width_out, height_out, depth_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = (3, 5, 7)  # Asymmetric kernel\nwidth = 64\nheight = 64\ndepth = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, width, height, depth)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 60, "problem_name": "60_conv_standard_3D__square_input__asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (kernel_width, kernel_height, kernel_depth).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        dilation (int or tuple, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, width, height, depth).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, width_out, height_out, depth_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = (3, 5, 7)  # Asymmetric kernel\nwidth = 64\nheight = 64\ndepth = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, width, height, depth)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_61", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 48\nout_channels = 48\nkernel_size = 3\ndepth = 64\nheight = 64\nwidth = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 48\nout_channels = 48\nkernel_size = 3\ndepth = 64\nheight = 64\nwidth = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 61, "problem_name": "61_conv_transposed_3D__square_input__square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 48\nout_channels = 48\nkernel_size = 3\ndepth = 64\nheight = 64\nwidth = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_62", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        dilation (int or tuple, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 64\nkernel_size = (5, 9)\nwidth = 512\nheight = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        dilation (int or tuple, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 64\nkernel_size = (5, 9)\nwidth = 512\nheight = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 62, "problem_name": "62_conv_standard_2D__square_input__asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        dilation (int or tuple, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 64\nkernel_size = (5, 9)\nwidth = 512\nheight = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_63", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with a square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, (kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 16\nout_channels = 128\nkernel_size = 3\nwidth = 1024\nheight = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with a square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, (kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 16\nout_channels = 128\nkernel_size = 3\nwidth = 1024\nheight = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 63, "problem_name": "63_conv_standard_2D__square_input__square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with a square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, (kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 16\nout_channels = 128\nkernel_size = 3\nwidth = 1024\nheight = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_64", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 1D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d_transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d_transpose(x)\n\n# Test code\nbatch_size = 64\nin_channels = 128\nout_channels = 128\nkernel_size = 3\n# much larger signal length for heavier workload\nlength = 65536\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 1D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d_transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d_transpose(x)\n\n# Test code\nbatch_size = 64\nin_channels = 128\nout_channels = 128\nkernel_size = 3\n# much larger signal length for heavier workload\nlength = 65536\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 64, "problem_name": "64_conv_transposed_1D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 1D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d_transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d_transpose(x)\n\n# Test code\nbatch_size = 64\nin_channels = 128\nout_channels = 128\nkernel_size = 3\n# much larger signal length for heavier workload\nlength = 65536\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_65", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int or tuple, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 64\nout_channels = 64\nkernel_size = (3, 7)  # larger asymmetric kernel\nwidth = 512\nheight = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int or tuple, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 64\nout_channels = 64\nkernel_size = (3, 7)  # larger asymmetric kernel\nwidth = 512\nheight = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 65, "problem_name": "65_conv_transposed_2D__square_input__asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int or tuple, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 64\nout_channels = 64\nkernel_size = (3, 7)  # larger asymmetric kernel\nwidth = 512\nheight = 512\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_66", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with asymmetric input and kernel sizes.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel in the form (kernel_size_d, kernel_size_h, kernel_size_w).\n        stride (tuple, optional): Stride of the convolution in the form (stride_d, stride_h, stride_w). Defaults to (1, 1, 1).\n        padding (tuple, optional): Padding applied to the input in the form (padding_d, padding_h, padding_w). Defaults to (0, 0, 0).\n        dilation (tuple, optional): Spacing between kernel elements in the form (dilation_d, dilation_h, dilation_w). Defaults to (1, 1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), dilation: tuple = (1, 1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 3\nout_channels = 64\nkernel_size = (3, 5, 7)  # Asymmetric kernel size\ndepth = 16\nheight = 128\nwidth = 128\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with asymmetric input and kernel sizes.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel in the form (kernel_size_d, kernel_size_h, kernel_size_w).\n        stride (tuple, optional): Stride of the convolution in the form (stride_d, stride_h, stride_w). Defaults to (1, 1, 1).\n        padding (tuple, optional): Padding applied to the input in the form (padding_d, padding_h, padding_w). Defaults to (0, 0, 0).\n        dilation (tuple, optional): Spacing between kernel elements in the form (dilation_d, dilation_h, dilation_w). Defaults to (1, 1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), dilation: tuple = (1, 1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 3\nout_channels = 64\nkernel_size = (3, 5, 7)  # Asymmetric kernel size\ndepth = 16\nheight = 128\nwidth = 128\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 66, "problem_name": "66_conv_standard_3D__asymmetric_input__asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 3D convolution operation with asymmetric input and kernel sizes.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel in the form (kernel_size_d, kernel_size_h, kernel_size_w).\n        stride (tuple, optional): Stride of the convolution in the form (stride_d, stride_h, stride_w). Defaults to (1, 1, 1).\n        padding (tuple, optional): Padding applied to the input in the form (padding_d, padding_h, padding_w). Defaults to (0, 0, 0).\n        dilation (tuple, optional): Spacing between kernel elements in the form (dilation_d, dilation_h, dilation_w). Defaults to (1, 1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), dilation: tuple = (1, 1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv3d = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 3\nout_channels = 64\nkernel_size = (3, 5, 7)  # Asymmetric kernel size\ndepth = 16\nheight = 128\nwidth = 128\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_67", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 1D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d(x)\n\n# Test code\nbatch_size = 32\nin_channels = 64\nout_channels = 128\nkernel_size = 3\nlength = 131072\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 1D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d(x)\n\n# Test code\nbatch_size = 32\nin_channels = 64\nout_channels = 128\nkernel_size = 3\nlength = 131072\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 67, "problem_name": "67_conv_standard_1D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 1D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d(x)\n\n# Test code\nbatch_size = 32\nin_channels = 64\nout_channels = 128\nkernel_size = 3\nlength = 131072\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_68", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (kernel_depth, kernel_width, kernel_height), \n                             where kernel_width == kernel_height.\n        stride (tuple, optional): Stride of the convolution. Defaults to (1, 1, 1).\n        padding (tuple, optional): Padding applied to the input. Defaults to (0, 0, 0).\n        output_padding (tuple, optional): Additional size added to one side of the output shape. Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, width, height).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, width_out, height_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_depth = 3\nkernel_width = 5\nkernel_height = 5\ndepth = 64\nwidth = 64\nheight = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, width, height)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, (kernel_depth, kernel_width, kernel_height)]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (kernel_depth, kernel_width, kernel_height), \n                             where kernel_width == kernel_height.\n        stride (tuple, optional): Stride of the convolution. Defaults to (1, 1, 1).\n        padding (tuple, optional): Padding applied to the input. Defaults to (0, 0, 0).\n        output_padding (tuple, optional): Additional size added to one side of the output shape. Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, width, height).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, width_out, height_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_depth = 3\nkernel_width = 5\nkernel_height = 5\ndepth = 64\nwidth = 64\nheight = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, width, height)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, (kernel_depth, kernel_width, kernel_height)]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 68, "problem_name": "68_conv_transposed_3D__square_input__asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (kernel_depth, kernel_width, kernel_height), \n                             where kernel_width == kernel_height.\n        stride (tuple, optional): Stride of the convolution. Defaults to (1, 1, 1).\n        padding (tuple, optional): Padding applied to the input. Defaults to (0, 0, 0).\n        output_padding (tuple, optional): Additional size added to one side of the output shape. Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, width, height).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, width_out, height_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_depth = 3\nkernel_width = 5\nkernel_height = 5\ndepth = 64\nwidth = 64\nheight = 64\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, width, height)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, (kernel_depth, kernel_width, kernel_height)]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_69", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution operation with asymmetric input and kernel size.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of integers representing the kernel size (height, width).\n        stride (tuple, optional): Tuple of integers representing the stride of the convolution. Defaults to (1, 1).\n        padding (tuple, optional): Tuple of integers representing the padding applied to the input. Defaults to (0, 0).\n        output_padding (tuple, optional): Tuple of integers representing the additional size added to one side of the output shape. Defaults to (0, 0).\n        dilation (tuple, optional): Tuple of integers representing the spacing between kernel elements. Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), output_padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nkernel_size = (3, 5)\nheight_in = 128\nwidth_in = 256\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution operation with asymmetric input and kernel size.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of integers representing the kernel size (height, width).\n        stride (tuple, optional): Tuple of integers representing the stride of the convolution. Defaults to (1, 1).\n        padding (tuple, optional): Tuple of integers representing the padding applied to the input. Defaults to (0, 0).\n        output_padding (tuple, optional): Tuple of integers representing the additional size added to one side of the output shape. Defaults to (0, 0).\n        dilation (tuple, optional): Tuple of integers representing the spacing between kernel elements. Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), output_padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nkernel_size = (3, 5)\nheight_in = 128\nwidth_in = 256\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 69, "problem_name": "69_conv_transposed_2D__asymmetric_input__asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution operation with asymmetric input and kernel size.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of integers representing the kernel size (height, width).\n        stride (tuple, optional): Tuple of integers representing the stride of the convolution. Defaults to (1, 1).\n        padding (tuple, optional): Tuple of integers representing the padding applied to the input. Defaults to (0, 0).\n        output_padding (tuple, optional): Tuple of integers representing the additional size added to one side of the output shape. Defaults to (0, 0).\n        dilation (tuple, optional): Tuple of integers representing the spacing between kernel elements. Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), output_padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nkernel_size = (3, 5)\nheight_in = 128\nwidth_in = 256\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_70", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution operation with asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int or tuple, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int or tuple, optional): Additional size added to one side of each dimension in the output shape. \n                                                  Defaults to 0.\n        dilation (int or tuple, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, \n                 dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, (kernel_size, kernel_size, kernel_size), \n                                                stride=stride, padding=padding, output_padding=output_padding, \n                                                dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 48\nout_channels = 24\nkernel_size = 3\ndepth = 96\nheight = 96\nwidth = 96\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution operation with asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int or tuple, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int or tuple, optional): Additional size added to one side of each dimension in the output shape. \n                                                  Defaults to 0.\n        dilation (int or tuple, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, \n                 dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, (kernel_size, kernel_size, kernel_size), \n                                                stride=stride, padding=padding, output_padding=output_padding, \n                                                dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 48\nout_channels = 24\nkernel_size = 3\ndepth = 96\nheight = 96\nwidth = 96\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 70, "problem_name": "70_conv_transposed_3D__asymmetric_input__square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution operation with asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int or tuple, optional): Stride of the convolution. Defaults to 1.\n        padding (int or tuple, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int or tuple, optional): Additional size added to one side of each dimension in the output shape. \n                                                  Defaults to 0.\n        dilation (int or tuple, optional): Spacing between kernel elements. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, \n                 dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, (kernel_size, kernel_size, kernel_size), \n                                                stride=stride, padding=padding, output_padding=output_padding, \n                                                dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 3D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 48\nout_channels = 24\nkernel_size = 3\ndepth = 96\nheight = 96\nwidth = 96\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_71", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution with asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 32\nkernel_size = 3\n# large asymmetric input\nheight_in = 512\nwidth_in = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution with asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 32\nkernel_size = 3\n# large asymmetric input\nheight_in = 512\nwidth_in = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 71, "problem_name": "71_conv_transposed_2D__asymmetric_input__square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution with asymmetric input and a square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        output_padding (int, optional): Additional size added to one side of the output shape. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 32\nkernel_size = 3\n# large asymmetric input\nheight_in = 512\nwidth_in = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization"}}
{"task_id": "L1_72", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with asymmetric input and kernel, and optional stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple of ints): Size of the convolution kernel in the form (kernel_size_depth, kernel_size_height, kernel_size_width).\n        stride (tuple of ints, optional): Stride of the convolution in the form (stride_depth, stride_height, stride_width). Defaults to (1, 1, 1).\n        padding (tuple of ints, optional): Padding applied to the input in the form (padding_depth, padding_height, padding_width). Defaults to (0, 0, 0).\n        output_padding (tuple of ints, optional): Additional size added to one side of the output shape. Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 32\nkernel_size = (3, 5, 7)\ndepth = 12\nheight = 24\nwidth = 48\nstride = (2, 2, 2)\npadding = (1, 2, 3)\noutput_padding = (1, 1, 1)\ngroups = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with asymmetric input and kernel, and optional stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple of ints): Size of the convolution kernel in the form (kernel_size_depth, kernel_size_height, kernel_size_width).\n        stride (tuple of ints, optional): Stride of the convolution in the form (stride_depth, stride_height, stride_width). Defaults to (1, 1, 1).\n        padding (tuple of ints, optional): Padding applied to the input in the form (padding_depth, padding_height, padding_width). Defaults to (0, 0, 0).\n        output_padding (tuple of ints, optional): Additional size added to one side of the output shape. Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 32\nkernel_size = (3, 5, 7)\ndepth = 12\nheight = 24\nwidth = 48\nstride = (2, 2, 2)\npadding = (1, 2, 3)\noutput_padding = (1, 1, 1)\ngroups = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 72, "problem_name": "72_conv_transposed_3D_asymmetric_input_asymmetric_kernel___strided_padded_grouped_.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with asymmetric input and kernel, and optional stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple of ints): Size of the convolution kernel in the form (kernel_size_depth, kernel_size_height, kernel_size_width).\n        stride (tuple of ints, optional): Stride of the convolution in the form (stride_depth, stride_height, stride_width). Defaults to (1, 1, 1).\n        padding (tuple of ints, optional): Padding applied to the input in the form (padding_depth, padding_height, padding_width). Defaults to (0, 0, 0).\n        output_padding (tuple of ints, optional): Additional size added to one side of the output shape. Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 32\nkernel_size = (3, 5, 7)\ndepth = 12\nheight = 24\nwidth = 48\nstride = (2, 2, 2)\npadding = (1, 2, 3)\noutput_padding = (1, 1, 1)\ngroups = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, groups]"}}
{"task_id": "L1_73", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with asymmetric input and square kernel.\n    The input is padded before the convolution.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 4\nin_channels = 32\nout_channels = 32\nkernel_size = 3\ndepth = 32\nheight = 64\nwidth = 128\nstride = 2\npadding = 1\ngroups = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with asymmetric input and square kernel.\n    The input is padded before the convolution.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 4\nin_channels = 32\nout_channels = 32\nkernel_size = 3\ndepth = 32\nheight = 64\nwidth = 128\nstride = 2\npadding = 1\ngroups = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 73, "problem_name": "73_conv_transposed_3D_asymmetric_input_square_kernel__strided_padded__grouped.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with asymmetric input and square kernel.\n    The input is padded before the convolution.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 4\nin_channels = 32\nout_channels = 32\nkernel_size = 3\ndepth = 32\nheight = 64\nwidth = 128\nstride = 2\npadding = 1\ngroups = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups]"}}
{"task_id": "L1_74", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 1D convolution operation with square input and asymmetric kernel, optionally with dilation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d_transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d_transpose(x)\n\n# Test code\nbatch_size = 32\nin_channels = 32\nout_channels = 64\nkernel_size = 5\nlength = 131072\nstride = 1\npadding = 0\ndilation = 3\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 1D convolution operation with square input and asymmetric kernel, optionally with dilation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d_transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d_transpose(x)\n\n# Test code\nbatch_size = 32\nin_channels = 32\nout_channels = 64\nkernel_size = 5\nlength = 131072\nstride = 1\npadding = 0\ndilation = 3\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 74, "problem_name": "74_conv_transposed_1D_dilated.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 1D convolution operation with square input and asymmetric kernel, optionally with dilation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d_transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d_transpose(x)\n\n# Test code\nbatch_size = 32\nin_channels = 32\nout_channels = 64\nkernel_size = 5\nlength = 131072\nstride = 1\npadding = 0\ndilation = 3\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]"}}
{"task_id": "L1_75", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input, asymmetric kernel, \n    grouped, padded, and dilated.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (tuple, optional): Stride of the convolution (height, width). Defaults to (1, 1).\n        padding (tuple, optional): Padding applied to the input (height, width). Defaults to (0, 0).\n        dilation (tuple, optional): Spacing between kernel elements (height, width). Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight = 128\nwidth = 256\nstride = (2, 3)\npadding = (1, 2)\ndilation = (2, 1)\ngroups = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation, groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input, asymmetric kernel, \n    grouped, padded, and dilated.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (tuple, optional): Stride of the convolution (height, width). Defaults to (1, 1).\n        padding (tuple, optional): Padding applied to the input (height, width). Defaults to (0, 0).\n        dilation (tuple, optional): Spacing between kernel elements (height, width). Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight = 128\nwidth = 256\nstride = (2, 3)\npadding = (1, 2)\ndilation = (2, 1)\ngroups = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation, groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 75, "problem_name": "75_conv_transposed_2D_asymmetric_input_asymmetric_kernel_strided__grouped____padded____dilated__.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input, asymmetric kernel, \n    grouped, padded, and dilated.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (tuple, optional): Stride of the convolution (height, width). Defaults to (1, 1).\n        padding (tuple, optional): Padding applied to the input (height, width). Defaults to (0, 0).\n        dilation (tuple, optional): Spacing between kernel elements (height, width). Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight = 128\nwidth = 256\nstride = (2, 3)\npadding = (1, 2)\ndilation = (2, 1)\ngroups = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation, groups]"}}
{"task_id": "L1_76", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 1D convolution operation with asymmetric input and a square kernel, potentially dilated and strided.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nkernel_size = 3\n# longer signal\nlength = 524280\nstride = 3\ndilation = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, dilation]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 1D convolution operation with asymmetric input and a square kernel, potentially dilated and strided.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nkernel_size = 3\n# longer signal\nlength = 524280\nstride = 3\ndilation = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, dilation]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 76, "problem_name": "76_conv_standard_1D_dilated_strided__.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 1D convolution operation with asymmetric input and a square kernel, potentially dilated and strided.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nkernel_size = 3\n# longer signal\nlength = 524280\nstride = 3\ndilation = 4\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, dilation]"}}
{"task_id": "L1_77", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with square input and square kernel,\n    and supports padding, dilation, and stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel (square kernel, so only one value needed).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\ndepth = 16\nheight = 32\nwidth = 32\nstride = 2\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with square input and square kernel,\n    and supports padding, dilation, and stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel (square kernel, so only one value needed).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\ndepth = 16\nheight = 32\nwidth = 32\nstride = 2\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 77, "problem_name": "77_conv_transposed_3D_square_input_square_kernel___padded____dilated____strided__.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with square input and square kernel,\n    and supports padding, dilation, and stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel (square kernel, so only one value needed).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\ndepth = 16\nheight = 32\nwidth = 32\nstride = 2\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]"}}
{"task_id": "L1_78", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input and kernel, with optional padding.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (tuple, optional): Stride of the convolution (height, width). Defaults to (1, 1).\n        padding (tuple, optional): Padding applied to the input (height, width). Defaults to (0, 0).\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 32\nkernel_size = (3, 7)\nheight = 512\nwidth = 1024\nstride = (1, 1)\npadding = (1, 3)\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input and kernel, with optional padding.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (tuple, optional): Stride of the convolution (height, width). Defaults to (1, 1).\n        padding (tuple, optional): Padding applied to the input (height, width). Defaults to (0, 0).\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 32\nkernel_size = (3, 7)\nheight = 512\nwidth = 1024\nstride = (1, 1)\npadding = (1, 3)\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 78, "problem_name": "78_conv_transposed_2D_asymmetric_input_asymmetric_kernel___padded__.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input and kernel, with optional padding.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (tuple, optional): Stride of the convolution (height, width). Defaults to (1, 1).\n        padding (tuple, optional): Padding applied to the input (height, width). Defaults to (0, 0).\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 32\nkernel_size = (3, 7)\nheight = 512\nwidth = 1024\nstride = (1, 1)\npadding = (1, 3)\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]"}}
{"task_id": "L1_79", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 1D convolution operation with asymmetric input and square kernel.\n    Supports padding, striding, and dilation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d_transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d_transpose(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\n# long sequence\nlength = 131072\nstride = 2\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 1D convolution operation with asymmetric input and square kernel.\n    Supports padding, striding, and dilation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d_transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d_transpose(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\n# long sequence\nlength = 131072\nstride = 2\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 79, "problem_name": "79_conv_transposed_1D_asymmetric_input_square_kernel___padded____strided____dilated__.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a transposed 1D convolution operation with asymmetric input and square kernel.\n    Supports padding, striding, and dilation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d_transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 1D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, length).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, length_out).\n        \"\"\"\n        return self.conv1d_transpose(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\n# long sequence\nlength = 131072\nstride = 2\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]"}}
{"task_id": "L1_80", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with square input and asymmetric kernel, with dilation and padding.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width). \n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (tuple, optional): Padding applied to the input (top/bottom, left/right). Defaults to (0, 0).\n        dilation (tuple, optional): Spacing between kernel elements (height, width). Defaults to (1, 1).\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: tuple = (0, 0), dilation: tuple = (1, 1), bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 64\nkernel_size = (5, 9)\nwidth = 512\nheight = 512\nstride = 1\npadding = (2, 4)\ndilation = (2, 3)\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with square input and asymmetric kernel, with dilation and padding.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width). \n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (tuple, optional): Padding applied to the input (top/bottom, left/right). Defaults to (0, 0).\n        dilation (tuple, optional): Spacing between kernel elements (height, width). Defaults to (1, 1).\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: tuple = (0, 0), dilation: tuple = (1, 1), bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 64\nkernel_size = (5, 9)\nwidth = 512\nheight = 512\nstride = 1\npadding = (2, 4)\ndilation = (2, 3)\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 80, "problem_name": "80_conv_standard_2D_square_input_asymmetric_kernel___dilated____padded__.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a standard 2D convolution operation with square input and asymmetric kernel, with dilation and padding.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width). \n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (tuple, optional): Padding applied to the input (top/bottom, left/right). Defaults to (0, 0).\n        dilation (tuple, optional): Spacing between kernel elements (height, width). Defaults to (1, 1).\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: tuple = (0, 0), dilation: tuple = (1, 1), bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 8\nin_channels = 32\nout_channels = 64\nkernel_size = (5, 9)\nwidth = 512\nheight = 512\nstride = 1\npadding = (2, 4)\ndilation = (2, 3)\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]"}}
{"task_id": "L1_81", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input and square kernel, supporting dilation, padding, and stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel (square, e.g., 3 for a 3x3 kernel).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in). \n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\nheight_in = 64\nwidth_in = 128\nstride = 5\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input and square kernel, supporting dilation, padding, and stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel (square, e.g., 3 for a 3x3 kernel).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in). \n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\nheight_in = 64\nwidth_in = 128\nstride = 5\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 81, "problem_name": "81_conv_transposed_2D_asymmetric_input_square_kernel___dilated____padded____strided__.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input and square kernel, supporting dilation, padding, and stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel (square, e.g., 3 for a 3x3 kernel).\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in). \n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\nheight_in = 64\nwidth_in = 128\nstride = 5\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]"}}
{"task_id": "L1_82", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution operation with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, in_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 64\nkernel_size = 3\nwidth = 512\nheight = 512\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution operation with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, in_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 64\nkernel_size = 3\nwidth = 512\nheight = 512\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 82, "problem_name": "82_conv_depthwise_2D_square_input_square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution operation with square input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, in_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 64\nkernel_size = 3\nwidth = 512\nheight = 512\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding]"}}
{"task_id": "L1_83", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size=(kernel_size, 1), stride=stride, padding=padding, dilation=dilation, groups=in_channels, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, in_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 8\nkernel_size = 3\nwidth = 512\nheight = 512\nstride = 1\npadding = 0\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding, dilation]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size=(kernel_size, 1), stride=stride, padding=padding, dilation=dilation, groups=in_channels, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, in_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 8\nkernel_size = 3\nwidth = 512\nheight = 512\nstride = 1\npadding = 0\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding, dilation]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 83, "problem_name": "83_conv_depthwise_2D_square_input_asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution with a square input and an asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size=(kernel_size, 1), stride=stride, padding=padding, dilation=dilation, groups=in_channels, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, in_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 8\nkernel_size = 3\nwidth = 512\nheight = 512\nstride = 1\npadding = 0\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding, dilation]"}}
{"task_id": "L1_84", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution with asymmetric input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size), stride=stride, padding=padding, groups=in_channels, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 128\nout_channels = 128\nkernel_size = 3\nwidth_in = 512\nheight_in = 256\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution with asymmetric input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size), stride=stride, padding=padding, groups=in_channels, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 128\nout_channels = 128\nkernel_size = 3\nwidth_in = 512\nheight_in = 256\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 84, "problem_name": "84_conv_depthwise_2D_asymmetric_input_square_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution with asymmetric input and square kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the square convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size), stride=stride, padding=padding, groups=in_channels, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 64\nin_channels = 128\nout_channels = 128\nkernel_size = 3\nwidth_in = 512\nheight_in = 256\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]"}}
{"task_id": "L1_85", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution with asymmetric input and asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size_h (int): Height of the convolution kernel.\n        kernel_size_w (int): Width of the convolution kernel.\n        stride_h (int, optional): Stride of the convolution in height dimension. Defaults to 1.\n        stride_w (int, optional): Stride of the convolution in width dimension. Defaults to 1.\n        padding_h (int, optional): Padding applied to the input in height dimension. Defaults to 0.\n        padding_w (int, optional): Padding applied to the input in width dimension. Defaults to 0.\n        dilation_h (int, optional): Spacing between kernel elements in height dimension. Defaults to 1.\n        dilation_w (int, optional): Spacing between kernel elements in width dimension. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size_h: int, kernel_size_w: int, stride_h: int = 1, stride_w: int = 1, padding_h: int = 0, padding_w: int = 0, dilation_h: int = 1, dilation_w: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, (kernel_size_h, kernel_size_w), stride=(stride_h, stride_w), padding=(padding_h, padding_w), dilation=(dilation_h, dilation_w), groups=in_channels, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 32\nin_channels = 128\nout_channels = 128\nkernel_size_h = 3\nkernel_size_w = 7\nwidth = 256\nheight = 128\nstride_h = 1\nstride_w = 1\npadding_h = 0\npadding_w = 0\ndilation_h = 1\ndilation_w = 1\ngroups = in_channels\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size_h, kernel_size_w, stride_h, stride_w, padding_h, padding_w, dilation_h, dilation_w, groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution with asymmetric input and asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size_h (int): Height of the convolution kernel.\n        kernel_size_w (int): Width of the convolution kernel.\n        stride_h (int, optional): Stride of the convolution in height dimension. Defaults to 1.\n        stride_w (int, optional): Stride of the convolution in width dimension. Defaults to 1.\n        padding_h (int, optional): Padding applied to the input in height dimension. Defaults to 0.\n        padding_w (int, optional): Padding applied to the input in width dimension. Defaults to 0.\n        dilation_h (int, optional): Spacing between kernel elements in height dimension. Defaults to 1.\n        dilation_w (int, optional): Spacing between kernel elements in width dimension. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size_h: int, kernel_size_w: int, stride_h: int = 1, stride_w: int = 1, padding_h: int = 0, padding_w: int = 0, dilation_h: int = 1, dilation_w: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, (kernel_size_h, kernel_size_w), stride=(stride_h, stride_w), padding=(padding_h, padding_w), dilation=(dilation_h, dilation_w), groups=in_channels, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 32\nin_channels = 128\nout_channels = 128\nkernel_size_h = 3\nkernel_size_w = 7\nwidth = 256\nheight = 128\nstride_h = 1\nstride_w = 1\npadding_h = 0\npadding_w = 0\ndilation_h = 1\ndilation_w = 1\ngroups = in_channels\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size_h, kernel_size_w, stride_h, stride_w, padding_h, padding_w, dilation_h, dilation_w, groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 85, "problem_name": "85_conv_depthwise_2D_asymmetric_input_asymmetric_kernel.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise 2D convolution with asymmetric input and asymmetric kernel.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size_h (int): Height of the convolution kernel.\n        kernel_size_w (int): Width of the convolution kernel.\n        stride_h (int, optional): Stride of the convolution in height dimension. Defaults to 1.\n        stride_w (int, optional): Stride of the convolution in width dimension. Defaults to 1.\n        padding_h (int, optional): Padding applied to the input in height dimension. Defaults to 0.\n        padding_w (int, optional): Padding applied to the input in width dimension. Defaults to 0.\n        dilation_h (int, optional): Spacing between kernel elements in height dimension. Defaults to 1.\n        dilation_w (int, optional): Spacing between kernel elements in width dimension. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size_h: int, kernel_size_w: int, stride_h: int = 1, stride_w: int = 1, padding_h: int = 0, padding_w: int = 0, dilation_h: int = 1, dilation_w: int = 1, groups: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, (kernel_size_h, kernel_size_w), stride=(stride_h, stride_w), padding=(padding_h, padding_w), dilation=(dilation_h, dilation_w), groups=in_channels, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv2d(x)\n\n# Test code\nbatch_size = 32\nin_channels = 128\nout_channels = 128\nkernel_size_h = 3\nkernel_size_w = 7\nwidth = 256\nheight = 128\nstride_h = 1\nstride_w = 1\npadding_h = 0\npadding_w = 0\ndilation_h = 1\ndilation_w = 1\ngroups = in_channels\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size_h, kernel_size_w, stride_h, stride_w, padding_h, padding_w, dilation_h, dilation_w, groups]"}}
{"task_id": "L1_86", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise-separable 2D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=in_channels, bias=bias)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise-separable 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        return x\n\n# Test code\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nkernel_size = 3\nwidth = 512\nheight = 512\nstride = 1\npadding = 1\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise-separable 2D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=in_channels, bias=bias)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise-separable 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        return x\n\n# Test code\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nkernel_size = 3\nwidth = 512\nheight = 512\nstride = 1\npadding = 1\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 86, "problem_name": "86_conv_depthwise_separable_2D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a depthwise-separable 2D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int, optional): Stride of the convolution. Defaults to 1.\n        padding (int, optional): Padding applied to the input. Defaults to 0.\n        dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(Model, self).__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=in_channels, bias=bias)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the depthwise-separable 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        return x\n\n# Test code\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nkernel_size = 3\nwidth = 512\nheight = 512\nstride = 1\npadding = 1\ndilation = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]"}}
{"task_id": "L1_87", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a pointwise 2D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the pointwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        return self.conv1d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nwidth = 1024\nheight = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a pointwise 2D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the pointwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        return self.conv1d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nwidth = 1024\nheight = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 87, "problem_name": "87_conv_pointwise_2D.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Performs a pointwise 2D convolution operation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, bias: bool = False):\n        super(Model, self).__init__()\n        self.conv1d = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the pointwise 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        return self.conv1d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nwidth = 1024\nheight = 1024\n\ndef get_inputs():\n    x = torch.rand(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels]"}}
{"task_id": "L1_88", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n# From https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n\nclass Model(nn.Module):\n    \"\"\"\n    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x):\n        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n\nbatch_size = 8192\ndim = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, dim)]\n\ndef get_init_inputs():\n    return []", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n# From https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n\nclass Model(nn.Module):\n    \"\"\"\n    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x):\n        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n\nbatch_size = 8192\ndim = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, dim)]\n\ndef get_init_inputs():\n    return []", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 88, "problem_name": "88_MinGPTNewGelu.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n# From https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n\nclass Model(nn.Module):\n    \"\"\"\n    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n    \n    def forward(self, x):\n        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n\nbatch_size = 8192\ndim = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, dim)]\n\ndef get_init_inputs():\n    return []"}}
{"task_id": "L1_89", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A simple model that performs a cumulative sum (prefix sum) operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the scan operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the Scan model.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative sum.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass for the Scan model, computing the cumulative sum along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape), where `*input_shape` \n                              can vary depending on the use case.\n\n        Returns:\n            torch.Tensor: Tensor of the same shape as `x` after applying cumulative sum along `dim`.\n        \"\"\"\n        return torch.cumsum(x, dim=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    \"\"\"\n    Generates random inputs for testing the Scan model.\n\n    Returns:\n        list: A list containing a single randomly generated tensor with shape \n              (batch_size, *input_shape).\n    \"\"\"\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    \"\"\"\n    Returns the initialization parameters for the Scan model.\n\n    Returns:\n        list: A list containing the `dim` parameter for model initialization.\n    \"\"\"\n    return [dim]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A simple model that performs a cumulative sum (prefix sum) operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the scan operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the Scan model.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative sum.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass for the Scan model, computing the cumulative sum along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape), where `*input_shape` \n                              can vary depending on the use case.\n\n        Returns:\n            torch.Tensor: Tensor of the same shape as `x` after applying cumulative sum along `dim`.\n        \"\"\"\n        return torch.cumsum(x, dim=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    \"\"\"\n    Generates random inputs for testing the Scan model.\n\n    Returns:\n        list: A list containing a single randomly generated tensor with shape \n              (batch_size, *input_shape).\n    \"\"\"\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    \"\"\"\n    Returns the initialization parameters for the Scan model.\n\n    Returns:\n        list: A list containing the `dim` parameter for model initialization.\n    \"\"\"\n    return [dim]", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 89, "problem_name": "89_cumsum.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A simple model that performs a cumulative sum (prefix sum) operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the scan operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the Scan model.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative sum.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass for the Scan model, computing the cumulative sum along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape), where `*input_shape` \n                              can vary depending on the use case.\n\n        Returns:\n            torch.Tensor: Tensor of the same shape as `x` after applying cumulative sum along `dim`.\n        \"\"\"\n        return torch.cumsum(x, dim=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    \"\"\"\n    Generates random inputs for testing the Scan model.\n\n    Returns:\n        list: A list containing a single randomly generated tensor with shape \n              (batch_size, *input_shape).\n    \"\"\"\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    \"\"\"\n    Returns the initialization parameters for the Scan model.\n\n    Returns:\n        list: A list containing the `dim` parameter for model initialization.\n    \"\"\"\n    return [dim]"}}
{"task_id": "L1_90", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a cumulative product operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the cumulative product operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the CumulativeProductModel.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative product.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass, computing the cumulative product along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape).\n\n        Returns:\n            torch.Tensor: Tensor of the same shape as `x` after applying cumulative product along `dim`.\n        \"\"\"\n        return torch.cumprod(x, dim=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a cumulative product operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the cumulative product operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the CumulativeProductModel.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative product.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass, computing the cumulative product along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape).\n\n        Returns:\n            torch.Tensor: Tensor of the same shape as `x` after applying cumulative product along `dim`.\n        \"\"\"\n        return torch.cumprod(x, dim=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 90, "problem_name": "90_cumprod.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a cumulative product operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the cumulative product operation.\n    \"\"\"\n\n    def __init__(self, dim):\n        \"\"\"\n        Initialize the CumulativeProductModel.\n\n        Args:\n            dim (int): The dimension along which to perform the cumulative product.\n        \"\"\"\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass, computing the cumulative product along the specified dimension.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape).\n\n        Returns:\n            torch.Tensor: Tensor of the same shape as `x` after applying cumulative product along `dim`.\n        \"\"\"\n        return torch.cumprod(x, dim=self.dim)\n\n# Define input dimensions and parameters\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n"}}
{"task_id": "L1_91", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a reverse cumulative sum operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the reverse cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        return torch.cumsum(x.flip(self.dim), dim=self.dim).flip(self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a reverse cumulative sum operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the reverse cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        return torch.cumsum(x.flip(self.dim), dim=self.dim).flip(self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 91, "problem_name": "91_cumsum_reverse.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a reverse cumulative sum operation along a specified dimension.\n\n    Parameters:\n        dim (int): The dimension along which to perform the reverse cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        return torch.cumsum(x.flip(self.dim), dim=self.dim).flip(self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n"}}
{"task_id": "L1_92", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs an exclusive cumulative sum (does not include the current element).\n\n    Parameters:\n        dim (int): The dimension along which to perform the exclusive cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        cumsum = torch.cumsum(x.narrow(dim=self.dim, start=0, length=x.size(self.dim)-1), dim=self.dim)\n        return torch.cat((torch.zeros_like(x.select(self.dim, 0).unsqueeze(self.dim)), cumsum), dim=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs an exclusive cumulative sum (does not include the current element).\n\n    Parameters:\n        dim (int): The dimension along which to perform the exclusive cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        cumsum = torch.cumsum(x.narrow(dim=self.dim, start=0, length=x.size(self.dim)-1), dim=self.dim)\n        return torch.cat((torch.zeros_like(x.select(self.dim, 0).unsqueeze(self.dim)), cumsum), dim=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 92, "problem_name": "92_cumsum_exclusive.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs an exclusive cumulative sum (does not include the current element).\n\n    Parameters:\n        dim (int): The dimension along which to perform the exclusive cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        cumsum = torch.cumsum(x.narrow(dim=self.dim, start=0, length=x.size(self.dim)-1), dim=self.dim)\n        return torch.cat((torch.zeros_like(x.select(self.dim, 0).unsqueeze(self.dim)), cumsum), dim=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [dim]\n"}}
{"task_id": "L1_93", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a masked cumulative sum, only summing elements that satisfy a condition.\n\n    Parameters:\n        dim (int): The dimension along which to perform the masked cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x, mask):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape).\n            mask (torch.Tensor): Boolean mask of the same shape as x.\n\n        Returns:\n            torch.Tensor: Cumulative sum of elements where mask is True.\n        \"\"\"\n        return torch.cumsum(x * mask, dim=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, *input_shape)\n    mask = torch.randint(0, 2, x.shape).bool()  # Random boolean mask\n    return [x, mask]\n\ndef get_init_inputs():\n    return [dim]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a masked cumulative sum, only summing elements that satisfy a condition.\n\n    Parameters:\n        dim (int): The dimension along which to perform the masked cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x, mask):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape).\n            mask (torch.Tensor): Boolean mask of the same shape as x.\n\n        Returns:\n            torch.Tensor: Cumulative sum of elements where mask is True.\n        \"\"\"\n        return torch.cumsum(x * mask, dim=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, *input_shape)\n    mask = torch.randint(0, 2, x.shape).bool()  # Random boolean mask\n    return [x, mask]\n\ndef get_init_inputs():\n    return [dim]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 93, "problem_name": "93_masked_cumsum.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a masked cumulative sum, only summing elements that satisfy a condition.\n\n    Parameters:\n        dim (int): The dimension along which to perform the masked cumulative sum.\n    \"\"\"\n\n    def __init__(self, dim):\n        super(Model, self).__init__()\n        self.dim = dim\n\n    def forward(self, x, mask):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_shape).\n            mask (torch.Tensor): Boolean mask of the same shape as x.\n\n        Returns:\n            torch.Tensor: Cumulative sum of elements where mask is True.\n        \"\"\"\n        return torch.cumsum(x * mask, dim=self.dim)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    x = torch.rand(batch_size, *input_shape)\n    mask = torch.randint(0, 2, x.shape).bool()  # Random boolean mask\n    return [x, mask]\n\ndef get_init_inputs():\n    return [dim]\n"}}
{"task_id": "L1_94", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes the Mean Squared Error loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.mean((predictions - targets) ** 2)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return []\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes the Mean Squared Error loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.mean((predictions - targets) ** 2)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return []\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 94, "problem_name": "94_MSELoss.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes the Mean Squared Error loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.mean((predictions - targets) ** 2)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return []\n"}}
{"task_id": "L1_95", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Cross Entropy Loss for multi-class classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.cross_entropy(predictions, targets)\n\nbatch_size = 32768\nnum_classes = 4096\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Cross Entropy Loss for multi-class classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.cross_entropy(predictions, targets)\n\nbatch_size = 32768\nnum_classes = 4096\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 95, "problem_name": "95_CrossEntropyLoss.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Cross Entropy Loss for multi-class classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.cross_entropy(predictions, targets)\n\nbatch_size = 32768\nnum_classes = 4096\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n"}}
{"task_id": "L1_96", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Smooth L1 (Huber) Loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.smooth_l1_loss(predictions, targets)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return []\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Smooth L1 (Huber) Loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.smooth_l1_loss(predictions, targets)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return []\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 96, "problem_name": "96_HuberLoss.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Smooth L1 (Huber) Loss for regression tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.smooth_l1_loss(predictions, targets)\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return []\n"}}
{"task_id": "L1_97", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor) -> torch.Tensor:\n        out = torch.nn.functional.scaled_dot_product_attention(Q, K, V)\n        return out\n\nbatch_size = 32\nnum_heads = 32\nsequence_length = 512\nembedding_dimension = 1024\n\ndef get_inputs():\n    Q = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension)\n    K = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension)\n    V = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension)\n    return [Q, K, V]\n\ndef get_init_inputs():\n    return []\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor) -> torch.Tensor:\n        out = torch.nn.functional.scaled_dot_product_attention(Q, K, V)\n        return out\n\nbatch_size = 32\nnum_heads = 32\nsequence_length = 512\nembedding_dimension = 1024\n\ndef get_inputs():\n    Q = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension)\n    K = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension)\n    V = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension)\n    return [Q, K, V]\n\ndef get_init_inputs():\n    return []\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 97, "problem_name": "97_ScaledDotProductAttention.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor) -> torch.Tensor:\n        out = torch.nn.functional.scaled_dot_product_attention(Q, K, V)\n        return out\n\nbatch_size = 32\nnum_heads = 32\nsequence_length = 512\nembedding_dimension = 1024\n\ndef get_inputs():\n    Q = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension)\n    K = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension)\n    V = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension)\n    return [Q, K, V]\n\ndef get_init_inputs():\n    return []\n"}}
{"task_id": "L1_98", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Kullback-Leibler Divergence for comparing two distributions.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.kl_div(torch.log(predictions), targets, reduction='batchmean')\n\nbatch_size = 8192 * 2\ninput_shape = (8192 * 2,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [(torch.rand(batch_size, *input_shape)*scale).softmax(dim=-1), torch.rand(batch_size, *input_shape).softmax(dim=-1)]\n\ndef get_init_inputs():\n    return []\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Kullback-Leibler Divergence for comparing two distributions.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.kl_div(torch.log(predictions), targets, reduction='batchmean')\n\nbatch_size = 8192 * 2\ninput_shape = (8192 * 2,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [(torch.rand(batch_size, *input_shape)*scale).softmax(dim=-1), torch.rand(batch_size, *input_shape).softmax(dim=-1)]\n\ndef get_init_inputs():\n    return []\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 98, "problem_name": "98_KLDivLoss.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Kullback-Leibler Divergence for comparing two distributions.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.nn.functional.kl_div(torch.log(predictions), targets, reduction='batchmean')\n\nbatch_size = 8192 * 2\ninput_shape = (8192 * 2,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [(torch.rand(batch_size, *input_shape)*scale).softmax(dim=-1), torch.rand(batch_size, *input_shape).softmax(dim=-1)]\n\ndef get_init_inputs():\n    return []\n"}}
{"task_id": "L1_99", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Triplet Margin Loss for metric learning tasks.\n\n    Parameters:\n        margin (float): The margin between the positive and negative samples.\n    \"\"\"\n    def __init__(self, margin=1.0):\n        super(Model, self).__init__()\n        self.loss_fn = torch.nn.TripletMarginLoss(margin=margin)\n\n    def forward(self, anchor, positive, negative):\n        return self.loss_fn(anchor, positive, negative)\n\nbatch_size = 32768\ninput_shape = (8192,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape), torch.rand(batch_size, *input_shape)]\n    \ndef get_init_inputs():\n    return [1.0]  # Default margin\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Triplet Margin Loss for metric learning tasks.\n\n    Parameters:\n        margin (float): The margin between the positive and negative samples.\n    \"\"\"\n    def __init__(self, margin=1.0):\n        super(Model, self).__init__()\n        self.loss_fn = torch.nn.TripletMarginLoss(margin=margin)\n\n    def forward(self, anchor, positive, negative):\n        return self.loss_fn(anchor, positive, negative)\n\nbatch_size = 32768\ninput_shape = (8192,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape), torch.rand(batch_size, *input_shape)]\n    \ndef get_init_inputs():\n    return [1.0]  # Default margin\n", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 99, "problem_name": "99_TripletMarginLoss.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Triplet Margin Loss for metric learning tasks.\n\n    Parameters:\n        margin (float): The margin between the positive and negative samples.\n    \"\"\"\n    def __init__(self, margin=1.0):\n        super(Model, self).__init__()\n        self.loss_fn = torch.nn.TripletMarginLoss(margin=margin)\n\n    def forward(self, anchor, positive, negative):\n        return self.loss_fn(anchor, positive, negative)\n\nbatch_size = 32768\ninput_shape = (8192,)\ndim = 1\n\ndef get_inputs():\n    scale = torch.rand(())\n    return [torch.rand(batch_size, *input_shape)*scale, torch.rand(batch_size, *input_shape), torch.rand(batch_size, *input_shape)]\n    \ndef get_init_inputs():\n    return [1.0]  # Default margin\n"}}
{"task_id": "L1_100", "level": 1, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Hinge Loss for binary classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.mean(torch.clamp(1 - predictions * targets, min=0))\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape), torch.randint(0, 2, (batch_size,)).float() * 2 - 1]\n\ndef get_init_inputs():\n    return []", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Hinge Loss for binary classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.mean(torch.clamp(1 - predictions * targets, min=0))\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape), torch.randint(0, 2, (batch_size,)).float() * 2 - 1]\n\ndef get_init_inputs():\n    return []", "metadata": {"source": "kernelbench_dataset_api", "level": 1, "problem_id": 100, "problem_name": "100_HingeLoss.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that computes Hinge Loss for binary classification tasks.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, predictions, targets):\n        return torch.mean(torch.clamp(1 - predictions * targets, min=0))\n\nbatch_size = 32768\ninput_shape = (32768,)\ndim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, *input_shape), torch.randint(0, 2, (batch_size,)).float() * 2 - 1]\n\ndef get_init_inputs():\n    return []"}}
{"task_id": "L2_1", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and adds a bias term.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = x + self.bias\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and adds a bias term.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = x + self.bias\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 1, "problem_name": "1_Conv2D_ReLU_BiasAdd.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and adds a bias term.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = x + self.bias\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]"}}
{"task_id": "L2_2", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a bias term, clamps, scales, clamps, and divides.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.bias\n        x = torch.clamp(x, min=0.0, max=1.0)\n        x = x * self.scaling_factor\n        x = torch.clamp(x, min=0.0, max=1.0)\n        x = x / self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128 \nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a bias term, clamps, scales, clamps, and divides.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.bias\n        x = torch.clamp(x, min=0.0, max=1.0)\n        x = x * self.scaling_factor\n        x = torch.clamp(x, min=0.0, max=1.0)\n        x = x / self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128 \nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 2, "problem_name": "2_ConvTranspose2d_BiasAdd_Clamp_Scaling_Clamp_Divide.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a bias term, clamps, scales, clamps, and divides.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.bias\n        x = torch.clamp(x, min=0.0, max=1.0)\n        x = x * self.scaling_factor\n        x = torch.clamp(x, min=0.0, max=1.0)\n        x = x / self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128 \nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]"}}
{"task_id": "L2_3", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by a sum, layer normalization, average pooling, and GELU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, sum_weight, norm_shape, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.sum_weight = nn.Parameter(torch.tensor(sum_weight))\n        self.norm = nn.LayerNorm(norm_shape)\n        self.avg_pool = nn.AvgPool3d(kernel_size=pool_kernel_size)\n        self.gelu = nn.GELU()\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.sum_weight\n        x = self.norm(x)\n        x = self.avg_pool(x)\n        x = self.gelu(x)\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = (3, 3, 3)\nstride = (2, 2, 2)\npadding = (1, 1, 1)\noutput_padding = (1, 1, 1)\nsum_weight = 1.0\nnorm_shape = (out_channels,)\npool_kernel_size = (2, 2, 2)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, sum_weight, norm_shape, pool_kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by a sum, layer normalization, average pooling, and GELU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, sum_weight, norm_shape, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.sum_weight = nn.Parameter(torch.tensor(sum_weight))\n        self.norm = nn.LayerNorm(norm_shape)\n        self.avg_pool = nn.AvgPool3d(kernel_size=pool_kernel_size)\n        self.gelu = nn.GELU()\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.sum_weight\n        x = self.norm(x)\n        x = self.avg_pool(x)\n        x = self.gelu(x)\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = (3, 3, 3)\nstride = (2, 2, 2)\npadding = (1, 1, 1)\noutput_padding = (1, 1, 1)\nsum_weight = 1.0\nnorm_shape = (out_channels,)\npool_kernel_size = (2, 2, 2)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, sum_weight, norm_shape, pool_kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 3, "problem_name": "3_ConvTranspose3d_Sum_LayerNorm_AvgPool_GELU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by a sum, layer normalization, average pooling, and GELU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, sum_weight, norm_shape, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.sum_weight = nn.Parameter(torch.tensor(sum_weight))\n        self.norm = nn.LayerNorm(norm_shape)\n        self.avg_pool = nn.AvgPool3d(kernel_size=pool_kernel_size)\n        self.gelu = nn.GELU()\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.sum_weight\n        x = self.norm(x)\n        x = self.avg_pool(x)\n        x = self.gelu(x)\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = (3, 3, 3)\nstride = (2, 2, 2)\npadding = (1, 1, 1)\noutput_padding = (1, 1, 1)\nsum_weight = 1.0\nnorm_shape = (out_channels,)\npool_kernel_size = (2, 2, 2)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, sum_weight, norm_shape, pool_kernel_size]"}}
{"task_id": "L2_4", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Mish, and another Mish.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size   = 64  \nin_channels  = 64  \nout_channels = 128  \nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Mish, and another Mish.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size   = 64  \nin_channels  = 64  \nout_channels = 128  \nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 4, "problem_name": "4_Conv2d_Mish_Mish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Mish, and another Mish.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size   = 64  \nin_channels  = 64  \nout_channels = 128  \nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}}
{"task_id": "L2_5", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, subtracts a bias term, and applies tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape, stride=2, padding=1, output_padding=1):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x - self.bias\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 32\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256 \nkernel_size = 4\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, subtracts a bias term, and applies tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape, stride=2, padding=1, output_padding=1):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x - self.bias\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 32\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256 \nkernel_size = 4\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 5, "problem_name": "5_ConvTranspose2d_Subtract_Tanh.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, subtracts a bias term, and applies tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape, stride=2, padding=1, output_padding=1):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x - self.bias\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 32\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256 \nkernel_size = 4\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]"}}
{"task_id": "L2_6", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Softmax, and performs two max pooling operations.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.pool1 = nn.MaxPool3d(pool_kernel_size)\n        self.pool2 = nn.MaxPool3d(pool_kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, depth, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels, depth', height', width') where depth', height', width' are the dimensions after pooling.\n        \"\"\"\n        x = self.conv(x)\n        x = torch.softmax(x, dim=1)\n        x = self.pool1(x)\n        x = self.pool2(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\npool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Softmax, and performs two max pooling operations.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.pool1 = nn.MaxPool3d(pool_kernel_size)\n        self.pool2 = nn.MaxPool3d(pool_kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, depth, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels, depth', height', width') where depth', height', width' are the dimensions after pooling.\n        \"\"\"\n        x = self.conv(x)\n        x = torch.softmax(x, dim=1)\n        x = self.pool1(x)\n        x = self.pool2(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\npool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 6, "problem_name": "6_Conv3d_Softmax_MaxPool_MaxPool.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Softmax, and performs two max pooling operations.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.pool1 = nn.MaxPool3d(pool_kernel_size)\n        self.pool2 = nn.MaxPool3d(pool_kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, depth, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels, depth', height', width') where depth', height', width' are the dimensions after pooling.\n        \"\"\"\n        x = self.conv(x)\n        x = torch.softmax(x, dim=1)\n        x = self.pool1(x)\n        x = self.pool2(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\npool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]"}}
{"task_id": "L2_7", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies ReLU, LeakyReLU, GELU, Sigmoid activations, and bias in sequence.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        x = torch.nn.functional.gelu(x)\n        x = torch.sigmoid(x)\n        x = x + self.bias\n        return x\n\nbatch_size = 64\nin_channels = 8\nout_channels = 32\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies ReLU, LeakyReLU, GELU, Sigmoid activations, and bias in sequence.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        x = torch.nn.functional.gelu(x)\n        x = torch.sigmoid(x)\n        x = x + self.bias\n        return x\n\nbatch_size = 64\nin_channels = 8\nout_channels = 32\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 7, "problem_name": "7_Conv3d_ReLU_LeakyReLU_GELU_Sigmoid_BiasAdd.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies ReLU, LeakyReLU, GELU, Sigmoid activations, and bias in sequence.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        x = torch.nn.functional.gelu(x)\n        x = torch.sigmoid(x)\n        x = x + self.bias\n        return x\n\nbatch_size = 64\nin_channels = 8\nout_channels = 32\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]"}}
{"task_id": "L2_8", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, divides by a constant, applies max pooling,\n    global average pooling, adds a bias term, and sums along a specific dimension.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divisor, pool_size, bias_shape, sum_dim):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.divisor = divisor\n        self.max_pool = nn.MaxPool3d(pool_size)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.sum_dim = sum_dim\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x / self.divisor\n        x = self.max_pool(x)\n        x = self.global_avg_pool(x)\n        x = x + self.bias\n        x = torch.sum(x, dim=self.sum_dim)\n        return x\n\nbatch_size   = 128  \nin_channels  = 8            \nout_channels = 16  \ndepth = 16; height = width = 64 \nkernel_size = (3, 3, 3)\ndivisor = 2.0\npool_size = (2, 2, 2)\nbias_shape = (out_channels, 1, 1, 1)\nsum_dim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor, pool_size, bias_shape, sum_dim]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, divides by a constant, applies max pooling,\n    global average pooling, adds a bias term, and sums along a specific dimension.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divisor, pool_size, bias_shape, sum_dim):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.divisor = divisor\n        self.max_pool = nn.MaxPool3d(pool_size)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.sum_dim = sum_dim\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x / self.divisor\n        x = self.max_pool(x)\n        x = self.global_avg_pool(x)\n        x = x + self.bias\n        x = torch.sum(x, dim=self.sum_dim)\n        return x\n\nbatch_size   = 128  \nin_channels  = 8            \nout_channels = 16  \ndepth = 16; height = width = 64 \nkernel_size = (3, 3, 3)\ndivisor = 2.0\npool_size = (2, 2, 2)\nbias_shape = (out_channels, 1, 1, 1)\nsum_dim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor, pool_size, bias_shape, sum_dim]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 8, "problem_name": "8_Conv3d_Divide_Max_GlobalAvgPool_BiasAdd_Sum.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, divides by a constant, applies max pooling,\n    global average pooling, adds a bias term, and sums along a specific dimension.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divisor, pool_size, bias_shape, sum_dim):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.divisor = divisor\n        self.max_pool = nn.MaxPool3d(pool_size)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.sum_dim = sum_dim\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x / self.divisor\n        x = self.max_pool(x)\n        x = self.global_avg_pool(x)\n        x = x + self.bias\n        x = torch.sum(x, dim=self.sum_dim)\n        return x\n\nbatch_size   = 128  \nin_channels  = 8            \nout_channels = 16  \ndepth = 16; height = width = 64 \nkernel_size = (3, 3, 3)\ndivisor = 2.0\npool_size = (2, 2, 2)\nbias_shape = (out_channels, 1, 1, 1)\nsum_dim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor, pool_size, bias_shape, sum_dim]"}}
{"task_id": "L2_9", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, subtraction, multiplication, and ReLU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = x - self.subtract_value\n        x = x * self.multiply_value\n        x = torch.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, subtraction, multiplication, and ReLU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = x - self.subtract_value\n        x = x * self.multiply_value\n        x = torch.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 9, "problem_name": "9_Matmul_Subtract_Multiply_ReLU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, subtraction, multiplication, and ReLU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = x - self.subtract_value\n        x = x * self.multiply_value\n        x = torch.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]"}}
{"task_id": "L2_10", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, followed by max pooling, hardtanh activation, mean operation, and tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.maxpool = nn.MaxPool2d(kernel_size=maxpool_kernel_size, stride=maxpool_stride)\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.maxpool(x)\n        x = self.hardtanh(x)\n        x = torch.mean(x, dim=(2, 3), keepdim=True)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride = 1\npadding = 1\nmaxpool_kernel_size = 2\nmaxpool_stride = 2\nhardtanh_min = -1\nhardtanh_max = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, followed by max pooling, hardtanh activation, mean operation, and tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.maxpool = nn.MaxPool2d(kernel_size=maxpool_kernel_size, stride=maxpool_stride)\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.maxpool(x)\n        x = self.hardtanh(x)\n        x = torch.mean(x, dim=(2, 3), keepdim=True)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride = 1\npadding = 1\nmaxpool_kernel_size = 2\nmaxpool_stride = 2\nhardtanh_min = -1\nhardtanh_max = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 10, "problem_name": "10_ConvTranspose2d_MaxPool_Hardtanh_Mean_Tanh.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, followed by max pooling, hardtanh activation, mean operation, and tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.maxpool = nn.MaxPool2d(kernel_size=maxpool_kernel_size, stride=maxpool_stride)\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.maxpool(x)\n        x = self.hardtanh(x)\n        x = torch.mean(x, dim=(2, 3), keepdim=True)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride = 1\npadding = 1\nmaxpool_kernel_size = 2\nmaxpool_stride = 2\nhardtanh_min = -1\nhardtanh_max = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max]"}}
{"task_id": "L2_11", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, batch normalization, tanh activation, max pooling, and group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, num_groups):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n        self.tanh = nn.Tanh()\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = self.tanh(x)\n        x = self.max_pool(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 512\nin_channels  = 64  \nout_channels = 128  \nheight = width = 2048  \nkernel_size  = 5\nstride       = 1  \npadding      = 1\ngroups       = 8\nnum_groups   = 8\nheight, width = 32, 32\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, num_groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, batch normalization, tanh activation, max pooling, and group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, num_groups):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n        self.tanh = nn.Tanh()\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = self.tanh(x)\n        x = self.max_pool(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 512\nin_channels  = 64  \nout_channels = 128  \nheight = width = 2048  \nkernel_size  = 5\nstride       = 1  \npadding      = 1\ngroups       = 8\nnum_groups   = 8\nheight, width = 32, 32\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, num_groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 11, "problem_name": "11_ConvTranspose2d_BatchNorm_Tanh_MaxPool_GroupNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, batch normalization, tanh activation, max pooling, and group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, num_groups):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n        self.tanh = nn.Tanh()\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = self.tanh(x)\n        x = self.max_pool(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 512\nin_channels  = 64  \nout_channels = 128  \nheight = width = 2048  \nkernel_size  = 5\nstride       = 1  \npadding      = 1\ngroups       = 8\nnum_groups   = 8\nheight, width = 32, 32\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, num_groups]"}}
{"task_id": "L2_12", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Gemm, multiplies the result, and applies LeakyReLU.\n    \"\"\"\n    def __init__(self, in_features, out_features, multiplier, negative_slope):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.multiplier = multiplier\n        self.leaky_relu = nn.LeakyReLU(negative_slope)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        return x\n\nbatch_size = 1024\nin_features  = 8192  \nout_features = 8192\nmultiplier = 2.0\nnegative_slope = 0.1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, multiplier, negative_slope]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Gemm, multiplies the result, and applies LeakyReLU.\n    \"\"\"\n    def __init__(self, in_features, out_features, multiplier, negative_slope):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.multiplier = multiplier\n        self.leaky_relu = nn.LeakyReLU(negative_slope)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        return x\n\nbatch_size = 1024\nin_features  = 8192  \nout_features = 8192\nmultiplier = 2.0\nnegative_slope = 0.1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, multiplier, negative_slope]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 12, "problem_name": "12_Gemm_Multiply_LeakyReLU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a Gemm, multiplies the result, and applies LeakyReLU.\n    \"\"\"\n    def __init__(self, in_features, out_features, multiplier, negative_slope):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.multiplier = multiplier\n        self.leaky_relu = nn.LeakyReLU(negative_slope)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        return x\n\nbatch_size = 1024\nin_features  = 8192  \nout_features = 8192\nmultiplier = 2.0\nnegative_slope = 0.1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, multiplier, negative_slope]"}}
{"task_id": "L2_13", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations:\n    1. Transposed 3D convolution\n    2. Mean pooling (across depth)\n    3. Addition\n    4. Softmax (across channels)\n    5. Tanh activation\n    6. Scaling\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.bias = nn.Parameter(torch.randn(1, out_channels, 1, 1, 1))  # Broadcastable bias over channels\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)                            # (B, C, D, H, W)\n        x = x.mean(dim=2, keepdim=True)                       # Mean pool over depth dim (D)\n        x = x + self.bias                                     # Bias add per channel\n        x = torch.softmax(x, dim=1)                           # Softmax over channels\n        x = torch.tanh(x)                                     # Nonlinearity\n        x = x * self.scaling_factor                           # Scaling\n        return x\n\n# === Test config ===\nbatch_size = 16\nin_channels  = 16  \nout_channels = 64  \ndepth = 32; height = width = 128  \nkernel_size  = 3\nstride       = 1  \npadding = 1\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scaling_factor]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations:\n    1. Transposed 3D convolution\n    2. Mean pooling (across depth)\n    3. Addition\n    4. Softmax (across channels)\n    5. Tanh activation\n    6. Scaling\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.bias = nn.Parameter(torch.randn(1, out_channels, 1, 1, 1))  # Broadcastable bias over channels\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)                            # (B, C, D, H, W)\n        x = x.mean(dim=2, keepdim=True)                       # Mean pool over depth dim (D)\n        x = x + self.bias                                     # Bias add per channel\n        x = torch.softmax(x, dim=1)                           # Softmax over channels\n        x = torch.tanh(x)                                     # Nonlinearity\n        x = x * self.scaling_factor                           # Scaling\n        return x\n\n# === Test config ===\nbatch_size = 16\nin_channels  = 16  \nout_channels = 64  \ndepth = 32; height = width = 128  \nkernel_size  = 3\nstride       = 1  \npadding = 1\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scaling_factor]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 13, "problem_name": "13_ConvTranspose3d_Mean_Add_Softmax_Tanh_Scaling.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations:\n    1. Transposed 3D convolution\n    2. Mean pooling (across depth)\n    3. Addition\n    4. Softmax (across channels)\n    5. Tanh activation\n    6. Scaling\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.bias = nn.Parameter(torch.randn(1, out_channels, 1, 1, 1))  # Broadcastable bias over channels\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)                            # (B, C, D, H, W)\n        x = x.mean(dim=2, keepdim=True)                       # Mean pool over depth dim (D)\n        x = x + self.bias                                     # Bias add per channel\n        x = torch.softmax(x, dim=1)                           # Softmax over channels\n        x = torch.tanh(x)                                     # Nonlinearity\n        x = x * self.scaling_factor                           # Scaling\n        return x\n\n# === Test config ===\nbatch_size = 16\nin_channels  = 16  \nout_channels = 64  \ndepth = 32; height = width = 128  \nkernel_size  = 3\nstride       = 1  \npadding = 1\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scaling_factor]\n"}}
{"task_id": "L2_14", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, division, summation, and scaling.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scaling_factor):\n        super(Model, self).__init__()\n        self.weight = nn.Parameter(torch.randn(hidden_size, input_size))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = torch.matmul(x, self.weight.T)  # Gemm\n        x = x / 2  # Divide\n        x = torch.sum(x, dim=1, keepdim=True) # Sum\n        x = x * self.scaling_factor  # Scaling\n        return x\n\n\nbatch_size   = 1024  \ninput_size   = 8192  \nhidden_size  = 8192 \nscaling_factor = 1.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, division, summation, and scaling.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scaling_factor):\n        super(Model, self).__init__()\n        self.weight = nn.Parameter(torch.randn(hidden_size, input_size))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = torch.matmul(x, self.weight.T)  # Gemm\n        x = x / 2  # Divide\n        x = torch.sum(x, dim=1, keepdim=True) # Sum\n        x = x * self.scaling_factor  # Scaling\n        return x\n\n\nbatch_size   = 1024  \ninput_size   = 8192  \nhidden_size  = 8192 \nscaling_factor = 1.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 14, "problem_name": "14_Gemm_Divide_Sum_Scaling.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, division, summation, and scaling.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scaling_factor):\n        super(Model, self).__init__()\n        self.weight = nn.Parameter(torch.randn(hidden_size, input_size))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = torch.matmul(x, self.weight.T)  # Gemm\n        x = x / 2  # Divide\n        x = torch.sum(x, dim=1, keepdim=True) # Sum\n        x = x * self.scaling_factor  # Scaling\n        return x\n\n\nbatch_size   = 1024  \ninput_size   = 8192  \nhidden_size  = 8192 \nscaling_factor = 1.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]"}}
{"task_id": "L2_15", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional transpose layer followed by Batch Normalization and subtraction.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.batch_norm = nn.BatchNorm3d(out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = x - torch.mean(x, dim=(2, 3, 4), keepdim=True)  # Subtract mean along spatial dimensions\n        return x\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional transpose layer followed by Batch Normalization and subtraction.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.batch_norm = nn.BatchNorm3d(out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = x - torch.mean(x, dim=(2, 3, 4), keepdim=True)  # Subtract mean along spatial dimensions\n        return x\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 15, "problem_name": "15_ConvTranspose3d_BatchNorm_Subtract.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional transpose layer followed by Batch Normalization and subtraction.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.batch_norm = nn.BatchNorm3d(out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = x - torch.mean(x, dim=(2, 3, 4), keepdim=True)  # Subtract mean along spatial dimensions\n        return x\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]"}}
{"task_id": "L2_16", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies Mish activation, adds a value, \n    applies Hardtanh activation, and scales the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n        self.add_value = add_value\n        self.scale = scale\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.nn.functional.mish(x) # Mish activation\n        x = x + self.add_value\n        x = torch.nn.functional.hardtanh(x, min_val=-1, max_val=1) # Hardtanh activation\n        x = x * self.scale # Scaling\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128  \nkernel_size  = 3\nstride       = 2  \npadding      = 1\noutput_padding = 1\nadd_value = 0.5\nscale = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies Mish activation, adds a value, \n    applies Hardtanh activation, and scales the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n        self.add_value = add_value\n        self.scale = scale\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.nn.functional.mish(x) # Mish activation\n        x = x + self.add_value\n        x = torch.nn.functional.hardtanh(x, min_val=-1, max_val=1) # Hardtanh activation\n        x = x * self.scale # Scaling\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128  \nkernel_size  = 3\nstride       = 2  \npadding      = 1\noutput_padding = 1\nadd_value = 0.5\nscale = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 16, "problem_name": "16_ConvTranspose2d_Mish_Add_Hardtanh_Scaling.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies Mish activation, adds a value, \n    applies Hardtanh activation, and scales the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n        self.add_value = add_value\n        self.scale = scale\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.nn.functional.mish(x) # Mish activation\n        x = x + self.add_value\n        x = torch.nn.functional.hardtanh(x, min_val=-1, max_val=1) # Hardtanh activation\n        x = x * self.scale # Scaling\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 64  \nheight = width = 128  \nkernel_size  = 3\nstride       = 2  \npadding      = 1\noutput_padding = 1\nadd_value = 0.5\nscale = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale]"}}
{"task_id": "L2_17", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Instance Normalization, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.instance_norm = nn.InstanceNorm2d(out_channels)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.instance_norm(x)\n        x = x / self.divide_by\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128  \nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Instance Normalization, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.instance_norm = nn.InstanceNorm2d(out_channels)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.instance_norm(x)\n        x = x / self.divide_by\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128  \nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 17, "problem_name": "17_Conv2d_InstanceNorm_Divide.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Instance Normalization, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.instance_norm = nn.InstanceNorm2d(out_channels)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.instance_norm(x)\n        x = x / self.divide_by\n        return x\n\nbatch_size = 128\nin_channels  = 64  \nout_channels = 128  \nheight = width = 128  \nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]"}}
{"task_id": "L2_18", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a sequence of operations:\n        - Matrix multiplication\n        - Summation\n        - Max\n        - Average pooling\n        - LogSumExp\n        - LogSumExp\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.linear(x)  # (batch_size, out_features)\n        x = torch.sum(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.max(x, dim=1, keepdim=True)[0] # (batch_size, 1)\n        x = torch.mean(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.logsumexp(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.logsumexp(x, dim=1, keepdim=True) # (batch_size, 1)\n        return x\n\nbatch_size = 1024\nin_features  = 8192  \nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a sequence of operations:\n        - Matrix multiplication\n        - Summation\n        - Max\n        - Average pooling\n        - LogSumExp\n        - LogSumExp\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.linear(x)  # (batch_size, out_features)\n        x = torch.sum(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.max(x, dim=1, keepdim=True)[0] # (batch_size, 1)\n        x = torch.mean(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.logsumexp(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.logsumexp(x, dim=1, keepdim=True) # (batch_size, 1)\n        return x\n\nbatch_size = 1024\nin_features  = 8192  \nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 18, "problem_name": "18_Matmul_Sum_Max_AvgPool_LogSumExp_LogSumExp.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a sequence of operations:\n        - Matrix multiplication\n        - Summation\n        - Max\n        - Average pooling\n        - LogSumExp\n        - LogSumExp\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.linear(x)  # (batch_size, out_features)\n        x = torch.sum(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.max(x, dim=1, keepdim=True)[0] # (batch_size, 1)\n        x = torch.mean(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.logsumexp(x, dim=1, keepdim=True) # (batch_size, 1)\n        x = torch.logsumexp(x, dim=1, keepdim=True) # (batch_size, 1)\n        return x\n\nbatch_size = 1024\nin_features  = 8192  \nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}}
{"task_id": "L2_19", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies GELU, and normalizes with GroupNorm.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, num_groups):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.nn.functional.gelu(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size   = 128  \nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride       = 1\ngroups = 8\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, groups, num_groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies GELU, and normalizes with GroupNorm.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, num_groups):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.nn.functional.gelu(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size   = 128  \nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride       = 1\ngroups = 8\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, groups, num_groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 19, "problem_name": "19_ConvTranspose2d_GELU_GroupNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies GELU, and normalizes with GroupNorm.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, num_groups):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.nn.functional.gelu(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size   = 128  \nin_channels  = 64  \nout_channels = 64  \nheight = width = 256  \nkernel_size  = 3\nstride       = 1\ngroups = 8\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, groups, num_groups]"}}
{"task_id": "L2_20", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by a sum, \n    a residual add, a multiplication, and another residual add.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        original_x = x.clone().detach()\n        x = x + self.bias\n        x = x + original_x\n        x = x * original_x\n        x = x + original_x\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by a sum, \n    a residual add, a multiplication, and another residual add.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        original_x = x.clone().detach()\n        x = x + self.bias\n        x = x + original_x\n        x = x * original_x\n        x = x + original_x\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 20, "problem_name": "20_ConvTranspose3d_Sum_ResidualAdd_Multiply_ResidualAdd.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by a sum, \n    a residual add, a multiplication, and another residual add.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        original_x = x.clone().detach()\n        x = x + self.bias\n        x = x + original_x\n        x = x * original_x\n        x = x + original_x\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]"}}
{"task_id": "L2_21", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, adds a bias term, scales, applies sigmoid, and performs group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups, bias_shape, scale_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x + self.bias\n        x = x * self.scale\n        x = torch.sigmoid(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 32\nheight = width = 256\nkernel_size = 3\nnum_groups = 8\nbias_shape = (out_channels, 1, 1)\nscale_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, bias_shape, scale_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, adds a bias term, scales, applies sigmoid, and performs group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups, bias_shape, scale_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x + self.bias\n        x = x * self.scale\n        x = torch.sigmoid(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 32\nheight = width = 256\nkernel_size = 3\nnum_groups = 8\nbias_shape = (out_channels, 1, 1)\nscale_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, bias_shape, scale_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 21, "problem_name": "21_Conv2d_Add_Scale_Sigmoid_GroupNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, adds a bias term, scales, applies sigmoid, and performs group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups, bias_shape, scale_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x + self.bias\n        x = x * self.scale\n        x = torch.sigmoid(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 32\nheight = width = 256\nkernel_size = 3\nnum_groups = 8\nbias_shape = (out_channels, 1, 1)\nscale_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, bias_shape, scale_shape]"}}
{"task_id": "L2_22", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, scales the result, adds a residual connection, clamps the output,\n    applies LogSumExp, and finally applies the Mish activation function.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scale_factor, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(input_size, hidden_size)\n        self.scale_factor = scale_factor\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.matmul(x)\n        x = x * self.scale_factor\n        x = x + x\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = x * torch.nn.functional.mish(x)  # Mish activation\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscale_factor = 2.0\nclamp_min = -10.0\nclamp_max = 10.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scale_factor, clamp_min, clamp_max]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, scales the result, adds a residual connection, clamps the output,\n    applies LogSumExp, and finally applies the Mish activation function.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scale_factor, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(input_size, hidden_size)\n        self.scale_factor = scale_factor\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.matmul(x)\n        x = x * self.scale_factor\n        x = x + x\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = x * torch.nn.functional.mish(x)  # Mish activation\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscale_factor = 2.0\nclamp_min = -10.0\nclamp_max = 10.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scale_factor, clamp_min, clamp_max]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 22, "problem_name": "22_Matmul_Scale_ResidualAdd_Clamp_LogSumExp_Mish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, scales the result, adds a residual connection, clamps the output,\n    applies LogSumExp, and finally applies the Mish activation function.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scale_factor, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(input_size, hidden_size)\n        self.scale_factor = scale_factor\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.matmul(x)\n        x = x * self.scale_factor\n        x = x + x\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = x * torch.nn.functional.mish(x)  # Mish activation\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscale_factor = 2.0\nclamp_min = -10.0\nclamp_max = 10.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scale_factor, clamp_min, clamp_max]"}}
{"task_id": "L2_23", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, computes the mean\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.conv(x)\n        x = self.group_norm(x)\n        x = x.mean(dim=[1, 2, 3, 4]) # Compute mean across all dimensions except batch\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24\nD, H, W = 24, 32, 32\nkernel_size = 3\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, computes the mean\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.conv(x)\n        x = self.group_norm(x)\n        x = x.mean(dim=[1, 2, 3, 4]) # Compute mean across all dimensions except batch\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24\nD, H, W = 24, 32, 32\nkernel_size = 3\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 23, "problem_name": "23_Conv3d_GroupNorm_Mean.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, computes the mean\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.conv(x)\n        x = self.group_norm(x)\n        x = x.mean(dim=[1, 2, 3, 4]) # Compute mean across all dimensions except batch\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24\nD, H, W = 24, 32, 32\nkernel_size = 3\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups]"}}
{"task_id": "L2_24", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a 3D convolution, applies minimum operation along a specific dimension, \n    and then applies softmax.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, dim):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W)\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, H, W)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.min(x, dim=self.dim)[0]  # Apply minimum along the specified dimension\n        x = torch.softmax(x, dim=1)  # Apply softmax along the channel dimension\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24  # Increased output channels\nD, H, W = 24, 32, 32  # Increased depth\nkernel_size = 3\ndim = 2  # Dimension along which to apply minimum operation (e.g., depth)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, dim]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a 3D convolution, applies minimum operation along a specific dimension, \n    and then applies softmax.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, dim):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W)\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, H, W)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.min(x, dim=self.dim)[0]  # Apply minimum along the specified dimension\n        x = torch.softmax(x, dim=1)  # Apply softmax along the channel dimension\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24  # Increased output channels\nD, H, W = 24, 32, 32  # Increased depth\nkernel_size = 3\ndim = 2  # Dimension along which to apply minimum operation (e.g., depth)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, dim]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 24, "problem_name": "24_Conv3d_Min_Softmax.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a 3D convolution, applies minimum operation along a specific dimension, \n    and then applies softmax.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, dim):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.dim = dim\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W)\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, H, W)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.min(x, dim=self.dim)[0]  # Apply minimum along the specified dimension\n        x = torch.softmax(x, dim=1)  # Apply softmax along the channel dimension\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 24  # Increased output channels\nD, H, W = 24, 32, 32  # Increased depth\nkernel_size = 3\ndim = 2  # Dimension along which to apply minimum operation (e.g., depth)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, dim]"}}
{"task_id": "L2_25", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies minimum operation, Tanh, and another Tanh.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.min(x, dim=1, keepdim=True)[0] # Apply minimum operation along the channel dimension\n        x = torch.tanh(x)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 128\nin_channels = 16\nout_channels = 64\nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies minimum operation, Tanh, and another Tanh.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.min(x, dim=1, keepdim=True)[0] # Apply minimum operation along the channel dimension\n        x = torch.tanh(x)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 128\nin_channels = 16\nout_channels = 64\nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 25, "problem_name": "25_Conv2d_Min_Tanh_Tanh.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies minimum operation, Tanh, and another Tanh.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.min(x, dim=1, keepdim=True)[0] # Apply minimum operation along the channel dimension\n        x = torch.tanh(x)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 128\nin_channels = 16\nout_channels = 64\nheight = width = 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}}
{"task_id": "L2_26", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, adds an input tensor, and applies HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x, add_input):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n            add_input (torch.Tensor): Input tensor to be added after transposed convolution, of shape (batch_size, out_channels, D, H, W).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W) after HardSwish activation.\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = x + add_input\n        x = x * torch.nn.functional.hardswish(x)\n        return x\n\n\nbatch_size = 128\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 16, 16\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W), torch.rand(batch_size, out_channels, D*stride, H*stride, W*stride)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, adds an input tensor, and applies HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x, add_input):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n            add_input (torch.Tensor): Input tensor to be added after transposed convolution, of shape (batch_size, out_channels, D, H, W).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W) after HardSwish activation.\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = x + add_input\n        x = x * torch.nn.functional.hardswish(x)\n        return x\n\n\nbatch_size = 128\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 16, 16\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W), torch.rand(batch_size, out_channels, D*stride, H*stride, W*stride)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 26, "problem_name": "26_ConvTranspose3d_Add_HardSwish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, adds an input tensor, and applies HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x, add_input):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n            add_input (torch.Tensor): Input tensor to be added after transposed convolution, of shape (batch_size, out_channels, D, H, W).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W) after HardSwish activation.\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = x + add_input\n        x = x * torch.nn.functional.hardswish(x)\n        return x\n\n\nbatch_size = 128\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 16, 16\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W), torch.rand(batch_size, out_channels, D*stride, H*stride, W*stride)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]"}}
{"task_id": "L2_27", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs:\n    1. Conv3D\n    2. HardSwish activation\n    3. GroupNorm  \n    4. Mean pooling across spatial dimensions\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups=4, bias=True):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, bias=bias)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)                             # (B, C, D, H, W)\n        x = F.hardswish(x)                           # Nonlinear activation\n        x = self.group_norm(x)                       # Normalization over channels\n        x = torch.mean(x, dim=[2, 3, 4])             # Mean over spatial dims \u2192 (B, C)\n        return x\n\n# === Test config ===\nbatch_size = 1024\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs:\n    1. Conv3D\n    2. HardSwish activation\n    3. GroupNorm  \n    4. Mean pooling across spatial dimensions\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups=4, bias=True):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, bias=bias)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)                             # (B, C, D, H, W)\n        x = F.hardswish(x)                           # Nonlinear activation\n        x = self.group_norm(x)                       # Normalization over channels\n        x = torch.mean(x, dim=[2, 3, 4])             # Mean over spatial dims \u2192 (B, C)\n        return x\n\n# === Test config ===\nbatch_size = 1024\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 27, "problem_name": "27_Conv3d_HardSwish_GroupNorm_Mean.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs:\n    1. Conv3D\n    2. HardSwish activation\n    3. GroupNorm  \n    4. Mean pooling across spatial dimensions\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups=4, bias=True):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, bias=bias)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)                             # (B, C, D, H, W)\n        x = F.hardswish(x)                           # Nonlinear activation\n        x = self.group_norm(x)                       # Normalization over channels\n        x = torch.mean(x, dim=[2, 3, 4])             # Mean over spatial dims \u2192 (B, C)\n        return x\n\n# === Test config ===\nbatch_size = 1024\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}}
{"task_id": "L2_28", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a batch matrix multiplication, instance normalization, summation, residual addition, and multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.bmm = nn.Linear(in_features, out_features)\n        self.instance_norm = nn.InstanceNorm2d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x, y):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n            y (torch.Tensor): Input tensor of shape (batch_size, out_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.bmm(x)\n        x = self.instance_norm(x.unsqueeze(1).unsqueeze(1)).squeeze(1).squeeze(1)\n        x = x + y\n        x = x * y\n        return x\n\nbatch_size = 1024  # Increased batch size\nin_features = 8192  # Increased input features\nout_features = 8192  # Increased output features\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features), torch.rand(batch_size, out_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a batch matrix multiplication, instance normalization, summation, residual addition, and multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.bmm = nn.Linear(in_features, out_features)\n        self.instance_norm = nn.InstanceNorm2d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x, y):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n            y (torch.Tensor): Input tensor of shape (batch_size, out_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.bmm(x)\n        x = self.instance_norm(x.unsqueeze(1).unsqueeze(1)).squeeze(1).squeeze(1)\n        x = x + y\n        x = x * y\n        return x\n\nbatch_size = 1024  # Increased batch size\nin_features = 8192  # Increased input features\nout_features = 8192  # Increased output features\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features), torch.rand(batch_size, out_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 28, "problem_name": "28_BMM_InstanceNorm_Sum_ResidualAdd_Multiply.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a batch matrix multiplication, instance normalization, summation, residual addition, and multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.bmm = nn.Linear(in_features, out_features)\n        self.instance_norm = nn.InstanceNorm2d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x, y):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n            y (torch.Tensor): Input tensor of shape (batch_size, out_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.bmm(x)\n        x = self.instance_norm(x.unsqueeze(1).unsqueeze(1)).squeeze(1).squeeze(1)\n        x = x + y\n        x = x * y\n        return x\n\nbatch_size = 1024  # Increased batch size\nin_features = 8192  # Increased input features\nout_features = 8192  # Increased output features\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features), torch.rand(batch_size, out_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}}
{"task_id": "L2_29", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Mish, and applies Mish again.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Mish, and applies Mish again.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 29, "problem_name": "29_Matmul_Mish_Mish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Mish, and applies Mish again.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}}
{"task_id": "L2_30", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GEMM, applies Group Normalization, and then HardTanh.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.group_norm(x)\n        x = self.hardtanh(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 16\nhardtanh_min = -2.0\nhardtanh_max = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, hardtanh_min, hardtanh_max]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GEMM, applies Group Normalization, and then HardTanh.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.group_norm(x)\n        x = self.hardtanh(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 16\nhardtanh_min = -2.0\nhardtanh_max = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, hardtanh_min, hardtanh_max]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 30, "problem_name": "30_Gemm_GroupNorm_Hardtanh.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GEMM, applies Group Normalization, and then HardTanh.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.group_norm(x)\n        x = self.hardtanh(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 16\nhardtanh_min = -2.0\nhardtanh_max = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, hardtanh_min, hardtanh_max]"}}
{"task_id": "L2_31", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, takes the minimum with a constant, adds a bias term, and multiplies by a scaling factor.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.min(x, torch.tensor(self.constant_value))\n        x = x + self.bias\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight = width = 128\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, takes the minimum with a constant, adds a bias term, and multiplies by a scaling factor.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.min(x, torch.tensor(self.constant_value))\n        x = x + self.bias\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight = width = 128\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 31, "problem_name": "31_Conv2d_Min_Add_Multiply.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, takes the minimum with a constant, adds a bias term, and multiplies by a scaling factor.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.min(x, torch.tensor(self.constant_value))\n        x = x + self.bias\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight = width = 128\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]"}}
{"task_id": "L2_32", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, scales the output, and then applies a minimum operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        x = self.conv(x)\n        x = x * self.scale_factor\n        x = torch.min(x, dim=1, keepdim=True)[0]  # Minimum along channel dimension\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight = width = 256\nkernel_size = 3\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, scales the output, and then applies a minimum operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        x = self.conv(x)\n        x = x * self.scale_factor\n        x = torch.min(x, dim=1, keepdim=True)[0]  # Minimum along channel dimension\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight = width = 256\nkernel_size = 3\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 32, "problem_name": "32_Conv2d_Scaling_Min.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, scales the output, and then applies a minimum operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        x = self.conv(x)\n        x = x * self.scale_factor\n        x = torch.min(x, dim=1, keepdim=True)[0]  # Minimum along channel dimension\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight = width = 256\nkernel_size = 3\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]"}}
{"task_id": "L2_33", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GEMM (general matrix multiplication), applies scaling, \n    and then batch normalization.\n    \"\"\"\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scale\n        x = self.bn(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GEMM (general matrix multiplication), applies scaling, \n    and then batch normalization.\n    \"\"\"\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scale\n        x = self.bn(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 33, "problem_name": "33_Gemm_Scale_BatchNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a GEMM (general matrix multiplication), applies scaling, \n    and then batch normalization.\n    \"\"\"\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scale\n        x = self.bn(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]"}}
{"task_id": "L2_34", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, layer normalization, GELU activation, and scaling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=True, eps=1e-5, scaling_factor=1.0):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.layer_norm = nn.LayerNorm(out_channels, eps=eps)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D', H', W').\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.layer_norm(x)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 4\nstride = 2\npadding = 1\nbias = True\neps = 1e-5\nscaling_factor = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias, eps, scaling_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, layer normalization, GELU activation, and scaling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=True, eps=1e-5, scaling_factor=1.0):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.layer_norm = nn.LayerNorm(out_channels, eps=eps)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D', H', W').\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.layer_norm(x)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 4\nstride = 2\npadding = 1\nbias = True\neps = 1e-5\nscaling_factor = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias, eps, scaling_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 34, "problem_name": "34_ConvTranspose3d_LayerNorm_GELU_Scaling.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, layer normalization, GELU activation, and scaling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=True, eps=1e-5, scaling_factor=1.0):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.layer_norm = nn.LayerNorm(out_channels, eps=eps)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D', H', W').\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.layer_norm(x)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 4\nstride = 2\npadding = 1\nbias = True\neps = 1e-5\nscaling_factor = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias, eps, scaling_factor]"}}
{"task_id": "L2_35", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtracts a value, applies HardSwish, MaxPool, and Mish activation functions.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract_value, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract_value = subtract_value\n        self.pool = nn.MaxPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract_value\n        x = torch.nn.functional.hardswish(x)\n        x = self.pool(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight = width = 128\nkernel_size = 3\nsubtract_value = 0.5\npool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract_value, pool_kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtracts a value, applies HardSwish, MaxPool, and Mish activation functions.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract_value, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract_value = subtract_value\n        self.pool = nn.MaxPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract_value\n        x = torch.nn.functional.hardswish(x)\n        x = self.pool(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight = width = 128\nkernel_size = 3\nsubtract_value = 0.5\npool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract_value, pool_kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 35, "problem_name": "35_Conv2d_Subtract_HardSwish_MaxPool_Mish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtracts a value, applies HardSwish, MaxPool, and Mish activation functions.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract_value, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract_value = subtract_value\n        self.pool = nn.MaxPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract_value\n        x = torch.nn.functional.hardswish(x)\n        x = self.pool(x)\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight = width = 128\nkernel_size = 3\nsubtract_value = 0.5\npool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract_value, pool_kernel_size]"}}
{"task_id": "L2_36", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution transpose, minimum operation, sum operation, GELU activation and addition.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.min(x, dim=1, keepdim=True)[0]  # Minimum operation along channel dimension\n        x = torch.sum(x, dim=2, keepdim=True)  # Sum operation along height dimension\n        x = torch.nn.functional.gelu(x)  # GELU activation\n        x = x + self.bias\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution transpose, minimum operation, sum operation, GELU activation and addition.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.min(x, dim=1, keepdim=True)[0]  # Minimum operation along channel dimension\n        x = torch.sum(x, dim=2, keepdim=True)  # Sum operation along height dimension\n        x = torch.nn.functional.gelu(x)  # GELU activation\n        x = x + self.bias\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 36, "problem_name": "36_ConvTranspose2d_Min_Sum_GELU_Add.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution transpose, minimum operation, sum operation, GELU activation and addition.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.min(x, dim=1, keepdim=True)[0]  # Minimum operation along channel dimension\n        x = torch.sum(x, dim=2, keepdim=True)  # Sum operation along height dimension\n        x = torch.nn.functional.gelu(x)  # GELU activation\n        x = x + self.bias\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]"}}
{"task_id": "L2_37", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, applies Swish activation, sums with a bias term, and normalizes with GroupNorm.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, bias_shape):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = torch.sigmoid(x) * x  # Swish activation\n        x = x + self.bias\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 32768\nin_features = 1024\nout_features = 4096\nnum_groups = 64\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, applies Swish activation, sums with a bias term, and normalizes with GroupNorm.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, bias_shape):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = torch.sigmoid(x) * x  # Swish activation\n        x = x + self.bias\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 32768\nin_features = 1024\nout_features = 4096\nnum_groups = 64\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 37, "problem_name": "37_Matmul_Swish_Sum_GroupNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, applies Swish activation, sums with a bias term, and normalizes with GroupNorm.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, bias_shape):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = torch.sigmoid(x) * x  # Swish activation\n        x = x + self.bias\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 32768\nin_features = 1024\nout_features = 4096\nnum_groups = 64\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]"}}
{"task_id": "L2_38", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs average pooling, 3D transposed convolution, clamping,\n    spatial softmax, and multiplication by a learnable scale.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool3d(pool_kernel_size)\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n        self.scale = nn.Parameter(torch.ones(1, out_channels, 1, 1, 1))\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth, height, width).\n        \"\"\"\n        x = self.avg_pool(x)\n        x = self.conv_transpose(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        b, c, d, h, w = x.shape\n        x = x.view(b, c, -1)                     # flatten spatial dims\n        x = torch.softmax(x, dim=2)\n        x = x.view(b, c, d, h, w)\n        x = x * self.scale\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs average pooling, 3D transposed convolution, clamping,\n    spatial softmax, and multiplication by a learnable scale.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool3d(pool_kernel_size)\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n        self.scale = nn.Parameter(torch.ones(1, out_channels, 1, 1, 1))\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth, height, width).\n        \"\"\"\n        x = self.avg_pool(x)\n        x = self.conv_transpose(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        b, c, d, h, w = x.shape\n        x = x.view(b, c, -1)                     # flatten spatial dims\n        x = torch.softmax(x, dim=2)\n        x = x.view(b, c, d, h, w)\n        x = x * self.scale\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 38, "problem_name": "38_ConvTranspose3d_AvgPool_Clamp_Softmax_Multiply.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs average pooling, 3D transposed convolution, clamping,\n    spatial softmax, and multiplication by a learnable scale.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.avg_pool = nn.AvgPool3d(pool_kernel_size)\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n        self.scale = nn.Parameter(torch.ones(1, out_channels, 1, 1, 1))\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth, height, width).\n        \"\"\"\n        x = self.avg_pool(x)\n        x = self.conv_transpose(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        b, c, d, h, w = x.shape\n        x = x.view(b, c, -1)                     # flatten spatial dims\n        x = torch.softmax(x, dim=2)\n        x = x.view(b, c, d, h, w)\n        x = x * self.scale\n        return x\n\nbatch_size = 32\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 64, 64\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max]\n"}}
{"task_id": "L2_39", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, scales the result, and applies batch normalization.\n    \"\"\"\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scale\n        x = self.bn(x)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, scales the result, and applies batch normalization.\n    \"\"\"\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scale\n        x = self.bn(x)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 39, "problem_name": "39_Gemm_Scale_BatchNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, scales the result, and applies batch normalization.\n    \"\"\"\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scale\n        x = self.bn(x)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]"}}
{"task_id": "L2_40", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, scaling, and residual addition.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        scaling_factor (float): Scaling factor to apply after matrix multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        original_x = x.clone().detach()\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, scaling, and residual addition.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        scaling_factor (float): Scaling factor to apply after matrix multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        original_x = x.clone().detach()\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 40, "problem_name": "40_Matmul_Scaling_ResidualAdd.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, scaling, and residual addition.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        scaling_factor (float): Scaling factor to apply after matrix multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        original_x = x.clone().detach()\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]"}}
{"task_id": "L2_41", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, BatchNorm, GELU, and ReLU in sequence.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.batch_norm = nn.BatchNorm1d(out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.batch_norm(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, BatchNorm, GELU, and ReLU in sequence.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.batch_norm = nn.BatchNorm1d(out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.batch_norm(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 41, "problem_name": "41_Gemm_BatchNorm_GELU_ReLU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, BatchNorm, GELU, and ReLU in sequence.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.batch_norm = nn.BatchNorm1d(out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.batch_norm(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 16384\nin_features = 4096\nout_features = 4096\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}}
{"task_id": "L2_42", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, global average pooling, adds a bias, applies log-sum-exp, sum, and multiplication.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.mean(x, dim=(2, 3), keepdim=True)  # Global average pooling\n        x = x + self.bias\n        x = torch.logsumexp(x, dim=1, keepdim=True)  # Log-sum-exp\n        x = torch.sum(x, dim=(2, 3))  # Sum\n        x = x * 10.0  # Multiplication\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight = width = 512\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, global average pooling, adds a bias, applies log-sum-exp, sum, and multiplication.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.mean(x, dim=(2, 3), keepdim=True)  # Global average pooling\n        x = x + self.bias\n        x = torch.logsumexp(x, dim=1, keepdim=True)  # Log-sum-exp\n        x = torch.sum(x, dim=(2, 3))  # Sum\n        x = x * 10.0  # Multiplication\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight = width = 512\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 42, "problem_name": "42_ConvTranspose2d_GlobalAvgPool_BiasAdd_LogSumExp_Sum_Multiply.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, global average pooling, adds a bias, applies log-sum-exp, sum, and multiplication.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.mean(x, dim=(2, 3), keepdim=True)  # Global average pooling\n        x = x + self.bias\n        x = torch.logsumexp(x, dim=1, keepdim=True)  # Log-sum-exp\n        x = torch.sum(x, dim=(2, 3))  # Sum\n        x = x * 10.0  # Multiplication\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight = width = 512\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]"}}
{"task_id": "L2_43", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, max pooling, log sum exp, and ReLU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.max_pool = nn.MaxPool3d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, depth, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels, depth', height', width')\n        \"\"\"\n        x = self.conv(x)\n        x = self.max_pool(x)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 4\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 128, 128\nkernel_size = 3\nstride = 1\npadding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, max pooling, log sum exp, and ReLU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.max_pool = nn.MaxPool3d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, depth, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels, depth', height', width')\n        \"\"\"\n        x = self.conv(x)\n        x = self.max_pool(x)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 4\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 128, 128\nkernel_size = 3\nstride = 1\npadding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 43, "problem_name": "43_Conv3d_Max_LogSumExp_ReLU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, max pooling, log sum exp, and ReLU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.max_pool = nn.MaxPool3d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, depth, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels, depth', height', width')\n        \"\"\"\n        x = self.conv(x)\n        x = self.max_pool(x)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 4\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 128, 128\nkernel_size = 3\nstride = 1\npadding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]"}}
{"task_id": "L2_44", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, multiplies by a scalar, applies global average pooling, \n    another global average pooling\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.multiplier = multiplier\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.multiplier\n        x = torch.mean(x, dim=[2, 3], keepdim=True)  # First global average pooling\n        x = torch.mean(x, dim=[2, 3], keepdim=True)  # Second global average pooling\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, multiplies by a scalar, applies global average pooling, \n    another global average pooling\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.multiplier = multiplier\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.multiplier\n        x = torch.mean(x, dim=[2, 3], keepdim=True)  # First global average pooling\n        x = torch.mean(x, dim=[2, 3], keepdim=True)  # Second global average pooling\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 44, "problem_name": "44_ConvTranspose2d_Multiply_GlobalAvgPool_GlobalAvgPool_Mean.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, multiplies by a scalar, applies global average pooling, \n    another global average pooling\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.multiplier = multiplier\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.multiplier\n        x = torch.mean(x, dim=[2, 3], keepdim=True)  # First global average pooling\n        x = torch.mean(x, dim=[2, 3], keepdim=True)  # Second global average pooling\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier]"}}
{"task_id": "L2_45", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), applies Sigmoid,\n    another Gemm, and computes LogSumExp over features.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, output_size):\n        super(Model, self).__init__()\n        self.linear1 = nn.Linear(input_size, hidden_size)\n        self.linear2 = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = torch.sigmoid(x)\n        x = self.linear2(x)\n        x = torch.logsumexp(x, dim=1)  # compute LogSumExp over features per sample\n        return x\n\nbatch_size = 16384\ninput_size = 2048\nhidden_size = 4096\noutput_size = 1024\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, output_size]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), applies Sigmoid,\n    another Gemm, and computes LogSumExp over features.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, output_size):\n        super(Model, self).__init__()\n        self.linear1 = nn.Linear(input_size, hidden_size)\n        self.linear2 = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = torch.sigmoid(x)\n        x = self.linear2(x)\n        x = torch.logsumexp(x, dim=1)  # compute LogSumExp over features per sample\n        return x\n\nbatch_size = 16384\ninput_size = 2048\nhidden_size = 4096\noutput_size = 1024\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, output_size]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 45, "problem_name": "45_Gemm_Sigmoid_LogSumExp.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), applies Sigmoid,\n    another Gemm, and computes LogSumExp over features.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, output_size):\n        super(Model, self).__init__()\n        self.linear1 = nn.Linear(input_size, hidden_size)\n        self.linear2 = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = torch.sigmoid(x)\n        x = self.linear2(x)\n        x = torch.logsumexp(x, dim=1)  # compute LogSumExp over features per sample\n        return x\n\nbatch_size = 16384\ninput_size = 2048\nhidden_size = 4096\noutput_size = 1024\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, output_size]\n"}}
{"task_id": "L2_46", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtraction, tanh activation, subtraction and average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract1_value, subtract2_value, kernel_size_pool):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract1_value = subtract1_value\n        self.subtract2_value = subtract2_value\n        self.avgpool = nn.AvgPool2d(kernel_size_pool)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract1_value\n        x = torch.tanh(x)\n        x = x - self.subtract2_value\n        x = self.avgpool(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nsubtract1_value = 0.5\nsubtract2_value = 0.2\nkernel_size_pool = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract1_value, subtract2_value, kernel_size_pool]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtraction, tanh activation, subtraction and average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract1_value, subtract2_value, kernel_size_pool):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract1_value = subtract1_value\n        self.subtract2_value = subtract2_value\n        self.avgpool = nn.AvgPool2d(kernel_size_pool)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract1_value\n        x = torch.tanh(x)\n        x = x - self.subtract2_value\n        x = self.avgpool(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nsubtract1_value = 0.5\nsubtract2_value = 0.2\nkernel_size_pool = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract1_value, subtract2_value, kernel_size_pool]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 46, "problem_name": "46_Conv2d_Subtract_Tanh_Subtract_AvgPool.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtraction, tanh activation, subtraction and average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract1_value, subtract2_value, kernel_size_pool):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract1_value = subtract1_value\n        self.subtract2_value = subtract2_value\n        self.avgpool = nn.AvgPool2d(kernel_size_pool)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract1_value\n        x = torch.tanh(x)\n        x = x - self.subtract2_value\n        x = self.avgpool(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\nsubtract1_value = 0.5\nsubtract2_value = 0.2\nkernel_size_pool = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract1_value, subtract2_value, kernel_size_pool]"}}
{"task_id": "L2_47", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Mish activation, and then applies Tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D', H', W').\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 32, 64, 64\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Mish activation, and then applies Tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D', H', W').\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 32, 64, 64\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 47, "problem_name": "47_Conv3d_Mish_Tanh.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Mish activation, and then applies Tanh activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D', H', W').\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.mish(x)\n        x = torch.tanh(x)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 32, 64, 64\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}}
{"task_id": "L2_48", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, scales the output, applies tanh, multiplies by a scaling factor, and applies sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.scaling_factor = nn.Parameter(torch.randn(bias_shape))\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.scaling_factor \n        x = torch.tanh(x)\n        x = x * self.bias\n        x = torch.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nscaling_factor = 2\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, scales the output, applies tanh, multiplies by a scaling factor, and applies sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.scaling_factor = nn.Parameter(torch.randn(bias_shape))\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.scaling_factor \n        x = torch.tanh(x)\n        x = x * self.bias\n        x = torch.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nscaling_factor = 2\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 48, "problem_name": "48_Conv3d_Scaling_Tanh_Multiply_Sigmoid.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, scales the output, applies tanh, multiplies by a scaling factor, and applies sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.scaling_factor = nn.Parameter(torch.randn(bias_shape))\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.scaling_factor \n        x = torch.tanh(x)\n        x = x * self.bias\n        x = torch.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nscaling_factor = 2\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape]"}}
{"task_id": "L2_49", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Softmax and Sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, bias=bias)\n        self.softmax = nn.Softmax(dim=1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.softmax(x)\n        x = self.sigmoid(x)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Softmax and Sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, bias=bias)\n        self.softmax = nn.Softmax(dim=1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.softmax(x)\n        x = self.sigmoid(x)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 49, "problem_name": "49_ConvTranspose3d_Softmax_Sigmoid.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Softmax and Sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, bias=bias)\n        self.softmax = nn.Softmax(dim=1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.softmax(x)\n        x = self.sigmoid(x)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nD, H, W = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding]"}}
{"task_id": "L2_50", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scaling, average pooling, bias addition, and scaling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.scale1 = nn.Parameter(torch.tensor(scale1))\n        self.avg_pool = nn.AvgPool3d(kernel_size=2)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scale2 = nn.Parameter(torch.tensor(scale2))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale1\n        x = self.avg_pool(x)\n        x = x + self.bias\n        x = x * self.scale2\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale1 = 0.5\nscale2 = 1.0\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scaling, average pooling, bias addition, and scaling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.scale1 = nn.Parameter(torch.tensor(scale1))\n        self.avg_pool = nn.AvgPool3d(kernel_size=2)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scale2 = nn.Parameter(torch.tensor(scale2))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale1\n        x = self.avg_pool(x)\n        x = x + self.bias\n        x = x * self.scale2\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale1 = 0.5\nscale2 = 1.0\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 50, "problem_name": "50_ConvTranspose3d_Scaling_AvgPool_BiasAdd_Scaling.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scaling, average pooling, bias addition, and scaling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.scale1 = nn.Parameter(torch.tensor(scale1))\n        self.avg_pool = nn.AvgPool3d(kernel_size=2)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scale2 = nn.Parameter(torch.tensor(scale2))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale1\n        x = self.avg_pool(x)\n        x = x + self.bias\n        x = x * self.scale2\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale1 = 0.5\nscale2 = 1.0\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale1, scale2, bias_shape]"}}
{"task_id": "L2_51", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations: Gemm, Subtract, GlobalAvgPool, LogSumExp, GELU, and ResidualAdd.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=bias)\n        self.subtract = nn.Parameter(torch.randn(out_features))\n\n    def forward(self, x):\n        original_x = x.clone().detach()\n        # Gemm\n        x = self.gemm(x)\n\n        # Subtract\n        x = x - self.subtract\n\n        # GlobalAvgPool\n        x = torch.mean(x, dim=1, keepdim=True)\n\n        # LogSumExp\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n\n        # GELU\n        x = torch.nn.functional.gelu(x)\n\n        # ResidualAdd\n        x = x + original_x\n\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations: Gemm, Subtract, GlobalAvgPool, LogSumExp, GELU, and ResidualAdd.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=bias)\n        self.subtract = nn.Parameter(torch.randn(out_features))\n\n    def forward(self, x):\n        original_x = x.clone().detach()\n        # Gemm\n        x = self.gemm(x)\n\n        # Subtract\n        x = x - self.subtract\n\n        # GlobalAvgPool\n        x = torch.mean(x, dim=1, keepdim=True)\n\n        # LogSumExp\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n\n        # GELU\n        x = torch.nn.functional.gelu(x)\n\n        # ResidualAdd\n        x = x + original_x\n\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 51, "problem_name": "51_Gemm_Subtract_GlobalAvgPool_LogSumExp_GELU_ResidualAdd.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a series of operations: Gemm, Subtract, GlobalAvgPool, LogSumExp, GELU, and ResidualAdd.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=bias)\n        self.subtract = nn.Parameter(torch.randn(out_features))\n\n    def forward(self, x):\n        original_x = x.clone().detach()\n        # Gemm\n        x = self.gemm(x)\n\n        # Subtract\n        x = x - self.subtract\n\n        # GlobalAvgPool\n        x = torch.mean(x, dim=1, keepdim=True)\n\n        # LogSumExp\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n\n        # GELU\n        x = torch.nn.functional.gelu(x)\n\n        # ResidualAdd\n        x = x + original_x\n\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}}
{"task_id": "L2_52", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies activation, and then applies Batch Normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bn = nn.BatchNorm2d(out_channels, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.multiply(torch.tanh(torch.nn.functional.softplus(x)), x)\n        x = self.bn(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies activation, and then applies Batch Normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bn = nn.BatchNorm2d(out_channels, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.multiply(torch.tanh(torch.nn.functional.softplus(x)), x)\n        x = self.bn(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 52, "problem_name": "52_Conv2d_Activation_BatchNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies activation, and then applies Batch Normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bn = nn.BatchNorm2d(out_channels, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.multiply(torch.tanh(torch.nn.functional.softplus(x)), x)\n        x = self.bn(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 128\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}}
{"task_id": "L2_53", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, scaling, hardtanh, and GELU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n        self.gelu = nn.GELU()\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scaling_factor\n        x = self.hardtanh(x)\n        x = self.gelu(x)\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\nscaling_factor = 0.5\nhardtanh_min = -2\nhardtanh_max = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, scaling, hardtanh, and GELU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n        self.gelu = nn.GELU()\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scaling_factor\n        x = self.hardtanh(x)\n        x = self.gelu(x)\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\nscaling_factor = 0.5\nhardtanh_min = -2\nhardtanh_max = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 53, "problem_name": "53_Gemm_Scaling_Hardtanh_GELU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, scaling, hardtanh, and GELU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n        self.hardtanh = nn.Hardtanh(min_val=hardtanh_min, max_val=hardtanh_max)\n        self.gelu = nn.GELU()\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = x * self.scaling_factor\n        x = self.hardtanh(x)\n        x = self.gelu(x)\n        return x\n\nbatch_size = 2048\nin_features = 8192\nout_features = 8192\nscaling_factor = 0.5\nhardtanh_min = -2\nhardtanh_max = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max]"}}
{"task_id": "L2_54", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, multiplies by a learnable scalar, applies LeakyReLU, and then GELU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape)) \n        self.leaky_relu = nn.LeakyReLU()\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, multiplies by a learnable scalar, applies LeakyReLU, and then GELU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape)) \n        self.leaky_relu = nn.LeakyReLU()\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 54, "problem_name": "54_Conv2d_Multiply_LeakyReLU_GELU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, multiplies by a learnable scalar, applies LeakyReLU, and then GELU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape)) \n        self.leaky_relu = nn.LeakyReLU()\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 64\nin_channels = 64\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape]"}}
{"task_id": "L2_55", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs matrix multiplication, max pooling, sum, and scaling.\n    \"\"\"\n    def __init__(self, in_features, out_features, kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.max_pool = nn.MaxPool1d(kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.max_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.sum(x, dim=1)\n        x = x * self.scale_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nkernel_size = 2\nscale_factor = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, kernel_size, scale_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs matrix multiplication, max pooling, sum, and scaling.\n    \"\"\"\n    def __init__(self, in_features, out_features, kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.max_pool = nn.MaxPool1d(kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.max_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.sum(x, dim=1)\n        x = x * self.scale_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nkernel_size = 2\nscale_factor = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, kernel_size, scale_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 55, "problem_name": "55_Matmul_MaxPool_Sum_Scale.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs matrix multiplication, max pooling, sum, and scaling.\n    \"\"\"\n    def __init__(self, in_features, out_features, kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.max_pool = nn.MaxPool1d(kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.max_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.sum(x, dim=1)\n        x = x * self.scale_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nkernel_size = 2\nscale_factor = 0.5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, kernel_size, scale_factor]"}}
{"task_id": "L2_56", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies sigmoid, and sums the result.\n    \"\"\"\n    def __init__(self, input_size, hidden_size):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(input_size, hidden_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.linear(x)\n        x = torch.sigmoid(x)\n        x = torch.sum(x, dim=1, keepdim=True)\n        return x\n\nbatch_size = 128\ninput_size = 32768\nhidden_size = 32768\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies sigmoid, and sums the result.\n    \"\"\"\n    def __init__(self, input_size, hidden_size):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(input_size, hidden_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.linear(x)\n        x = torch.sigmoid(x)\n        x = torch.sum(x, dim=1, keepdim=True)\n        return x\n\nbatch_size = 128\ninput_size = 32768\nhidden_size = 32768\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 56, "problem_name": "56_Matmul_Sigmoid_Sum.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies sigmoid, and sums the result.\n    \"\"\"\n    def __init__(self, input_size, hidden_size):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(input_size, hidden_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, 1).\n        \"\"\"\n        x = self.linear(x)\n        x = torch.sigmoid(x)\n        x = torch.sum(x, dim=1, keepdim=True)\n        return x\n\nbatch_size = 128\ninput_size = 32768\nhidden_size = 32768\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size]"}}
{"task_id": "L2_57", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and applies HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = x * torch.clamp((x + 3) / 6, 0, 1)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and applies HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = x * torch.clamp((x + 3) / 6, 0, 1)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 57, "problem_name": "57_Conv2d_ReLU_HardSwish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies ReLU, and applies HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.relu(x)\n        x = x * torch.clamp((x + 3) / 6, 0, 1)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}}
{"task_id": "L2_58", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, LogSumExp, HardSwish, subtraction, clamp operations.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.bias = nn.Parameter(torch.randn(1, 1, 1, 1)) \n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = x * torch.sigmoid(x + 3) / 6\n        x = x - self.bias\n        x = torch.clamp(x, min=-1, max=1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (1, 1, 1, 1)  \n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, LogSumExp, HardSwish, subtraction, clamp operations.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.bias = nn.Parameter(torch.randn(1, 1, 1, 1)) \n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = x * torch.sigmoid(x + 3) / 6\n        x = x - self.bias\n        x = torch.clamp(x, min=-1, max=1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (1, 1, 1, 1)  \n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 58, "problem_name": "58_ConvTranspose3d_LogSumExp_HardSwish_Subtract_Clamp.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, LogSumExp, HardSwish, subtraction, clamp operations.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.bias = nn.Parameter(torch.randn(1, 1, 1, 1)) \n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        x = x * torch.sigmoid(x + 3) / 6\n        x = x - self.bias\n        x = torch.clamp(x, min=-1, max=1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (1, 1, 1, 1)  \n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]\n"}}
{"task_id": "L2_59", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 59, "problem_name": "59_Matmul_Swish_Scaling.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_features = 32768\nout_features = 32768\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]"}}
{"task_id": "L2_60", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Swish activation, \n    group normalization, and then HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, eps, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.group_norm = nn.GroupNorm(num_groups=groups, num_channels=out_channels, eps=eps)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.sigmoid(x) * x  # Swish activation\n        x = self.group_norm(x)\n        x = torch.nn.functional.hardswish(x)  # HardSwish activation\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\ngroups = 4\neps = 1e-5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, eps]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Swish activation, \n    group normalization, and then HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, eps, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.group_norm = nn.GroupNorm(num_groups=groups, num_channels=out_channels, eps=eps)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.sigmoid(x) * x  # Swish activation\n        x = self.group_norm(x)\n        x = torch.nn.functional.hardswish(x)  # HardSwish activation\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\ngroups = 4\neps = 1e-5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, eps]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 60, "problem_name": "60_ConvTranspose3d_Swish_GroupNorm_HardSwish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies Swish activation, \n    group normalization, and then HardSwish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, eps, bias=True):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.group_norm = nn.GroupNorm(num_groups=groups, num_channels=out_channels, eps=eps)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.sigmoid(x) * x  # Swish activation\n        x = self.group_norm(x)\n        x = torch.nn.functional.hardswish(x)  # HardSwish activation\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\ngroups = 4\neps = 1e-5\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, groups, eps]"}}
{"task_id": "L2_61", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed 3D convolution, applies ReLU, and then applies group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, bias=False):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, bias=bias)\n        self.relu = nn.ReLU()\n        self.group_norm = nn.GroupNorm(num_groups=groups, num_channels=out_channels)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.relu(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nD, H, W = 32, 32, 32\nkernel_size = 3\ngroups = 8\nbias = False\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, bias]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed 3D convolution, applies ReLU, and then applies group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, bias=False):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, bias=bias)\n        self.relu = nn.ReLU()\n        self.group_norm = nn.GroupNorm(num_groups=groups, num_channels=out_channels)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.relu(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nD, H, W = 32, 32, 32\nkernel_size = 3\ngroups = 8\nbias = False\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, bias]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 61, "problem_name": "61_ConvTranspose3d_ReLU_GroupNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed 3D convolution, applies ReLU, and then applies group normalization.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, bias=False):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, bias=bias)\n        self.relu = nn.ReLU()\n        self.group_norm = nn.GroupNorm(num_groups=groups, num_channels=out_channels)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, D, H, W).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, D, H, W).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.relu(x)\n        x = self.group_norm(x)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nD, H, W = 32, 32, 32\nkernel_size = 3\ngroups = 8\nbias = False\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, bias]"}}
{"task_id": "L2_62", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, group normalization, leaky ReLU activation, and element-wise sum.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, num_groups, eps=1e-5, negative_slope=0.01):\n        super(Model, self).__init__()\n        self.fc = nn.Linear(input_size, hidden_size)\n        self.gn = nn.GroupNorm(num_groups=num_groups, num_channels=hidden_size, eps=eps)\n        self.leaky_relu = nn.LeakyReLU(negative_slope=negative_slope)\n\n    def forward(self, x):\n        \"\"\"\n        Performs the forward pass of the model.\n\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.fc(x)\n        x = self.gn(x)\n        x = self.leaky_relu(x)\n        x = x + x\n        return x\n\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nnum_groups = 512\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, group normalization, leaky ReLU activation, and element-wise sum.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, num_groups, eps=1e-5, negative_slope=0.01):\n        super(Model, self).__init__()\n        self.fc = nn.Linear(input_size, hidden_size)\n        self.gn = nn.GroupNorm(num_groups=num_groups, num_channels=hidden_size, eps=eps)\n        self.leaky_relu = nn.LeakyReLU(negative_slope=negative_slope)\n\n    def forward(self, x):\n        \"\"\"\n        Performs the forward pass of the model.\n\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.fc(x)\n        x = self.gn(x)\n        x = self.leaky_relu(x)\n        x = x + x\n        return x\n\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nnum_groups = 512\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 62, "problem_name": "62_Matmul_GroupNorm_LeakyReLU_Sum.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, group normalization, leaky ReLU activation, and element-wise sum.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, num_groups, eps=1e-5, negative_slope=0.01):\n        super(Model, self).__init__()\n        self.fc = nn.Linear(input_size, hidden_size)\n        self.gn = nn.GroupNorm(num_groups=num_groups, num_channels=hidden_size, eps=eps)\n        self.leaky_relu = nn.LeakyReLU(negative_slope=negative_slope)\n\n    def forward(self, x):\n        \"\"\"\n        Performs the forward pass of the model.\n\n        Args:\n            x: Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.fc(x)\n        x = self.gn(x)\n        x = self.leaky_relu(x)\n        x = x + x\n        return x\n\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nnum_groups = 512\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_groups]"}}
{"task_id": "L2_63", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies ReLU, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, divisor):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.relu(x)\n        x = x / self.divisor\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, divisor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies ReLU, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, divisor):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.relu(x)\n        x = x / self.divisor\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, divisor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 63, "problem_name": "63_Gemm_ReLU_Divide.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies ReLU, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, divisor):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.relu(x)\n        x = x / self.divisor\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, divisor]"}}
{"task_id": "L2_64", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), followed by LogSumExp, LeakyReLU, \n    LeakyReLU, GELU, and GELU activations.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features, bias=bias)\n\n    def forward(self, x):\n        # Gemm\n        x = self.linear(x)\n        # LogSumExp\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        # LeakyReLU\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        # LeakyReLU\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        # GELU\n        x = torch.nn.functional.gelu(x)\n        # GELU\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), followed by LogSumExp, LeakyReLU, \n    LeakyReLU, GELU, and GELU activations.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features, bias=bias)\n\n    def forward(self, x):\n        # Gemm\n        x = self.linear(x)\n        # LogSumExp\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        # LeakyReLU\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        # LeakyReLU\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        # GELU\n        x = torch.nn.functional.gelu(x)\n        # GELU\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 64, "problem_name": "64_Gemm_LogSumExp_LeakyReLU_LeakyReLU_GELU_GELU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), followed by LogSumExp, LeakyReLU, \n    LeakyReLU, GELU, and GELU activations.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features, bias=bias)\n\n    def forward(self, x):\n        # Gemm\n        x = self.linear(x)\n        # LogSumExp\n        x = torch.logsumexp(x, dim=1, keepdim=True)\n        # LeakyReLU\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        # LeakyReLU\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        # GELU\n        x = torch.nn.functional.gelu(x)\n        # GELU\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}}
{"task_id": "L2_65", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    This model performs a convolution, average pooling, applies sigmoid, and sums the result.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.avg_pool = nn.AvgPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.avg_pool(x)\n        x = torch.sigmoid(x)\n        x = torch.sum(x, dim=[1,2,3]) # Sum over all spatial dimensions\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 384, 384\nkernel_size = 3\npool_kernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    This model performs a convolution, average pooling, applies sigmoid, and sums the result.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.avg_pool = nn.AvgPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.avg_pool(x)\n        x = torch.sigmoid(x)\n        x = torch.sum(x, dim=[1,2,3]) # Sum over all spatial dimensions\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 384, 384\nkernel_size = 3\npool_kernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 65, "problem_name": "65_Conv2d_AvgPool_Sigmoid_Sum.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    This model performs a convolution, average pooling, applies sigmoid, and sums the result.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.avg_pool = nn.AvgPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.avg_pool(x)\n        x = torch.sigmoid(x)\n        x = torch.sum(x, dim=[1,2,3]) # Sum over all spatial dimensions\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 384, 384\nkernel_size = 3\npool_kernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]"}}
{"task_id": "L2_66", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs matrix multiplication, applies dropout, and then applies softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features, dropout_p):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.dropout(x)\n        x = torch.softmax(x, dim=1)  # Softmax over features\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs matrix multiplication, applies dropout, and then applies softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features, dropout_p):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.dropout(x)\n        x = torch.softmax(x, dim=1)  # Softmax over features\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 66, "problem_name": "66_Matmul_Dropout_Softmax.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs matrix multiplication, applies dropout, and then applies softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features, dropout_p):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.dropout(x)\n        x = torch.softmax(x, dim=1)  # Softmax over features\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n"}}
{"task_id": "L2_67", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies GELU, and then performs global average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n        x = x.squeeze(-1).squeeze(-1)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies GELU, and then performs global average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n        x = x.squeeze(-1).squeeze(-1)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 67, "problem_name": "67_Conv2d_GELU_GlobalAvgPool.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies GELU, and then performs global average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n        x = x.squeeze(-1).squeeze(-1)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}}
{"task_id": "L2_68", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies minimum, and subtracts a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, constant):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.constant = nn.Parameter(torch.tensor(constant))\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.min(x, self.constant)\n        x = x - self.constant\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\nconstant = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, constant]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies minimum, and subtracts a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, constant):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.constant = nn.Parameter(torch.tensor(constant))\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.min(x, self.constant)\n        x = x - self.constant\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\nconstant = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, constant]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 68, "problem_name": "68_Matmul_Min_Subtract.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies minimum, and subtracts a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, constant):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.constant = nn.Parameter(torch.tensor(constant))\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.min(x, self.constant)\n        x = x - self.constant\n        return x\n\nbatch_size = 128\nin_features = 16384\nout_features = 16384\nconstant = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, constant]"}}
{"task_id": "L2_69", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies HardSwish, and then ReLU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.hardswish(x)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies HardSwish, and then ReLU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.hardswish(x)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 69, "problem_name": "69_Conv2d_HardSwish_ReLU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies HardSwish, and then ReLU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height, width).\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.hardswish(x)\n        x = torch.relu(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]"}}
{"task_id": "L2_70", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model implementing the pattern \"Gemm_Sigmoid_Scaling_ResidualAdd\".\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scaling_factor):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(input_size, hidden_size)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.gemm(x)\n        original_x = x\n        x = torch.sigmoid(x)\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model implementing the pattern \"Gemm_Sigmoid_Scaling_ResidualAdd\".\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scaling_factor):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(input_size, hidden_size)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.gemm(x)\n        original_x = x\n        x = torch.sigmoid(x)\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 70, "problem_name": "70_Gemm_Sigmoid_Scaling_ResidualAdd.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model implementing the pattern \"Gemm_Sigmoid_Scaling_ResidualAdd\".\n    \"\"\"\n    def __init__(self, input_size, hidden_size, scaling_factor):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(input_size, hidden_size)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, hidden_size).\n        \"\"\"\n        x = self.gemm(x)\n        original_x = x\n        x = torch.sigmoid(x)\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 1024\ninput_size = 8192\nhidden_size = 8192\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]"}}
{"task_id": "L2_71", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, divides by a constant, and applies LeakyReLU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divisor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x / self.divisor\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ndivisor = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, divides by a constant, and applies LeakyReLU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divisor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x / self.divisor\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ndivisor = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 71, "problem_name": "71_Conv2d_Divide_LeakyReLU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, divides by a constant, and applies LeakyReLU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, divisor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x / self.divisor\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ndivisor = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divisor]"}}
{"task_id": "L2_72", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a 3D transposed convolution, followed by batch normalization, \n    two average pooling layers.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.batch_norm = nn.BatchNorm3d(out_channels)\n        self.avg_pool1 = nn.AvgPool3d(kernel_size=2)\n        self.avg_pool2 = nn.AvgPool3d(kernel_size=2)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = self.avg_pool1(x)\n        x = self.avg_pool2(x)\n        return x\n\n\nbatch_size = 64\nin_channels = 3\nout_channels = 16\ndepth, height, width = 32, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a 3D transposed convolution, followed by batch normalization, \n    two average pooling layers.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.batch_norm = nn.BatchNorm3d(out_channels)\n        self.avg_pool1 = nn.AvgPool3d(kernel_size=2)\n        self.avg_pool2 = nn.AvgPool3d(kernel_size=2)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = self.avg_pool1(x)\n        x = self.avg_pool2(x)\n        return x\n\n\nbatch_size = 64\nin_channels = 3\nout_channels = 16\ndepth, height, width = 32, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 72, "problem_name": "72_ConvTranspose3d_BatchNorm_AvgPool_AvgPool.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a 3D transposed convolution, followed by batch normalization, \n    two average pooling layers.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.batch_norm = nn.BatchNorm3d(out_channels)\n        self.avg_pool1 = nn.AvgPool3d(kernel_size=2)\n        self.avg_pool2 = nn.AvgPool3d(kernel_size=2)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.batch_norm(x)\n        x = self.avg_pool1(x)\n        x = self.avg_pool2(x)\n        return x\n\n\nbatch_size = 64\nin_channels = 3\nout_channels = 16\ndepth, height, width = 32, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, bias_shape]"}}
{"task_id": "L2_73", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Batch Normalization, and scales the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Batch Normalization, and scales the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 73, "problem_name": "73_Conv2d_BatchNorm_Scaling.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies Batch Normalization, and scales the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor]"}}
{"task_id": "L2_74", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies LeakyReLU, multiplies by a learnable parameter, \n    applies LeakyReLU again, and performs a max pooling operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n        self.max_pool = nn.MaxPool3d(kernel_size=2)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.leaky_relu(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        x = self.max_pool(x)\n        return x\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies LeakyReLU, multiplies by a learnable parameter, \n    applies LeakyReLU again, and performs a max pooling operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n        self.max_pool = nn.MaxPool3d(kernel_size=2)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.leaky_relu(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        x = self.max_pool(x)\n        return x\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 74, "problem_name": "74_ConvTranspose3d_LeakyReLU_Multiply_LeakyReLU_Max.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, applies LeakyReLU, multiplies by a learnable parameter, \n    applies LeakyReLU again, and performs a max pooling operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n        self.max_pool = nn.MaxPool3d(kernel_size=2)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.leaky_relu(x)\n        x = x * self.multiplier\n        x = self.leaky_relu(x)\n        x = self.max_pool(x)\n        return x\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape]"}}
{"task_id": "L2_75", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, Group Normalization, Minimum operation, and Bias addition.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, bias_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = self.group_norm(x)\n        x = torch.min(x, dim=1, keepdim=True)[0] \n        x = x + self.bias\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 512\nbias_shape = (1, out_features, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, Group Normalization, Minimum operation, and Bias addition.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, bias_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = self.group_norm(x)\n        x = torch.min(x, dim=1, keepdim=True)[0] \n        x = x + self.bias\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 512\nbias_shape = (1, out_features, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 75, "problem_name": "75_Gemm_GroupNorm_Min_BiasAdd.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, Group Normalization, Minimum operation, and Bias addition.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, bias_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.gemm(x)\n        x = self.group_norm(x)\n        x = torch.min(x, dim=1, keepdim=True)[0] \n        x = x + self.bias\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 512\nbias_shape = (1, out_features, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, bias_shape]"}}
{"task_id": "L2_76", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a bias term, and applies ReLU.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=False)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor with shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor with shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x + self.bias\n        x = torch.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a bias term, and applies ReLU.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=False)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor with shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor with shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x + self.bias\n        x = torch.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 76, "problem_name": "76_Gemm_Add_ReLU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a bias term, and applies ReLU.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=False)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor with shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor with shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x + self.bias\n        x = torch.relu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape]"}}
{"task_id": "L2_77", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scales the output, applies batch normalization, \n    and then performs global average pooling. \n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scale_factor, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size)\n        self.scale_factor = scale_factor\n        self.batch_norm = nn.BatchNorm3d(out_channels, eps=eps, momentum=momentum)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale_factor\n        x = self.batch_norm(x)\n        x = self.global_avg_pool(x)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 16, 32, 32\nkernel_size = 5\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scales the output, applies batch normalization, \n    and then performs global average pooling. \n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scale_factor, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size)\n        self.scale_factor = scale_factor\n        self.batch_norm = nn.BatchNorm3d(out_channels, eps=eps, momentum=momentum)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale_factor\n        x = self.batch_norm(x)\n        x = self.global_avg_pool(x)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 16, 32, 32\nkernel_size = 5\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 77, "problem_name": "77_ConvTranspose3d_Scale_BatchNorm_GlobalAvgPool.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, scales the output, applies batch normalization, \n    and then performs global average pooling. \n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scale_factor, eps=1e-5, momentum=0.1):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size)\n        self.scale_factor = scale_factor\n        self.batch_norm = nn.BatchNorm3d(out_channels, eps=eps, momentum=momentum)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale_factor\n        x = self.batch_norm(x)\n        x = self.global_avg_pool(x)\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 16, 32, 32\nkernel_size = 5\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]"}}
{"task_id": "L2_78", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by two max pooling layers and a sum operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.max_pool1 = nn.MaxPool3d(kernel_size=2)\n        self.max_pool2 = nn.MaxPool3d(kernel_size=3)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool1(x)\n        x = self.max_pool2(x)\n        x = torch.sum(x, dim=1, keepdim=True) \n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 32, 32\nkernel_size = 5\nstride = 2\npadding = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by two max pooling layers and a sum operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.max_pool1 = nn.MaxPool3d(kernel_size=2)\n        self.max_pool2 = nn.MaxPool3d(kernel_size=3)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool1(x)\n        x = self.max_pool2(x)\n        x = torch.sum(x, dim=1, keepdim=True) \n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 32, 32\nkernel_size = 5\nstride = 2\npadding = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 78, "problem_name": "78_ConvTranspose3d_Max_Max_Sum.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, followed by two max pooling layers and a sum operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.max_pool1 = nn.MaxPool3d(kernel_size=2)\n        self.max_pool2 = nn.MaxPool3d(kernel_size=3)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool1(x)\n        x = self.max_pool2(x)\n        x = torch.sum(x, dim=1, keepdim=True) \n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 32, 32, 32\nkernel_size = 5\nstride = 2\npadding = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]"}}
{"task_id": "L2_79", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional layer followed by multiplication, instance normalization, clamping, multiplication, and a max operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.instance_norm = nn.InstanceNorm3d(out_channels)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.multiplier\n        x = self.instance_norm(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        x = x * self.multiplier\n        x = torch.max(x, dim=1)[0]\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1, 1)\nclamp_min = -1.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape, clamp_min, clamp_max]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional layer followed by multiplication, instance normalization, clamping, multiplication, and a max operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.instance_norm = nn.InstanceNorm3d(out_channels)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.multiplier\n        x = self.instance_norm(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        x = x * self.multiplier\n        x = torch.max(x, dim=1)[0]\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1, 1)\nclamp_min = -1.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape, clamp_min, clamp_max]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 79, "problem_name": "79_Conv3d_Multiply_InstanceNorm_Clamp_Multiply_Max.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A 3D convolutional layer followed by multiplication, instance normalization, clamping, multiplication, and a max operation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.instance_norm = nn.InstanceNorm3d(out_channels)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x * self.multiplier\n        x = self.instance_norm(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        x = x * self.multiplier\n        x = torch.max(x, dim=1)[0]\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1, 1)\nclamp_min = -1.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape, clamp_min, clamp_max]"}}
{"task_id": "L2_80", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, followed by a max operation, subtraction, and GELU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, max_dim):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.max_dim = max_dim\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_features)\n\n        Returns:\n            Output tensor of shape (batch_size, out_features)\n        \"\"\"\n        x = self.gemm(x)\n        x = torch.max(x, dim=self.max_dim, keepdim=True).values\n        x = x - x.mean(dim=1, keepdim=True)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nmax_dim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, max_dim]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, followed by a max operation, subtraction, and GELU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, max_dim):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.max_dim = max_dim\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_features)\n\n        Returns:\n            Output tensor of shape (batch_size, out_features)\n        \"\"\"\n        x = self.gemm(x)\n        x = torch.max(x, dim=self.max_dim, keepdim=True).values\n        x = x - x.mean(dim=1, keepdim=True)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nmax_dim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, max_dim]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 80, "problem_name": "80_Gemm_Max_Subtract_GELU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, followed by a max operation, subtraction, and GELU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, max_dim):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.max_dim = max_dim\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_features)\n\n        Returns:\n            Output tensor of shape (batch_size, out_features)\n        \"\"\"\n        x = self.gemm(x)\n        x = torch.max(x, dim=self.max_dim, keepdim=True).values\n        x = x - x.mean(dim=1, keepdim=True)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nmax_dim = 1\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, max_dim]"}}
{"task_id": "L2_81", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a gemm, swish, divide, clamp, tanh, and clamp operations.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=bias)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x / 2.0\n        x = torch.clamp(x, min=-1.0, max=1.0)  # Clamp between -1 and 1\n        x = torch.tanh(x)  # Tanh activation\n        x = torch.clamp(x, min=-1.0, max=1.0)  # Clamp between -1 and 1\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a gemm, swish, divide, clamp, tanh, and clamp operations.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=bias)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x / 2.0\n        x = torch.clamp(x, min=-1.0, max=1.0)  # Clamp between -1 and 1\n        x = torch.tanh(x)  # Tanh activation\n        x = torch.clamp(x, min=-1.0, max=1.0)  # Clamp between -1 and 1\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 81, "problem_name": "81_Gemm_Swish_Divide_Clamp_Tanh_Clamp.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a gemm, swish, divide, clamp, tanh, and clamp operations.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias=True):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features, bias=bias)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x / 2.0\n        x = torch.clamp(x, min=-1.0, max=1.0)  # Clamp between -1 and 1\n        x = torch.tanh(x)  # Tanh activation\n        x = torch.clamp(x, min=-1.0, max=1.0)  # Clamp between -1 and 1\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}}
{"task_id": "L2_82", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution, applies tanh, scaling, adds a bias term, and then max-pools.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.scaling_factor = scaling_factor\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.max_pool = nn.MaxPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        # Convolution\n        x = self.conv(x)\n        # Tanh activation\n        x = torch.tanh(x)\n        # Scaling\n        x = x * self.scaling_factor\n        # Bias addition\n        x = x + self.bias\n        # Max-pooling\n        x = self.max_pool(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nscaling_factor = 2.0\nbias_shape = (out_channels, 1, 1)\npool_kernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution, applies tanh, scaling, adds a bias term, and then max-pools.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.scaling_factor = scaling_factor\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.max_pool = nn.MaxPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        # Convolution\n        x = self.conv(x)\n        # Tanh activation\n        x = torch.tanh(x)\n        # Scaling\n        x = x * self.scaling_factor\n        # Bias addition\n        x = x + self.bias\n        # Max-pooling\n        x = self.max_pool(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nscaling_factor = 2.0\nbias_shape = (out_channels, 1, 1)\npool_kernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 82, "problem_name": "82_Conv2d_Tanh_Scaling_BiasAdd_Max.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a convolution, applies tanh, scaling, adds a bias term, and then max-pools.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.scaling_factor = scaling_factor\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.max_pool = nn.MaxPool2d(pool_kernel_size)\n\n    def forward(self, x):\n        # Convolution\n        x = self.conv(x)\n        # Tanh activation\n        x = torch.tanh(x)\n        # Scaling\n        x = x * self.scaling_factor\n        # Bias addition\n        x = x + self.bias\n        # Max-pooling\n        x = self.max_pool(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nscaling_factor = 2.0\nbias_shape = (out_channels, 1, 1)\npool_kernel_size = 4\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape, pool_kernel_size]"}}
{"task_id": "L2_83", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, minimum, clamp, and dropout.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, min_value, max_value, dropout_p):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.norm = nn.GroupNorm(groups, out_channels)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.norm(x)\n        x = torch.min(x, torch.tensor(min_value, device=x.device))\n        x = torch.clamp(x, min=min_value, max=max_value)\n        x = self.dropout(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\ngroups = 8\nmin_value = 0.0\nmax_value = 1.0\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, min_value, max_value, dropout_p]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, minimum, clamp, and dropout.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, min_value, max_value, dropout_p):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.norm = nn.GroupNorm(groups, out_channels)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.norm(x)\n        x = torch.min(x, torch.tensor(min_value, device=x.device))\n        x = torch.clamp(x, min=min_value, max=max_value)\n        x = self.dropout(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\ngroups = 8\nmin_value = 0.0\nmax_value = 1.0\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, min_value, max_value, dropout_p]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 83, "problem_name": "83_Conv3d_GroupNorm_Min_Clamp_Dropout.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies Group Normalization, minimum, clamp, and dropout.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, min_value, max_value, dropout_p):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.norm = nn.GroupNorm(groups, out_channels)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.norm(x)\n        x = torch.min(x, torch.tensor(min_value, device=x.device))\n        x = torch.clamp(x, min=min_value, max=max_value)\n        x = self.dropout(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 64, 64\nkernel_size = 3\ngroups = 8\nmin_value = 0.0\nmax_value = 1.0\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, min_value, max_value, dropout_p]"}}
{"task_id": "L2_84", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), Batch Normalization, scaling, and Softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, scale_shape=(1,)):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.scale = nn.Parameter(torch.ones(scale_shape))\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.bn(x)\n        x = self.scale * x\n        x = self.softmax(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nscale_shape = (1,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, scale_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), Batch Normalization, scaling, and Softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, scale_shape=(1,)):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.scale = nn.Parameter(torch.ones(scale_shape))\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.bn(x)\n        x = self.scale * x\n        x = self.softmax(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nscale_shape = (1,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, scale_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 84, "problem_name": "84_Gemm_BatchNorm_Scaling_Softmax.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication (Gemm), Batch Normalization, scaling, and Softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, scale_shape=(1,)):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.scale = nn.Parameter(torch.ones(scale_shape))\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = self.bn(x)\n        x = self.scale * x\n        x = self.softmax(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nscale_shape = (1,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, scale_shape]"}}
{"task_id": "L2_85", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs convolution, group normalization, scaling, max pooling, and clamping.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n        self.scale = nn.Parameter(torch.ones(scale_shape))\n        self.maxpool = nn.MaxPool2d(kernel_size=maxpool_kernel_size)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width).\n        Returns:\n            Output tensor of shape (batch_size, out_channels, height', width').\n        \"\"\"\n        x = self.conv(x)\n        x = self.group_norm(x)\n        x = x * self.scale\n        x = self.maxpool(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128 \nkernel_size = 3\nnum_groups = 16\nscale_shape = (out_channels, 1, 1)\nmaxpool_kernel_size = 4\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs convolution, group normalization, scaling, max pooling, and clamping.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n        self.scale = nn.Parameter(torch.ones(scale_shape))\n        self.maxpool = nn.MaxPool2d(kernel_size=maxpool_kernel_size)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width).\n        Returns:\n            Output tensor of shape (batch_size, out_channels, height', width').\n        \"\"\"\n        x = self.conv(x)\n        x = self.group_norm(x)\n        x = x * self.scale\n        x = self.maxpool(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128 \nkernel_size = 3\nnum_groups = 16\nscale_shape = (out_channels, 1, 1)\nmaxpool_kernel_size = 4\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 85, "problem_name": "85_Conv2d_GroupNorm_Scale_MaxPool_Clamp.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs convolution, group normalization, scaling, max pooling, and clamping.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n        self.scale = nn.Parameter(torch.ones(scale_shape))\n        self.maxpool = nn.MaxPool2d(kernel_size=maxpool_kernel_size)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width).\n        Returns:\n            Output tensor of shape (batch_size, out_channels, height', width').\n        \"\"\"\n        x = self.conv(x)\n        x = self.group_norm(x)\n        x = x * self.scale\n        x = self.maxpool(x)\n        x = torch.clamp(x, self.clamp_min, self.clamp_max)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128 \nkernel_size = 3\nnum_groups = 16\nscale_shape = (out_channels, 1, 1)\nmaxpool_kernel_size = 4\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max]"}}
{"task_id": "L2_86", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, divides by a scalar, and applies GELU activation.\n    \"\"\"\n    def __init__(self, input_size, output_size, divisor):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n        self.divisor = divisor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, output_size).\n        \"\"\"\n        x = self.linear(x)\n        x = x / self.divisor\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\ninput_size = 8192\noutput_size = 8192\ndivisor = 10.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, output_size, divisor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, divides by a scalar, and applies GELU activation.\n    \"\"\"\n    def __init__(self, input_size, output_size, divisor):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n        self.divisor = divisor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, output_size).\n        \"\"\"\n        x = self.linear(x)\n        x = x / self.divisor\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\ninput_size = 8192\noutput_size = 8192\ndivisor = 10.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, output_size, divisor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 86, "problem_name": "86_Matmul_Divide_GELU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, divides by a scalar, and applies GELU activation.\n    \"\"\"\n    def __init__(self, input_size, output_size, divisor):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n        self.divisor = divisor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, output_size).\n        \"\"\"\n        x = self.linear(x)\n        x = x / self.divisor\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 1024\ninput_size = 8192\noutput_size = 8192\ndivisor = 10.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, output_size, divisor]"}}
{"task_id": "L2_87", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtracts two values, applies Mish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract_value_1, subtract_value_2):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract_value_1 = subtract_value_1\n        self.subtract_value_2 = subtract_value_2\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract_value_1\n        x = x - self.subtract_value_2\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nsubtract_value_1 = 0.5\nsubtract_value_2 = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract_value_1, subtract_value_2]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtracts two values, applies Mish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract_value_1, subtract_value_2):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract_value_1 = subtract_value_1\n        self.subtract_value_2 = subtract_value_2\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract_value_1\n        x = x - self.subtract_value_2\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nsubtract_value_1 = 0.5\nsubtract_value_2 = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract_value_1, subtract_value_2]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 87, "problem_name": "87_Conv2d_Subtract_Subtract_Mish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, subtracts two values, applies Mish activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, subtract_value_1, subtract_value_2):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.subtract_value_1 = subtract_value_1\n        self.subtract_value_2 = subtract_value_2\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x - self.subtract_value_1\n        x = x - self.subtract_value_2\n        x = torch.nn.functional.mish(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 256, 256\nkernel_size = 3\nsubtract_value_1 = 0.5\nsubtract_value_2 = 0.2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, subtract_value_1, subtract_value_2]"}}
{"task_id": "L2_88", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, GroupNorm, Swish, Multiply, and Swish operations.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, multiply_weight_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.multiply_weight = nn.Parameter(torch.randn(multiply_weight_shape)) \n\n    def forward(self, x):\n        # (batch_size, in_features) -> (batch_size, out_features)\n        x = self.gemm(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = self.group_norm(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * torch.sigmoid(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * self.multiply_weight\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * torch.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 256\nmultiply_weight_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, multiply_weight_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, GroupNorm, Swish, Multiply, and Swish operations.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, multiply_weight_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.multiply_weight = nn.Parameter(torch.randn(multiply_weight_shape)) \n\n    def forward(self, x):\n        # (batch_size, in_features) -> (batch_size, out_features)\n        x = self.gemm(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = self.group_norm(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * torch.sigmoid(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * self.multiply_weight\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * torch.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 256\nmultiply_weight_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, multiply_weight_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 88, "problem_name": "88_Gemm_GroupNorm_Swish_Multiply_Swish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a GEMM, GroupNorm, Swish, Multiply, and Swish operations.\n    \"\"\"\n    def __init__(self, in_features, out_features, num_groups, multiply_weight_shape):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.group_norm = nn.GroupNorm(num_groups, out_features)\n        self.multiply_weight = nn.Parameter(torch.randn(multiply_weight_shape)) \n\n    def forward(self, x):\n        # (batch_size, in_features) -> (batch_size, out_features)\n        x = self.gemm(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = self.group_norm(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * torch.sigmoid(x)\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * self.multiply_weight\n        # (batch_size, out_features) -> (batch_size, out_features)\n        x = x * torch.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nnum_groups = 256\nmultiply_weight_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, num_groups, multiply_weight_shape]"}}
{"task_id": "L2_89", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a sequence of operations:\n        - ConvTranspose3d\n        - MaxPool3d\n        - Softmax\n        - Subtract\n        - Swish\n        - Max\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.max_pool = nn.MaxPool3d(kernel_size=pool_kernel_size, stride=pool_stride, padding=pool_padding)\n        self.subtract = nn.Parameter(torch.randn(out_channels)) # Assuming subtraction is element-wise across channels\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool(x)\n        x = torch.softmax(x, dim=1) # Apply softmax across channels (dim=1)\n        x = x - self.subtract.view(1, -1, 1, 1, 1) # Subtract across channels\n        x = torch.sigmoid(x) * x # Swish activation\n        x = torch.max(x, dim=1)[0] # Max pooling across channels\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\npool_stride = 2\npool_padding = 0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a sequence of operations:\n        - ConvTranspose3d\n        - MaxPool3d\n        - Softmax\n        - Subtract\n        - Swish\n        - Max\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.max_pool = nn.MaxPool3d(kernel_size=pool_kernel_size, stride=pool_stride, padding=pool_padding)\n        self.subtract = nn.Parameter(torch.randn(out_channels)) # Assuming subtraction is element-wise across channels\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool(x)\n        x = torch.softmax(x, dim=1) # Apply softmax across channels (dim=1)\n        x = x - self.subtract.view(1, -1, 1, 1, 1) # Subtract across channels\n        x = torch.sigmoid(x) * x # Swish activation\n        x = torch.max(x, dim=1)[0] # Max pooling across channels\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\npool_stride = 2\npool_padding = 0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 89, "problem_name": "89_ConvTranspose3d_MaxPool_Softmax_Subtract_Swish_Max.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a sequence of operations:\n        - ConvTranspose3d\n        - MaxPool3d\n        - Softmax\n        - Subtract\n        - Swish\n        - Max\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.max_pool = nn.MaxPool3d(kernel_size=pool_kernel_size, stride=pool_stride, padding=pool_padding)\n        self.subtract = nn.Parameter(torch.randn(out_channels)) # Assuming subtraction is element-wise across channels\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool(x)\n        x = torch.softmax(x, dim=1) # Apply softmax across channels (dim=1)\n        x = x - self.subtract.view(1, -1, 1, 1, 1) # Subtract across channels\n        x = torch.sigmoid(x) * x # Swish activation\n        x = torch.max(x, dim=1)[0] # Max pooling across channels\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\npool_stride = 2\npool_padding = 0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding]"}}
{"task_id": "L2_90", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies LeakyReLU, sums with a tensor, clamps, and applies GELU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, sum_tensor_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.sum_tensor = nn.Parameter(torch.randn(sum_tensor_shape))\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.2)\n        x = x + self.sum_tensor\n        x = torch.clamp(x, min=-1.0, max=1.0)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nsum_tensor_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, sum_tensor_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies LeakyReLU, sums with a tensor, clamps, and applies GELU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, sum_tensor_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.sum_tensor = nn.Parameter(torch.randn(sum_tensor_shape))\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.2)\n        x = x + self.sum_tensor\n        x = torch.clamp(x, min=-1.0, max=1.0)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nsum_tensor_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, sum_tensor_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 90, "problem_name": "90_Conv3d_LeakyReLU_Sum_Clamp_GELU.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a 3D convolution, applies LeakyReLU, sums with a tensor, clamps, and applies GELU activation.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, sum_tensor_shape):\n        super(Model, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.sum_tensor = nn.Parameter(torch.randn(sum_tensor_shape))\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.nn.functional.leaky_relu(x, negative_slope=0.2)\n        x = x + self.sum_tensor\n        x = torch.clamp(x, min=-1.0, max=1.0)\n        x = torch.nn.functional.gelu(x)\n        return x\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\ndepth, height, width = 16, 64, 64\nkernel_size = 3\nsum_tensor_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, sum_tensor_shape]"}}
{"task_id": "L2_91", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies softmax, adds a bias term, scales the result, and applies sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.softmax(x, dim=1)\n        x = x + self.bias\n        x = x * self.scaling_factor\n        x = torch.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies softmax, adds a bias term, scales the result, and applies sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.softmax(x, dim=1)\n        x = x + self.bias\n        x = x * self.scaling_factor\n        x = torch.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 91, "problem_name": "91_ConvTranspose2d_Softmax_BiasAdd_Scaling_Sigmoid.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, applies softmax, adds a bias term, scales the result, and applies sigmoid.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape)) \n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.softmax(x, dim=1)\n        x = x + self.bias\n        x = x * self.scaling_factor\n        x = torch.sigmoid(x)\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape, scaling_factor]"}}
{"task_id": "L2_92", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies Group Normalization, Tanh, HardSwish, \n    Residual Addition, and LogSumExp.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, eps=1e-5):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(groups, out_channels, eps=eps)\n        self.tanh = nn.Tanh()\n        self.hard_swish = nn.Hardswish()\n\n    def forward(self, x):\n        # Convolution\n        x_conv = self.conv(x)\n        # Group Normalization\n        x_norm = self.group_norm(x_conv)\n        # Tanh\n        x_tanh = self.tanh(x_norm)\n        # HardSwish\n        x_hard_swish = self.hard_swish(x_tanh)\n        # Residual Addition\n        x_res = x_conv + x_hard_swish\n        # LogSumExp\n        x_logsumexp = torch.logsumexp(x_res, dim=1, keepdim=True)\n        return x_logsumexp\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ngroups = 16\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies Group Normalization, Tanh, HardSwish, \n    Residual Addition, and LogSumExp.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, eps=1e-5):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(groups, out_channels, eps=eps)\n        self.tanh = nn.Tanh()\n        self.hard_swish = nn.Hardswish()\n\n    def forward(self, x):\n        # Convolution\n        x_conv = self.conv(x)\n        # Group Normalization\n        x_norm = self.group_norm(x_conv)\n        # Tanh\n        x_tanh = self.tanh(x_norm)\n        # HardSwish\n        x_hard_swish = self.hard_swish(x_tanh)\n        # Residual Addition\n        x_res = x_conv + x_hard_swish\n        # LogSumExp\n        x_logsumexp = torch.logsumexp(x_res, dim=1, keepdim=True)\n        return x_logsumexp\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ngroups = 16\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 92, "problem_name": "92_Conv2d_GroupNorm_Tanh_HardSwish_ResidualAdd_LogSumExp.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a convolution, applies Group Normalization, Tanh, HardSwish, \n    Residual Addition, and LogSumExp.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, groups, eps=1e-5):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(groups, out_channels, eps=eps)\n        self.tanh = nn.Tanh()\n        self.hard_swish = nn.Hardswish()\n\n    def forward(self, x):\n        # Convolution\n        x_conv = self.conv(x)\n        # Group Normalization\n        x_norm = self.group_norm(x_conv)\n        # Tanh\n        x_tanh = self.tanh(x_norm)\n        # HardSwish\n        x_hard_swish = self.hard_swish(x_tanh)\n        # Residual Addition\n        x_res = x_conv + x_hard_swish\n        # LogSumExp\n        x_logsumexp = torch.logsumexp(x_res, dim=1, keepdim=True)\n        return x_logsumexp\n\nbatch_size = 128\nin_channels = 8\nout_channels = 64\nheight, width = 128, 128\nkernel_size = 3\ngroups = 16\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups]"}}
{"task_id": "L2_93", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a value, takes the minimum, applies GELU, and multiplies by a value.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, add_value, multiply_value):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n        self.add_value = add_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.add_value\n        x = torch.min(x, torch.tensor(0.0, device=x.device))\n        x = torch.nn.functional.gelu(x)\n        x = x * self.multiply_value\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\nadd_value = 0.5\nmultiply_value = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, add_value, multiply_value]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a value, takes the minimum, applies GELU, and multiplies by a value.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, add_value, multiply_value):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n        self.add_value = add_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.add_value\n        x = torch.min(x, torch.tensor(0.0, device=x.device))\n        x = torch.nn.functional.gelu(x)\n        x = x * self.multiply_value\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\nadd_value = 0.5\nmultiply_value = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, add_value, multiply_value]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 93, "problem_name": "93_ConvTranspose2d_Add_Min_GELU_Multiply.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed convolution, adds a value, takes the minimum, applies GELU, and multiplies by a value.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, add_value, multiply_value):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n        self.add_value = add_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x + self.add_value\n        x = torch.min(x, torch.tensor(0.0, device=x.device))\n        x = torch.nn.functional.gelu(x)\n        x = x * self.multiply_value\n        return x\n\nbatch_size = 128\nin_channels = 64\nout_channels = 128\nheight, width = 64, 64\nkernel_size = 4\nstride = 2\nadd_value = 0.5\nmultiply_value = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, add_value, multiply_value]"}}
{"task_id": "L2_94", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a GEMM, BiasAdd, Hardtanh, Mish, and GroupNorm operations in sequence.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias_shape, num_groups):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.hardtanh = nn.Hardtanh()\n        self.mish = nn.Mish()\n        self.groupnorm = nn.GroupNorm(num_groups=num_groups, num_channels=out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x + self.bias\n        x = self.hardtanh(x)\n        x = self.mish(x)\n        x = self.groupnorm(x)\n        return x\n\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\nnum_groups = 256\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape, num_groups]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a GEMM, BiasAdd, Hardtanh, Mish, and GroupNorm operations in sequence.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias_shape, num_groups):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.hardtanh = nn.Hardtanh()\n        self.mish = nn.Mish()\n        self.groupnorm = nn.GroupNorm(num_groups=num_groups, num_channels=out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x + self.bias\n        x = self.hardtanh(x)\n        x = self.mish(x)\n        x = self.groupnorm(x)\n        return x\n\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\nnum_groups = 256\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape, num_groups]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 94, "problem_name": "94_Gemm_BiasAdd_Hardtanh_Mish_GroupNorm.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a GEMM, BiasAdd, Hardtanh, Mish, and GroupNorm operations in sequence.\n    \"\"\"\n    def __init__(self, in_features, out_features, bias_shape, num_groups):\n        super(Model, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.hardtanh = nn.Hardtanh()\n        self.mish = nn.Mish()\n        self.groupnorm = nn.GroupNorm(num_groups=num_groups, num_channels=out_features)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.gemm(x)\n        x = x + self.bias\n        x = self.hardtanh(x)\n        x = self.mish(x)\n        x = self.groupnorm(x)\n        return x\n\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbias_shape = (out_features,)\nnum_groups = 256\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bias_shape, num_groups]"}}
{"task_id": "L2_95", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a value, applies Swish, Tanh, GELU, and Hardtanh activation functions.\n    \"\"\"\n    def __init__(self, in_features, out_features, add_value_shape):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.add_value = nn.Parameter(torch.randn(add_value_shape)) \n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x + self.add_value\n        x = torch.sigmoid(x) * x # Swish\n        x = torch.tanh(x)\n        x = torch.nn.functional.gelu(x) # GELU\n        x = torch.nn.functional.hardtanh(x, min_val=-1, max_val=1) # Hardtanh\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nadd_value_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, add_value_shape]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a value, applies Swish, Tanh, GELU, and Hardtanh activation functions.\n    \"\"\"\n    def __init__(self, in_features, out_features, add_value_shape):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.add_value = nn.Parameter(torch.randn(add_value_shape)) \n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x + self.add_value\n        x = torch.sigmoid(x) * x # Swish\n        x = torch.tanh(x)\n        x = torch.nn.functional.gelu(x) # GELU\n        x = torch.nn.functional.hardtanh(x, min_val=-1, max_val=1) # Hardtanh\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nadd_value_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, add_value_shape]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 95, "problem_name": "95_Matmul_Add_Swish_Tanh_GELU_Hardtanh.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, adds a value, applies Swish, Tanh, GELU, and Hardtanh activation functions.\n    \"\"\"\n    def __init__(self, in_features, out_features, add_value_shape):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.add_value = nn.Parameter(torch.randn(add_value_shape)) \n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x + self.add_value\n        x = torch.sigmoid(x) * x # Swish\n        x = torch.tanh(x)\n        x = torch.nn.functional.gelu(x) # GELU\n        x = torch.nn.functional.hardtanh(x, min_val=-1, max_val=1) # Hardtanh\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nadd_value_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, add_value_shape]"}}
{"task_id": "L2_96", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed 3D convolution, multiplies by a scalar, applies max pooling, \n    global average pooling, and clamps the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.scale = scale\n        self.maxpool = nn.MaxPool3d(kernel_size=maxpool_kernel_size)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.clamp_min = 0\n        self.clamp_max = 1\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale\n        x = self.maxpool(x)\n        x = self.global_avg_pool(x)\n        x = torch.clamp(x, min=self.clamp_min, max=self.clamp_max)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale = 0.5\nmaxpool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed 3D convolution, multiplies by a scalar, applies max pooling, \n    global average pooling, and clamps the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.scale = scale\n        self.maxpool = nn.MaxPool3d(kernel_size=maxpool_kernel_size)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.clamp_min = 0\n        self.clamp_max = 1\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale\n        x = self.maxpool(x)\n        x = self.global_avg_pool(x)\n        x = torch.clamp(x, min=self.clamp_min, max=self.clamp_max)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale = 0.5\nmaxpool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 96, "problem_name": "96_ConvTranspose3d_Multiply_Max_GlobalAvgPool_Clamp.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a transposed 3D convolution, multiplies by a scalar, applies max pooling, \n    global average pooling, and clamps the output.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.scale = scale\n        self.maxpool = nn.MaxPool3d(kernel_size=maxpool_kernel_size)\n        self.global_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.clamp_min = 0\n        self.clamp_max = 1\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = x * self.scale\n        x = self.maxpool(x)\n        x = self.global_avg_pool(x)\n        x = torch.clamp(x, min=self.clamp_min, max=self.clamp_max)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\nscale = 0.5\nmaxpool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size]"}}
{"task_id": "L2_97", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, batch normalization, bias addition, division, and Swish activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = self.bn(x)\n        x = x + self.bias\n        x = x / self.divide_value\n        x = x * torch.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, batch normalization, bias addition, division, and Swish activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = self.bn(x)\n        x = x + self.bias\n        x = x / self.divide_value\n        x = x * torch.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 97, "problem_name": "97_Matmul_BatchNorm_BiasAdd_Divide_Swish.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, batch normalization, bias addition, division, and Swish activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = self.bn(x)\n        x = x + self.bias\n        x = x / self.divide_value\n        x = x * torch.sigmoid(x)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]"}}
{"task_id": "L2_98", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model implementing the pattern \"Matmul_AvgPool_GELU_Scale_Max\".\n    \"\"\"\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\npool_kernel_size = 16\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model implementing the pattern \"Matmul_AvgPool_GELU_Scale_Max\".\n    \"\"\"\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\npool_kernel_size = 16\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 98, "problem_name": "98_Matmul_AvgPool_GELU_Scale_Max.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model implementing the pattern \"Matmul_AvgPool_GELU_Scale_Max\".\n    \"\"\"\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(Model, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\npool_kernel_size = 16\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]"}}
{"task_id": "L2_99", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies GELU, and then applies Softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.softmax(x, dim=1)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies GELU, and then applies Softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.softmax(x, dim=1)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 99, "problem_name": "99_Matmul_GELU_Softmax.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies GELU, and then applies Softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.softmax(x, dim=1)\n        return x\n\nbatch_size = 1024\nin_features = 8192\nout_features = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]"}}
{"task_id": "L2_100", "level": 2, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a transposed 3D convolution, clamps the output to a minimum value, \n    and then divides the result by a constant.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, min_value, divisor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.min_value = min_value\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.clamp(x, min=self.min_value)\n        x = x / self.divisor\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 24, 48, 48\nkernel_size = 3\nstride = 2\npadding = 1\nmin_value = -1.0\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, min_value, divisor]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a transposed 3D convolution, clamps the output to a minimum value, \n    and then divides the result by a constant.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, min_value, divisor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.min_value = min_value\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.clamp(x, min=self.min_value)\n        x = x / self.divisor\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 24, 48, 48\nkernel_size = 3\nstride = 2\npadding = 1\nmin_value = -1.0\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, min_value, divisor]", "metadata": {"source": "kernelbench_dataset_api", "level": 2, "problem_id": 100, "problem_name": "100_ConvTranspose3d_Clamp_Min_Divide.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    A model that performs a transposed 3D convolution, clamps the output to a minimum value, \n    and then divides the result by a constant.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, min_value, divisor):\n        super(Model, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n        self.min_value = min_value\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.clamp(x, min=self.min_value)\n        x = x / self.divisor\n        return x\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\ndepth, height, width = 24, 48, 48\nkernel_size = 3\nstride = 2\npadding = 1\nmin_value = -1.0\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, min_value, divisor]"}}
{"task_id": "L3_1", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for layer_size in layer_sizes:\n            layers.append(nn.Linear(current_input_size, layer_size))\n            layers.append(nn.ReLU())\n            current_input_size = layer_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nlayer_sizes = [16384, 16384]\noutput_size = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, layer_sizes, output_size]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for layer_size in layer_sizes:\n            layers.append(nn.Linear(current_input_size, layer_size))\n            layers.append(nn.ReLU())\n            current_input_size = layer_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nlayer_sizes = [16384, 16384]\noutput_size = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, layer_sizes, output_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 1, "problem_name": "1_MLP.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for layer_size in layer_sizes:\n            layers.append(nn.Linear(current_input_size, layer_size))\n            layers.append(nn.ReLU())\n            current_input_size = layer_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nlayer_sizes = [16384, 16384]\noutput_size = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, layer_sizes, output_size]"}}
{"task_id": "L3_2", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param hidden_layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for hidden_size in hidden_layer_sizes:\n            layers.append(nn.Linear(current_input_size, hidden_size))\n            layers.append(nn.ReLU())\n            current_input_size = hidden_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nhidden_layer_sizes = [32768, 32768]\noutput_size = 16384\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param hidden_layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for hidden_size in hidden_layer_sizes:\n            layers.append(nn.Linear(current_input_size, hidden_size))\n            layers.append(nn.ReLU())\n            current_input_size = hidden_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nhidden_layer_sizes = [32768, 32768]\noutput_size = 16384\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 2, "problem_name": "2_ShallowWideMLP.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param hidden_layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for hidden_size in hidden_layer_sizes:\n            layers.append(nn.Linear(current_input_size, hidden_size))\n            layers.append(nn.ReLU())\n            current_input_size = hidden_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 128\ninput_size = 16384\nhidden_layer_sizes = [32768, 32768]\noutput_size = 16384\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]"}}
{"task_id": "L3_3", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param hidden_layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for hidden_size in hidden_layer_sizes:\n            layers.append(nn.Linear(current_input_size, hidden_size))\n            layers.append(nn.ReLU())\n            current_input_size = hidden_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 1024\ninput_size = 8192\nhidden_layer_sizes = [1024] * 16  # deep network with wider layers\noutput_size = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param hidden_layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for hidden_size in hidden_layer_sizes:\n            layers.append(nn.Linear(current_input_size, hidden_size))\n            layers.append(nn.ReLU())\n            current_input_size = hidden_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 1024\ninput_size = 8192\nhidden_layer_sizes = [1024] * 16  # deep network with wider layers\noutput_size = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 3, "problem_name": "3_DeepNarrowMLP.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, input_size, hidden_layer_sizes, output_size):\n        \"\"\"\n        :param input_size: The number of input features\n        :param hidden_layer_sizes: A list of ints containing the sizes of each hidden layer\n        :param output_size: The number of output features\n        \"\"\"\n        super(Model, self).__init__()\n        \n        layers = []\n        current_input_size = input_size\n        \n        for hidden_size in hidden_layer_sizes:\n            layers.append(nn.Linear(current_input_size, hidden_size))\n            layers.append(nn.ReLU())\n            current_input_size = hidden_size\n        \n        layers.append(nn.Linear(current_input_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, input_size)\n        :return: The output tensor, shape (batch_size, output_size)\n        \"\"\"\n        return self.network(x)\n\n# Test code\nbatch_size = 1024\ninput_size = 8192\nhidden_layer_sizes = [1024] * 16  # deep network with wider layers\noutput_size = 8192\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_layer_sizes, output_size]"}}
{"task_id": "L3_4", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes):\n        \"\"\"\n        LeNet-5 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes.\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # Convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n        self.fc2 = nn.Linear(in_features=120, out_features=84)\n        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the LeNet-5 model.\n\n        :param x: The input tensor, shape (batch_size, 1, 32, 32)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        # First convolutional layer with ReLU activation and max pooling\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        \n        # Second convolutional layer with ReLU activation and max pooling\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        \n        # Flatten the output for the fully connected layers\n        x = x.view(-1, 16*5*5)\n        \n        # First fully connected layer with ReLU activation\n        x = F.relu(self.fc1(x))\n        \n        # Second fully connected layer with ReLU activation\n        x = F.relu(self.fc2(x))\n        \n        # Final fully connected layer\n        x = self.fc3(x)\n        \n        return x\n\n# Test code for the LeNet-5 model (larger batch & image)\nbatch_size = 4096\nnum_classes = 20\n\ndef get_inputs():\n    return [torch.rand(batch_size, 1, 32, 32)]\n\ndef get_init_inputs():\n    return [num_classes]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes):\n        \"\"\"\n        LeNet-5 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes.\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # Convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n        self.fc2 = nn.Linear(in_features=120, out_features=84)\n        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the LeNet-5 model.\n\n        :param x: The input tensor, shape (batch_size, 1, 32, 32)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        # First convolutional layer with ReLU activation and max pooling\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        \n        # Second convolutional layer with ReLU activation and max pooling\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        \n        # Flatten the output for the fully connected layers\n        x = x.view(-1, 16*5*5)\n        \n        # First fully connected layer with ReLU activation\n        x = F.relu(self.fc1(x))\n        \n        # Second fully connected layer with ReLU activation\n        x = F.relu(self.fc2(x))\n        \n        # Final fully connected layer\n        x = self.fc3(x)\n        \n        return x\n\n# Test code for the LeNet-5 model (larger batch & image)\nbatch_size = 4096\nnum_classes = 20\n\ndef get_inputs():\n    return [torch.rand(batch_size, 1, 32, 32)]\n\ndef get_init_inputs():\n    return [num_classes]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 4, "problem_name": "4_LeNet5.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes):\n        \"\"\"\n        LeNet-5 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes.\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # Convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n        self.fc2 = nn.Linear(in_features=120, out_features=84)\n        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the LeNet-5 model.\n\n        :param x: The input tensor, shape (batch_size, 1, 32, 32)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        # First convolutional layer with ReLU activation and max pooling\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        \n        # Second convolutional layer with ReLU activation and max pooling\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        \n        # Flatten the output for the fully connected layers\n        x = x.view(-1, 16*5*5)\n        \n        # First fully connected layer with ReLU activation\n        x = F.relu(self.fc1(x))\n        \n        # Second fully connected layer with ReLU activation\n        x = F.relu(self.fc2(x))\n        \n        # Final fully connected layer\n        x = self.fc3(x)\n        \n        return x\n\n# Test code for the LeNet-5 model (larger batch & image)\nbatch_size = 4096\nnum_classes = 20\n\ndef get_inputs():\n    return [torch.rand(batch_size, 1, 32, 32)]\n\ndef get_init_inputs():\n    return [num_classes]"}}
{"task_id": "L3_5", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # First convolutional layer\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Second convolutional layer\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Third convolutional layer\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)\n        self.relu3 = nn.ReLU(inplace=True)\n        \n        # Fourth convolutional layer\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)\n        self.relu4 = nn.ReLU(inplace=True)\n        \n        # Fifth convolutional layer\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n        self.relu5 = nn.ReLU(inplace=True)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(in_features=256 * 6 * 6, out_features=4096)\n        self.relu6 = nn.ReLU(inplace=True)\n        self.dropout1 = nn.Dropout(p=0.0)\n        \n        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n        self.relu7 = nn.ReLU(inplace=True)\n        self.dropout2 = nn.Dropout(p=0.0)\n        \n        self.fc3 = nn.Linear(in_features=4096, out_features=num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.maxpool1(x)\n        \n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.maxpool2(x)\n        \n        x = self.conv3(x)\n        x = self.relu3(x)\n        \n        x = self.conv4(x)\n        x = self.relu4(x)\n        \n        x = self.conv5(x)\n        x = self.relu5(x)\n        x = self.maxpool3(x)\n        \n        x = torch.flatten(x, 1)\n        \n        x = self.fc1(x)\n        x = self.relu6(x)\n        x = self.dropout1(x)\n        \n        x = self.fc2(x)\n        x = self.relu7(x)\n        x = self.dropout2(x)\n        \n        x = self.fc3(x)\n        \n        return x\n\n# Test code\nbatch_size = 1024\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # First convolutional layer\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Second convolutional layer\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Third convolutional layer\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)\n        self.relu3 = nn.ReLU(inplace=True)\n        \n        # Fourth convolutional layer\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)\n        self.relu4 = nn.ReLU(inplace=True)\n        \n        # Fifth convolutional layer\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n        self.relu5 = nn.ReLU(inplace=True)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(in_features=256 * 6 * 6, out_features=4096)\n        self.relu6 = nn.ReLU(inplace=True)\n        self.dropout1 = nn.Dropout(p=0.0)\n        \n        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n        self.relu7 = nn.ReLU(inplace=True)\n        self.dropout2 = nn.Dropout(p=0.0)\n        \n        self.fc3 = nn.Linear(in_features=4096, out_features=num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.maxpool1(x)\n        \n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.maxpool2(x)\n        \n        x = self.conv3(x)\n        x = self.relu3(x)\n        \n        x = self.conv4(x)\n        x = self.relu4(x)\n        \n        x = self.conv5(x)\n        x = self.relu5(x)\n        x = self.maxpool3(x)\n        \n        x = torch.flatten(x, 1)\n        \n        x = self.fc1(x)\n        x = self.relu6(x)\n        x = self.dropout1(x)\n        \n        x = self.fc2(x)\n        x = self.relu7(x)\n        x = self.dropout2(x)\n        \n        x = self.fc3(x)\n        \n        return x\n\n# Test code\nbatch_size = 1024\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 5, "problem_name": "5_AlexNet.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # First convolutional layer\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Second convolutional layer\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Third convolutional layer\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)\n        self.relu3 = nn.ReLU(inplace=True)\n        \n        # Fourth convolutional layer\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)\n        self.relu4 = nn.ReLU(inplace=True)\n        \n        # Fifth convolutional layer\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n        self.relu5 = nn.ReLU(inplace=True)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(in_features=256 * 6 * 6, out_features=4096)\n        self.relu6 = nn.ReLU(inplace=True)\n        self.dropout1 = nn.Dropout(p=0.0)\n        \n        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n        self.relu7 = nn.ReLU(inplace=True)\n        self.dropout2 = nn.Dropout(p=0.0)\n        \n        self.fc3 = nn.Linear(in_features=4096, out_features=num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.maxpool1(x)\n        \n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.maxpool2(x)\n        \n        x = self.conv3(x)\n        x = self.relu3(x)\n        \n        x = self.conv4(x)\n        x = self.relu4(x)\n        \n        x = self.conv5(x)\n        x = self.relu5(x)\n        x = self.maxpool3(x)\n        \n        x = torch.flatten(x, 1)\n        \n        x = self.fc1(x)\n        x = self.relu6(x)\n        x = self.dropout1(x)\n        \n        x = self.fc2(x)\n        x = self.relu7(x)\n        x = self.dropout2(x)\n        \n        x = self.fc3(x)\n        \n        return x\n\n# Test code\nbatch_size = 1024\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]"}}
{"task_id": "L3_6", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_1x1: Number of output channels for the 1x1 convolution\n        :param reduce_3x3: Number of output channels for the 1x1 reduction before 3x3 convolution\n        :param out_3x3: Number of output channels for the 3x3 convolution\n        :param reduce_5x5: Number of output channels for the 1x1 reduction before 5x5 convolution\n        :param out_5x5: Number of output channels for the 5x5 convolution\n        :param pool_proj: Number of output channels for the pooling projection\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # 1x1 convolution branch\n        self.branch1x1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n        \n        # 3x3 convolution branch\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_3x3, kernel_size=1),\n            nn.Conv2d(reduce_3x3, out_3x3, kernel_size=3, padding=1)\n        )\n        \n        # 5x5 convolution branch\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_5x5, kernel_size=1),\n            nn.Conv2d(reduce_5x5, out_5x5, kernel_size=5, padding=2)\n        )\n        \n        # Max pooling branch\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n        \n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\n# Test code\nin_channels = 480\nout_1x1 = 192\nreduce_3x3 = 96\nout_3x3 = 208\nreduce_5x5 = 16\nout_5x5 = 48\npool_proj = 64\nbatch_size = 10\nheight = 224\nwidth = 224\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_1x1: Number of output channels for the 1x1 convolution\n        :param reduce_3x3: Number of output channels for the 1x1 reduction before 3x3 convolution\n        :param out_3x3: Number of output channels for the 3x3 convolution\n        :param reduce_5x5: Number of output channels for the 1x1 reduction before 5x5 convolution\n        :param out_5x5: Number of output channels for the 5x5 convolution\n        :param pool_proj: Number of output channels for the pooling projection\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # 1x1 convolution branch\n        self.branch1x1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n        \n        # 3x3 convolution branch\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_3x3, kernel_size=1),\n            nn.Conv2d(reduce_3x3, out_3x3, kernel_size=3, padding=1)\n        )\n        \n        # 5x5 convolution branch\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_5x5, kernel_size=1),\n            nn.Conv2d(reduce_5x5, out_5x5, kernel_size=5, padding=2)\n        )\n        \n        # Max pooling branch\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n        \n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\n# Test code\nin_channels = 480\nout_1x1 = 192\nreduce_3x3 = 96\nout_3x3 = 208\nreduce_5x5 = 16\nout_5x5 = 48\npool_proj = 64\nbatch_size = 10\nheight = 224\nwidth = 224\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 6, "problem_name": "6_GoogleNetInceptionModule.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_1x1: Number of output channels for the 1x1 convolution\n        :param reduce_3x3: Number of output channels for the 1x1 reduction before 3x3 convolution\n        :param out_3x3: Number of output channels for the 3x3 convolution\n        :param reduce_5x5: Number of output channels for the 1x1 reduction before 5x5 convolution\n        :param out_5x5: Number of output channels for the 5x5 convolution\n        :param pool_proj: Number of output channels for the pooling projection\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # 1x1 convolution branch\n        self.branch1x1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n        \n        # 3x3 convolution branch\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_3x3, kernel_size=1),\n            nn.Conv2d(reduce_3x3, out_3x3, kernel_size=3, padding=1)\n        )\n        \n        # 5x5 convolution branch\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_5x5, kernel_size=1),\n            nn.Conv2d(reduce_5x5, out_5x5, kernel_size=5, padding=2)\n        )\n        \n        # Max pooling branch\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n        \n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\n# Test code\nin_channels = 480\nout_1x1 = 192\nreduce_3x3 = 96\nout_3x3 = 208\nreduce_5x5 = 16\nout_5x5 = 48\npool_proj = 64\nbatch_size = 10\nheight = 224\nwidth = 224\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj]"}}
{"task_id": "L3_7", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass InceptionModule(nn.Module):\n    def __init__(self, in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_1x1: Number of output channels for the 1x1 convolution\n        :param reduce_3x3: Number of output channels for the 1x1 reduction before 3x3 convolution\n        :param out_3x3: Number of output channels for the 3x3 convolution\n        :param reduce_5x5: Number of output channels for the 1x1 reduction before 5x5 convolution\n        :param out_5x5: Number of output channels for the 5x5 convolution\n        :param pool_proj: Number of output channels for the pooling projection\n        \"\"\"\n        super(InceptionModule, self).__init__()\n        \n        # 1x1 convolution branch\n        self.branch1x1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n        \n        # 3x3 convolution branch\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_3x3, kernel_size=1),\n            nn.Conv2d(reduce_3x3, out_3x3, kernel_size=3, padding=1)\n        )\n        \n        # 5x5 convolution branch\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_5x5, kernel_size=1),\n            nn.Conv2d(reduce_5x5, out_5x5, kernel_size=5, padding=2)\n        )\n        \n        # Max pooling branch\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n        \n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.maxpool1 = nn.MaxPool2d(3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)\n        self.conv3 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n        self.maxpool2 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n        self.maxpool3 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n        self.maxpool4 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n        \n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(0.0)\n        self.fc = nn.Linear(1024, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.maxpool1(F.relu(self.conv1(x)))\n        x = F.relu(self.conv2(x))\n        x = self.maxpool2(F.relu(self.conv3(x)))\n        \n        x = self.inception3a(x)\n        x = self.inception3b(x)\n        x = self.maxpool3(x)\n        \n        x = self.inception4a(x)\n        x = self.inception4b(x)\n        x = self.inception4c(x)\n        x = self.inception4d(x)\n        x = self.inception4e(x)\n        x = self.maxpool4(x)\n        \n        x = self.inception5a(x)\n        x = self.inception5b(x)\n        \n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        \n        return x\n\n# Test code\nbatch_size = 10\ninput_channels = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_channels, height, width)]\n\ndef get_init_inputs():\n    return [num_classes]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass InceptionModule(nn.Module):\n    def __init__(self, in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_1x1: Number of output channels for the 1x1 convolution\n        :param reduce_3x3: Number of output channels for the 1x1 reduction before 3x3 convolution\n        :param out_3x3: Number of output channels for the 3x3 convolution\n        :param reduce_5x5: Number of output channels for the 1x1 reduction before 5x5 convolution\n        :param out_5x5: Number of output channels for the 5x5 convolution\n        :param pool_proj: Number of output channels for the pooling projection\n        \"\"\"\n        super(InceptionModule, self).__init__()\n        \n        # 1x1 convolution branch\n        self.branch1x1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n        \n        # 3x3 convolution branch\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_3x3, kernel_size=1),\n            nn.Conv2d(reduce_3x3, out_3x3, kernel_size=3, padding=1)\n        )\n        \n        # 5x5 convolution branch\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_5x5, kernel_size=1),\n            nn.Conv2d(reduce_5x5, out_5x5, kernel_size=5, padding=2)\n        )\n        \n        # Max pooling branch\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n        \n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.maxpool1 = nn.MaxPool2d(3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)\n        self.conv3 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n        self.maxpool2 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n        self.maxpool3 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n        self.maxpool4 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n        \n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(0.0)\n        self.fc = nn.Linear(1024, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.maxpool1(F.relu(self.conv1(x)))\n        x = F.relu(self.conv2(x))\n        x = self.maxpool2(F.relu(self.conv3(x)))\n        \n        x = self.inception3a(x)\n        x = self.inception3b(x)\n        x = self.maxpool3(x)\n        \n        x = self.inception4a(x)\n        x = self.inception4b(x)\n        x = self.inception4c(x)\n        x = self.inception4d(x)\n        x = self.inception4e(x)\n        x = self.maxpool4(x)\n        \n        x = self.inception5a(x)\n        x = self.inception5b(x)\n        \n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        \n        return x\n\n# Test code\nbatch_size = 10\ninput_channels = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_channels, height, width)]\n\ndef get_init_inputs():\n    return [num_classes]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 7, "problem_name": "7_GoogleNetInceptionV1.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass InceptionModule(nn.Module):\n    def __init__(self, in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_1x1: Number of output channels for the 1x1 convolution\n        :param reduce_3x3: Number of output channels for the 1x1 reduction before 3x3 convolution\n        :param out_3x3: Number of output channels for the 3x3 convolution\n        :param reduce_5x5: Number of output channels for the 1x1 reduction before 5x5 convolution\n        :param out_5x5: Number of output channels for the 5x5 convolution\n        :param pool_proj: Number of output channels for the pooling projection\n        \"\"\"\n        super(InceptionModule, self).__init__()\n        \n        # 1x1 convolution branch\n        self.branch1x1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n        \n        # 3x3 convolution branch\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_3x3, kernel_size=1),\n            nn.Conv2d(reduce_3x3, out_3x3, kernel_size=3, padding=1)\n        )\n        \n        # 5x5 convolution branch\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_5x5, kernel_size=1),\n            nn.Conv2d(reduce_5x5, out_5x5, kernel_size=5, padding=2)\n        )\n        \n        # Max pooling branch\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n        \n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.maxpool1 = nn.MaxPool2d(3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)\n        self.conv3 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n        self.maxpool2 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n        self.maxpool3 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n        self.maxpool4 = nn.MaxPool2d(3, stride=2, padding=1)\n        \n        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n        \n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(0.0)\n        self.fc = nn.Linear(1024, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.maxpool1(F.relu(self.conv1(x)))\n        x = F.relu(self.conv2(x))\n        x = self.maxpool2(F.relu(self.conv3(x)))\n        \n        x = self.inception3a(x)\n        x = self.inception3b(x)\n        x = self.maxpool3(x)\n        \n        x = self.inception4a(x)\n        x = self.inception4b(x)\n        x = self.inception4c(x)\n        x = self.inception4d(x)\n        x = self.inception4e(x)\n        x = self.maxpool4(x)\n        \n        x = self.inception5a(x)\n        x = self.inception5b(x)\n        \n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        \n        return x\n\n# Test code\nbatch_size = 10\ninput_channels = 3\nheight = 224\nwidth = 224\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, input_channels, height, width)]\n\ndef get_init_inputs():\n    return [num_classes]"}}
{"task_id": "L3_8", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_channels * self.expansion),\n        )\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_channels * self.expansion),\n        )\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 8, "problem_name": "8_ResNetBasicBlock.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_channels * self.expansion),\n        )\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]"}}
{"task_id": "L3_9", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n\n    def _make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n# Test code\nbatch_size = 2\nnum_classes = 1000\ninput_shape = (batch_size, 3, 224, 224)\n\ndef get_inputs():\n    return [torch.rand(input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n\n    def _make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n# Test code\nbatch_size = 2\nnum_classes = 1000\ninput_shape = (batch_size, 3, 224, 224)\n\ndef get_inputs():\n    return [torch.rand(input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 9, "problem_name": "9_ResNet18.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n\n    def _make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n# Test code\nbatch_size = 2\nnum_classes = 1000\ninput_shape = (batch_size, 3, 224, 224)\n\ndef get_inputs():\n    return [torch.rand(input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]"}}
{"task_id": "L3_10", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels * expansion, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\nclass Model(nn.Module):\n    def __init__(self, layers, num_classes=1000):\n        \"\"\"\n        :param block: Type of block to use (BasicBlock or Bottleneck)\n        :param layers: List of integers specifying the number of blocks in each layer\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        block = Bottleneck\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n# Test code\nbatch_size = 10\nheight = 224\nwidth = 224\nlayers = [3, 4, 23, 3]\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [layers, num_classes]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels * expansion, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\nclass Model(nn.Module):\n    def __init__(self, layers, num_classes=1000):\n        \"\"\"\n        :param block: Type of block to use (BasicBlock or Bottleneck)\n        :param layers: List of integers specifying the number of blocks in each layer\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        block = Bottleneck\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n# Test code\nbatch_size = 10\nheight = 224\nwidth = 224\nlayers = [3, 4, 23, 3]\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [layers, num_classes]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 10, "problem_name": "10_ResNet101.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        \"\"\"\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param stride: Stride for the first convolutional layer\n        :param downsample: Downsample layer for the shortcut connection\n        \"\"\"\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, in_channels, height, width)\n        :return: Output tensor, shape (batch_size, out_channels * expansion, height, width)\n        \"\"\"\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\nclass Model(nn.Module):\n    def __init__(self, layers, num_classes=1000):\n        \"\"\"\n        :param block: Type of block to use (BasicBlock or Bottleneck)\n        :param layers: List of integers specifying the number of blocks in each layer\n        :param num_classes: Number of output classes\n        \"\"\"\n        super(Model, self).__init__()\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        block = Bottleneck\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor, shape (batch_size, 3, height, width)\n        :return: Output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n# Test code\nbatch_size = 10\nheight = 224\nwidth = 224\nlayers = [3, 4, 23, 3]\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [layers, num_classes]"}}
{"task_id": "L3_11", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        Initialize the VGG16 model.\n        \n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # VGG16 architecture: 5 blocks of convolutional layers followed by max pooling\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        # Fully connected layers\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the VGG16 model.\n        \n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        Initialize the VGG16 model.\n        \n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # VGG16 architecture: 5 blocks of convolutional layers followed by max pooling\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        # Fully connected layers\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the VGG16 model.\n        \n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 11, "problem_name": "11_VGG16.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        Initialize the VGG16 model.\n        \n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # VGG16 architecture: 5 blocks of convolutional layers followed by max pooling\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        # Fully connected layers\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the VGG16 model.\n        \n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]"}}
{"task_id": "L3_12", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        Initialize the VGG19 model.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # VGG19 architecture: 16 Conv layers + 5 MaxPool layers + 3 Fully Connected layers\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the VGG19 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "reference_kernel": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        Initialize the VGG19 model.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # VGG19 architecture: 16 Conv layers + 5 MaxPool layers + 3 Fully Connected layers\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the VGG19 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 12, "problem_name": "12_VGG19.py", "ref_arch_src": "import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        Initialize the VGG19 model.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet)\n        \"\"\"\n        super(Model, self).__init__()\n        \n        # VGG19 architecture: 16 Conv layers + 5 MaxPool layers + 3 Fully Connected layers\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.0),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the VGG19 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]"}}
{"task_id": "L3_13", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(Model, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nbatch_size = 128\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 256, 256\n\ndef get_inputs():\n    return [torch.rand(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(Model, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nbatch_size = 128\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 256, 256\n\ndef get_inputs():\n    return [torch.rand(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 13, "problem_name": "13_DenseNet121TransitionLayer.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(Model, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nbatch_size = 128\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 256, 256\n\ndef get_inputs():\n    return [torch.rand(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n"}}
{"task_id": "L3_14", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(Model, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n    \nbatch_size = 10\nnum_layers = 6\nnum_input_features = 32\ngrowth_rate = 32\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.rand(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_layers, num_input_features , growth_rate]", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(Model, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n    \nbatch_size = 10\nnum_layers = 6\nnum_input_features = 32\ngrowth_rate = 32\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.rand(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_layers, num_input_features , growth_rate]", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 14, "problem_name": "14_DenseNet121DenseBlock.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(Model, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n    \nbatch_size = 10\nnum_layers = 6\nnum_input_features = 32\ngrowth_rate = 32\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.rand(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_layers, num_input_features , growth_rate]"}}
{"task_id": "L3_15", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DenseBlock(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(DenseBlock, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n\nclass TransitionLayer(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(TransitionLayer, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nclass Model(nn.Module):\n    def __init__(self, growth_rate: int = 32, num_classes: int = 1000):\n        \"\"\"\n        :param growth_rate: The growth rate of the DenseNet (new features added per layer)\n        :param num_classes: The number of output classes for classification\n        \"\"\"\n        super(Model, self).__init__()\n\n        # Initial convolution and pooling\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n\n        # Each dense block is followed by a transition layer, except the last one\n        num_features = 64\n        block_layers = [6, 12, 24, 16]  # Corresponding layers in DenseNet121\n\n        self.dense_blocks = nn.ModuleList()\n        self.transition_layers = nn.ModuleList()\n\n        for i, num_layers in enumerate(block_layers):\n            block = DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=growth_rate)\n            self.dense_blocks.append(block)\n            num_features = num_features + num_layers * growth_rate\n\n            if i != len(block_layers) - 1:\n                transition = TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)\n                self.transition_layers.append(transition)\n                num_features = num_features // 2\n\n        # Final batch norm and classifier\n        self.final_bn = nn.BatchNorm2d(num_features)\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, 3, height, width)\n        :return: Output tensor of shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n\n        for i, block in enumerate(self.dense_blocks):\n            x = block(x)\n            if i != len(self.dense_blocks) - 1:\n                x = self.transition_layers[i](x)\n\n        x = self.final_bn(x)\n        x = F.relu(x, inplace=True)\n        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Testing the DenseNet121 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224  # Standard input size for DenseNet\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [32, num_classes]\n", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DenseBlock(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(DenseBlock, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n\nclass TransitionLayer(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(TransitionLayer, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nclass Model(nn.Module):\n    def __init__(self, growth_rate: int = 32, num_classes: int = 1000):\n        \"\"\"\n        :param growth_rate: The growth rate of the DenseNet (new features added per layer)\n        :param num_classes: The number of output classes for classification\n        \"\"\"\n        super(Model, self).__init__()\n\n        # Initial convolution and pooling\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n\n        # Each dense block is followed by a transition layer, except the last one\n        num_features = 64\n        block_layers = [6, 12, 24, 16]  # Corresponding layers in DenseNet121\n\n        self.dense_blocks = nn.ModuleList()\n        self.transition_layers = nn.ModuleList()\n\n        for i, num_layers in enumerate(block_layers):\n            block = DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=growth_rate)\n            self.dense_blocks.append(block)\n            num_features = num_features + num_layers * growth_rate\n\n            if i != len(block_layers) - 1:\n                transition = TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)\n                self.transition_layers.append(transition)\n                num_features = num_features // 2\n\n        # Final batch norm and classifier\n        self.final_bn = nn.BatchNorm2d(num_features)\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, 3, height, width)\n        :return: Output tensor of shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n\n        for i, block in enumerate(self.dense_blocks):\n            x = block(x)\n            if i != len(self.dense_blocks) - 1:\n                x = self.transition_layers[i](x)\n\n        x = self.final_bn(x)\n        x = F.relu(x, inplace=True)\n        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Testing the DenseNet121 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224  # Standard input size for DenseNet\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [32, num_classes]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 15, "problem_name": "15_DenseNet121.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DenseBlock(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(DenseBlock, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n\nclass TransitionLayer(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(TransitionLayer, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nclass Model(nn.Module):\n    def __init__(self, growth_rate: int = 32, num_classes: int = 1000):\n        \"\"\"\n        :param growth_rate: The growth rate of the DenseNet (new features added per layer)\n        :param num_classes: The number of output classes for classification\n        \"\"\"\n        super(Model, self).__init__()\n\n        # Initial convolution and pooling\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n\n        # Each dense block is followed by a transition layer, except the last one\n        num_features = 64\n        block_layers = [6, 12, 24, 16]  # Corresponding layers in DenseNet121\n\n        self.dense_blocks = nn.ModuleList()\n        self.transition_layers = nn.ModuleList()\n\n        for i, num_layers in enumerate(block_layers):\n            block = DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=growth_rate)\n            self.dense_blocks.append(block)\n            num_features = num_features + num_layers * growth_rate\n\n            if i != len(block_layers) - 1:\n                transition = TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)\n                self.transition_layers.append(transition)\n                num_features = num_features // 2\n\n        # Final batch norm and classifier\n        self.final_bn = nn.BatchNorm2d(num_features)\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, 3, height, width)\n        :return: Output tensor of shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n\n        for i, block in enumerate(self.dense_blocks):\n            x = block(x)\n            if i != len(self.dense_blocks) - 1:\n                x = self.transition_layers[i](x)\n\n        x = self.final_bn(x)\n        x = F.relu(x, inplace=True)\n        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Testing the DenseNet121 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224  # Standard input size for DenseNet\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [32, num_classes]\n"}}
{"task_id": "L3_16", "level": 3, "prompt": "Optimize this PyTorch model with a custom GPU kernel implementation.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DenseBlock(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(DenseBlock, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n\nclass TransitionLayer(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(TransitionLayer, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nclass Model(nn.Module):\n    def __init__(self, growth_rate: int = 32, num_classes: int = 1000):\n        \"\"\"\n        :param growth_rate: The growth rate of the DenseNet (new features added per layer)\n        :param num_classes: The number of output classes for classification\n        \"\"\"\n        super(Model, self).__init__()\n\n        # Initial convolution and pooling\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n\n        # Each dense block is followed by a transition layer, except the last one\n        num_features = 64\n        block_layers = [6, 12, 48, 32]  # Corresponding layers in DenseNet201\n\n        self.dense_blocks = nn.ModuleList()\n        self.transition_layers = nn.ModuleList()\n\n        for i, num_layers in enumerate(block_layers):\n            block = DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=growth_rate)\n            self.dense_blocks.append(block)\n            num_features = num_features + num_layers * growth_rate\n\n            if i != len(block_layers) - 1:\n                transition = TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)\n                self.transition_layers.append(transition)\n                num_features = num_features // 2\n\n        # Final batch norm and classifier\n        self.final_bn = nn.BatchNorm2d(num_features)\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, 3, height, width)\n        :return: Output tensor of shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n\n        for i, block in enumerate(self.dense_blocks):\n            x = block(x)\n            if i != len(self.dense_blocks) - 1:\n                x = self.transition_layers[i](x)\n\n        x = self.final_bn(x)\n        x = F.relu(x, inplace=True)\n        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Testing the DenseNet201 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224  # Standard input size for DenseNet\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [32, num_classes]\n", "reference_kernel": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DenseBlock(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(DenseBlock, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n\nclass TransitionLayer(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(TransitionLayer, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nclass Model(nn.Module):\n    def __init__(self, growth_rate: int = 32, num_classes: int = 1000):\n        \"\"\"\n        :param growth_rate: The growth rate of the DenseNet (new features added per layer)\n        :param num_classes: The number of output classes for classification\n        \"\"\"\n        super(Model, self).__init__()\n\n        # Initial convolution and pooling\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n\n        # Each dense block is followed by a transition layer, except the last one\n        num_features = 64\n        block_layers = [6, 12, 48, 32]  # Corresponding layers in DenseNet201\n\n        self.dense_blocks = nn.ModuleList()\n        self.transition_layers = nn.ModuleList()\n\n        for i, num_layers in enumerate(block_layers):\n            block = DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=growth_rate)\n            self.dense_blocks.append(block)\n            num_features = num_features + num_layers * growth_rate\n\n            if i != len(block_layers) - 1:\n                transition = TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)\n                self.transition_layers.append(transition)\n                num_features = num_features // 2\n\n        # Final batch norm and classifier\n        self.final_bn = nn.BatchNorm2d(num_features)\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, 3, height, width)\n        :return: Output tensor of shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n\n        for i, block in enumerate(self.dense_blocks):\n            x = block(x)\n            if i != len(self.dense_blocks) - 1:\n                x = self.transition_layers[i](x)\n\n        x = self.final_bn(x)\n        x = F.relu(x, inplace=True)\n        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Testing the DenseNet201 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224  # Standard input size for DenseNet\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [32, num_classes]\n", "metadata": {"source": "kernelbench_dataset_api", "level": 3, "problem_id": 16, "problem_name": "16_DenseNet201.py", "ref_arch_src": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DenseBlock(nn.Module):\n    def __init__(self, num_layers: int, num_input_features: int, growth_rate: int):\n        \"\"\"\n        :param num_layers: The number of layers in the dense block\n        :param num_input_features: The number of input feature maps\n        :param growth_rate: The growth rate for the dense block (new features added per layer)\n        \"\"\"\n        super(DenseBlock, self).__init__()\n        layers = []\n        for i in range(num_layers):\n            layers.append(self._make_layer(num_input_features + i * growth_rate, growth_rate))\n        self.layers = nn.ModuleList(layers)\n\n    def _make_layer(self, in_features: int, growth_rate: int):\n        \"\"\"\n        Creates a single layer with BatchNorm, ReLU, Conv2D, and Dropout.\n        \"\"\"\n        return nn.Sequential(\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_features, growth_rate, kernel_size=3, padding=1, bias=False),\n            nn.Dropout(0.0)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Concatenated output tensor with shape (batch_size, num_output_features, height, width)\n        \"\"\"\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(x)\n            features.append(new_feature)\n            x = torch.cat(features, 1)  # Concatenate along channel axis\n        return x\n\nclass TransitionLayer(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        \"\"\"\n        :param num_input_features: The number of input feature maps\n        :param num_output_features: The number of output feature maps\n        \"\"\"\n        super(TransitionLayer, self).__init__()\n        self.transition = nn.Sequential(\n            nn.BatchNorm2d(num_input_features),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, num_input_features, height, width)\n        :return: Downsampled tensor with reduced number of feature maps\n        \"\"\"\n        return self.transition(x)\n\nclass Model(nn.Module):\n    def __init__(self, growth_rate: int = 32, num_classes: int = 1000):\n        \"\"\"\n        :param growth_rate: The growth rate of the DenseNet (new features added per layer)\n        :param num_classes: The number of output classes for classification\n        \"\"\"\n        super(Model, self).__init__()\n\n        # Initial convolution and pooling\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n\n        # Each dense block is followed by a transition layer, except the last one\n        num_features = 64\n        block_layers = [6, 12, 48, 32]  # Corresponding layers in DenseNet201\n\n        self.dense_blocks = nn.ModuleList()\n        self.transition_layers = nn.ModuleList()\n\n        for i, num_layers in enumerate(block_layers):\n            block = DenseBlock(num_layers=num_layers, num_input_features=num_features, growth_rate=growth_rate)\n            self.dense_blocks.append(block)\n            num_features = num_features + num_layers * growth_rate\n\n            if i != len(block_layers) - 1:\n                transition = TransitionLayer(num_input_features=num_features, num_output_features=num_features // 2)\n                self.transition_layers.append(transition)\n                num_features = num_features // 2\n\n        # Final batch norm and classifier\n        self.final_bn = nn.BatchNorm2d(num_features)\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        :param x: Input tensor of shape (batch_size, 3, height, width)\n        :return: Output tensor of shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n\n        for i, block in enumerate(self.dense_blocks):\n            x = block(x)\n            if i != len(self.dense_blocks) - 1:\n                x = self.transition_layers[i](x)\n\n        x = self.final_bn(x)\n        x = F.relu(x, inplace=True)\n        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Testing the DenseNet201 model\nbatch_size = 10\nnum_classes = 10\nheight, width = 224, 224  # Standard input size for DenseNet\n\ndef get_inputs():\n    return [torch.rand(batch_size, 3, height, width)]\n\ndef get_init_inputs():\n    return [32, num_classes]\n"}}
