model:
  base_model: Qwen/Qwen2.5-Coder-7B-Instruct
  policy_family: qwen7b_lora
  dtype: bfloat16
  lora:
    rank: 64
    alpha: 16
    dropout: 0.05
  generation:
    temperature: 0.8
    top_p: 0.95
    max_new_tokens: 1024

training:
  batch_size: 8
  grad_accum_steps: 2
  learning_rate: 1.0e-5
  epochs: 3
